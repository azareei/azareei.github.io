<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://azareei.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://azareei.github.io/" rel="alternate" type="text/html" /><updated>2025-06-23T05:15:56+00:00</updated><id>https://azareei.github.io/feed.xml</id><title type="html">Ahmad Zareei</title><subtitle>Personal homepage of Ahmad Zareei, Senion AI research Scientist @META
</subtitle><entry><title type="html">Learning Gen-AI</title><link href="https://azareei.github.io/blog/2025/Generative-AI/" rel="alternate" type="text/html" title="Learning Gen-AI" /><published>2025-01-07T18:00:00+00:00</published><updated>2025-01-07T18:00:00+00:00</updated><id>https://azareei.github.io/blog/2025/Generative-AI</id><content type="html" xml:base="https://azareei.github.io/blog/2025/Generative-AI/"><![CDATA[<p>This is my note for my journey in getting deeper in Generative AI.</p>

<h1 id="generative-ai">Generative AI</h1>

<p>A generative model is a <em>joint</em> probability distribution $p(x)$, for $x\in\mathcal{X}$ . It’s a joint distribution because $x$ can be multidimensional where it consists of multiple variables  $(x_1, x_2, \ldots, x_n)$.</p>

<p>We also have <em>conditional</em> generative model $p(x\vert c)$ in which the generative model would be conditioned on inputs or covariates $c\in C$.</p>

<h2 id="1-types-of-generative-models">1 Types of generative Models</h2>

<ul>
  <li><strong>Probabilistic graphical models (PGM):</strong> uses simple, often linear, mappings to map a set of interconnected latent variables $z_1, \ldots, z_L$ to observed variables $x_1, \ldots, x_D$.</li>
  <li><strong>Deep Generative Models (DGM):</strong> uses deep neural networks to learn a complex mapping from a single latent vector $z$ to the observed data $x$. Types of DGM are
    <ul>
      <li><strong>Variational Autoencoders (VAE)</strong></li>
      <li><strong>AutoRegressive Models (ARM) models</strong></li>
      <li><strong>Normalizing Flows</strong></li>
      <li><strong>Diffusion Models</strong></li>
      <li><strong>Energy Based Models (EBM)</strong></li>
      <li><strong>Generative Adversarial Networks (GAN)</strong></li>
    </ul>
  </li>
</ul>

<p>The following table summarizes the different generative models across different aspects (we’ll discuss why in the next chapters):</p>

<table>
  <thead>
    <tr>
      <th><strong>Model</strong></th>
      <th><strong>Density</strong></th>
      <th><strong>Sampling</strong></th>
      <th><strong>Training</strong></th>
      <th><strong>Latents</strong></th>
      <th><strong>Architecture</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>PGM-D</strong><br />i.e., Probabilistic Graphical Model - Directed</td>
      <td>Exact, fast: The joint distribution $p(x)$ can be computed exactly and efficiently, leveraging the directed graph structure.</td>
      <td>Fast: Sampling is efficient using ancestral sampling, which sequentially samples variables based on dependencies in the DAG.</td>
      <td>MLE: Trained using Maximum Likelihood Estimation, which directly optimizes the likelihood of observed data.</td>
      <td>Optional: Latent variables (hidden variables) can be included but are not required for the model.</td>
      <td>Sparse DAG: The model uses a sparse Directed Acyclic Graph, where edges capture directed dependencies.</td>
    </tr>
    <tr>
      <td><strong>PGM-U</strong><br />i.e., Probabilistic Graphical Model - Undirected</td>
      <td>Approximate, slow: The joint distribution $p(x)$ requires approximations due to the intractable partition function, making it computationally slow</td>
      <td>Slow: Sampling typically involves computationally expensive methods like Markov Chain Monte Carlo (MCMC).</td>
      <td>MLE-A: Trained using approximate Maximum Likelihood Estimation, as exact computation of likelihood is infeasible.</td>
      <td>Optional: Latent variables can be included but are not mandatory for the model.</td>
      <td>Sparse graph: The model uses a sparse undirected graph, where edges represent mutual dependencies.</td>
    </tr>
    <tr>
      <td><strong>VAE</strong><br />i.e., Variational Auto Encoder</td>
      <td>LB, fast: Provides a <strong>lower bound</strong> on the likelihood (e.g., Evidence Lower Bound, or ELBO) and is computationally efficient for density modeling.</td>
      <td>Fast: Efficient sampling is achieved via reparameterization, enabling smooth gradient-based optimization in latent space.</td>
      <td>MLE-LB: Trained by maximizing a lower bound on the likelihood, balancing reconstruction and latent regularization.</td>
      <td>$\mathbb{R}^L$: Latent representations (e.g., a compressed representation of the data) are a central feature of the model.</td>
      <td>Encoder-Decoder: Uses an encoder to map data to latent space and a decoder to reconstruct the data from the latent space.</td>
    </tr>
    <tr>
      <td><strong>ARM</strong><br />i.d., AutoRegressive Model</td>
      <td>Exact, fast: The joint distribution $p(x)$ is computed exactly and efficiently using the sequential nature of the model.</td>
      <td>Slow: Sampling is sequential, requiring one variable to be sampled at a time, which increases computation time.</td>
      <td>MLE: Trained using Maximum Likelihood Estimation, directly optimizing the likelihood of sequentially modeled variables.</td>
      <td>None: Does not use latent variables; it explicitly models the observed data.</td>
      <td>Sequential: Processes data one variable at a time, reflecting the sequential dependency structure of the model.</td>
    </tr>
    <tr>
      <td><strong>Flows</strong></td>
      <td>Exact, slow/fast: Exact computation of $p(x)$, but speed depends on the specific normalizing flow architecture and its invertible transformations.</td>
      <td>Slow: Sampling involves applying invertible transformations, which can be computationally expensive depending on the model.</td>
      <td>MLE: Trained using Maximum Likelihood Estimation by directly optimizing the likelihood of the transformed data.</td>
      <td>$\mathbb{R}^D$: Latent representations are central, as flows map data to and from latent space using invertible transformations.</td>
      <td>Invertible: Uses invertible transformations to map between data and latent space, ensuring exact density computation.</td>
    </tr>
    <tr>
      <td><strong>EBM</strong>, <br />i.e., Energy Based Models</td>
      <td>Approx, slow: Density estimation is approximate due to the need to compute a complex energy-based objective, which is computationally expensive.</td>
      <td>Slow: Sampling often relies on expensive iterative methods like Langevin Dynamics to generate samples.</td>
      <td>MLE-A: Trained using approximate Maximum Likelihood Estimation due to challenges in normalizing the energy function.</td>
      <td>Optional: Latent variables can be included but are not essential for energy-based models.</td>
      <td>Discriminative: Models the energy function to differentiate between observed and unobserved data rather than direct probabilities.</td>
    </tr>
    <tr>
      <td><strong>Diffusion</strong></td>
      <td>LB: Provides a <strong>lower bound</strong> on likelihood during training by modeling a sequence of forward and reverse processes.</td>
      <td>Slow: Sampling involves iterative denoising steps (e.g., reversing the diffusion process), which is computationally intensive.</td>
      <td>MLE-LB: Trained by maximizing a lower bound on the likelihood, optimizing the reconstruction of data from corrupted inputs.</td>
      <td>$\mathbb{R}^D$: Latent representations are central, as the diffusion process maps data into progressively noisier latent spaces.</td>
      <td>Encoder-Decoder: Uses an encoder to add noise to data (diffusion) and a decoder to reverse the process (denoising).</td>
    </tr>
    <tr>
      <td><strong>GAN</strong>, <br />i.e., Generative Adversarial Networks</td>
      <td>NA: Does not explicitly model the density $p(x)$; instead, it learns to generate data by adversarial training.</td>
      <td>Fast: Sampling is efficient, as the generator directly maps random noise to generated data in one forward pass.</td>
      <td>Min-max: Trained using adversarial training, where a generator and discriminator compete to improve data generation.</td>
      <td>$\mathbb{R}^L$: Latent representations (e.g., random noise vectors) are central to generating data.</td>
      <td>Generator-Discriminator: Combines a generator (to create data) and a discriminator (to evaluate its realism).</td>
    </tr>
  </tbody>
</table>

<h2 id="2-goals-of-generative-ai">2 Goals of Generative AI</h2>

<ol>
  <li><strong>Data Generation</strong>: One of the primary goals of generative AI is <strong>data generation</strong>, where models create new data samples that resemble the original data they were trained on. This includes generating realistic images, text, audio, or other forms of data. Generative AI is also used for various tasks, such as:
    <ul>
      <li><strong>Creating synthetic data</strong> for training discriminative models.</li>
      <li><strong>Conditional generation</strong> to control outputs based on specific inputs, enabling applications such as:
        <ul>
          <li>Text-to-image (e.g., generating an image from a text description).</li>
          <li>Image-to-text (e.g., image captioning).</li>
          <li>Image-to-image (e.g., colorization, inpainting, uncropping, and restoration).</li>
          <li>Speech-to-text (e.g., automatic speech recognition or ASR).</li>
          <li>Sequence-to-sequence (e.g., machine translation or text continuation).</li>
        </ul>
      </li>
    </ul>

    <p>The difference between conditional generative models and discriminative models lies in the outputs: generative models allow multiple valid outputs, whereas discriminative models assume a single correct output.</p>
  </li>
  <li><strong>Density estimation</strong>: Generative models are useful for calculating the probability of observed data, $p(x)$, which is known as density function. This has applications in: 
    <ul>
      <li><strong>Outlier detection</strong>: Identifying data points with low probability under the estimated distribution, which may indicate anomalies or rare events. </li>
      <li><strong>Data compression</strong>: Using the probability distribution to represent data more efficiently by assigning shorter codes to more likely outcomes.</li>
      <li><strong>Generative classification</strong>: Classifying data by estimating class-conditional densities $p(x\vert c)$ and combining them with prior probabilities to make decisions.</li>
      <li>
        <p><strong>Model comparison</strong>: Evaluating and comparing different models by analyzing how well they represent the observed data distribution.</p>

        <p>Simple methods like kernel density estimation (KDE) are effective in low dimensions, using kernels (e.g., uniform or Gaussian) to estimate $p(x\vert \mathcal{D})$ based on observed data $\mathcal{D}$. However, KDE faces challenges in high dimensions due to the curse of dimensionality, requiring the use of parametric models  $p_\theta(x)$ for efficient and scalable density estimation.</p>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>Missing Data Imputation</strong>: missing values in a dataset are filled in using probabilistic methods. For example, a simple approach like mean value imputation replaces missing values with the average of observed values for each feature but ignores dependencies between variables. A more advanced method involves fitting a generative model to the observed data  $p(X_o)$ and sampling missing values conditioned on the observed data $p(X_m \vert X_o)$. This approach, called multiple imputation, can handle complex data types, such as filling in missing pixels in images (in-painting). Generative models provide a more robust solution by capturing variable dependencies and offering uncertainty estimates for the imputed values.</p>
  </li>
  <li>
    <p><strong>Structure Discovery</strong>: Generative models with latent variables can uncover hidden patterns or structures in data by inferring the latent causes $z$ that generate observed data $x$ using Bayes’ rule $p(z\vert x) \propto p(z)p(x\vert z)$. For example, in social network analysis, a generative model can represent each user’s behavior and interactions using latent variables $z$  that correspond to hidden community memberships or shared interests. By applying Bayes’ rule, the model can infer these latent communities $z$ from observed interaction patterns $x$, revealing the underlying structure of the network and grouping users with similar behaviors or preferences.</p>
  </li>
  <li>
    <p> <strong>Latent Space Interpolation</strong>: Generative models with latent variable representations enable <strong>latent space interpolation</strong>, where new data is generated by smoothly blending features between existing data points. For example, given two images, their latent encodings $z_1$ and$ z_2$ can serve as anchors in the latent space. By interpolating linearly between these encodings $z = \lambda z_1 + (1-\lambda)z_2$ and decoding the results, the model generates images combining characteristics of both inputs, such as transitioning between two digits or blending facial attributes. Additionally, <strong>latent space arithmetic</strong> allows modifying specific attributes. For example, in a model trained on celebrity faces, adding a learned offset vector for “sunglasses” to a latent encoding can generate a version of the face with sunglasses, while subtracting the vector can remove them. These techniques make latent spaces powerful for generating and manipulating data with meaningful variations.</p>
  </li>
  <li>
    <p><strong>Generative Design</strong>: Generative models are used to explore designs with specific properties. For example, in material science, a model trained on molecular data can generate new chemical structures optimized for properties like higher conductivity or stability by searching the latent space.</p>
  </li>
  <li>
    <p><strong>Model-Based Reinforcement Learning</strong>: Generative models simulate environments, such as robotics tasks, enabling agents to practice and plan in virtual settings, reducing reliance on expensive real-world data collection.</p>
  </li>
  <li>
    <p><strong>Representation Learning</strong>: Generative models learn compact latent representations $z$ that capture the underlying structure of data. For example, a model trained on medical images can extract features like the presence of tumors, which can then be used for tasks like diagnosis or prediction.</p>
  </li>
  <li><strong>Data Compression</strong>: Generative models predict the probability of data patterns and assign shorter codes to frequent patterns, enabling efficient storage and transmission of data, as described by Shannon’s information theory.</li>
</ol>

<h2 id="3-evaluating-generative-models">3 Evaluating generative models</h2>

<p>The generative AI models are evaluated on three aspects</p>
<ol>
  <li><strong>Sample Quality</strong>: Do the generated examples look realistic and belong to the same type of data as the training set?</li>
  <li><strong>Sample Diversity</strong>: Do the generated examples represent all the different variations present in the real data?</li>
  <li><strong>Generalization</strong>: Can the model create new examples that go beyond simply memorizing the training data?</li>
</ol>

<p>No single metric captures all above, we use different metrics for each or combine parts.</p>

<h3 id="31-likelihood-based-evaluation">3.1 Likelihood-based evaluation</h3>

<p>To evaluate how well a generative model $q$ matches the true data distribution $p$, <strong>KL Divergence</strong> is a commonly used metric:</p>

\[D_{KL}(p \parallel q) = \int p(x) \log \frac{p(x)}{q(x)} dx = \int p(x) \log p(x) \, dx - \int p(x) \log q(x) \, dx = - H(p) + H_{ce}(p, q)\]

<p>The $D_{KL}$ measures the <em>distance</em> between the two distributions. Smaller value indicates that the model closely approximates the true data distribution. The first term on the RHS is the <strong>entropy</strong> of $p(x)$, denoted as $H(p)$. Since $H(p)$ depends only on the true distribution $p(x)$, it is a constant when evaluating the model $q(x)$. The second term is the <strong>cross-entropy</strong> between $p(x)$ and $q(x)$, denoted as $H_{ce}(p, q)$.</p>

<p>Minimizing $D_{KL}(p \parallel q)$ is equivalent to minimizing the cross-entropy $H_{ce}(p, q)$ (note that the entropy term,  $H(p)$, is constant and does not depend on $q$).</p>

<p>Given an empirical observed dataset $\mathcal{D} = {x_1, x_2, \dots, x_N}$, we can approximate $p(x)$ with the empirical data distribution,  $p(x) = \frac{1}{N} \sum_{i=1}^N \delta (x-x_i)$,  where $x_i$ is the $i$th observed data, and $\delta(.)$ is the Dirac’s delta function. The cross-entropy then becomes:</p>

\[H_{ce}(p, q) = -\frac{1}{N} \sum_{n=1}^{N} \log q(x_n)\]

<p>This is known as the <strong>Negative Log Likelihood (NLL)</strong>.</p>

\[\text{NLL} = -\frac{1}{N} \sum_{n=1}^{N} \log q(x_n)\]

<p>Key Insights:</p>
<ul>
  <li>
    <p><strong>NLL and Cross-Entropy</strong>: The NLL represents the average penalty for the model $q(x)$ assigning probabilities to observed data points in a dataset.</p>
  </li>
  <li>
    <p><strong>Test Set Evaluation</strong>: NLL is typically computed on a held-out test set to measure the model’s generalization ability.</p>
  </li>
  <li>
    <p><strong>Entropy</strong> $H(p)$: Since entropy is a constant with respect to the model $q(x)$, it does not affect optimization when training the model.</p>
  </li>
</ul>

<h4 id="311-nll-and-perplexity">3.1.1 NLL and perplexity</h4>

<p>For models of discrete data, such as language models, <strong>Negative Log Likelihood (NLL)</strong> is a straightforward way to measure how well the model predicts the data. NLL evaluates the average “surprise” the model experiences when it encounters the actual outcomes in the dataset, based on the probabilities it assigns to them. The term “surprise” refers to how unexpected an event is, given the model’s prediction. If the model assigns a high probability to the correct outcome, the surprise (and NLL) is low. Conversely, if the model assigns a low probability, the surprise is high, reflecting the model’s uncertainty.</p>
<ul>
  <li>
    <p><strong>Example:</strong>	
 Suppose a language model predicts the next word in the sentence “The cat sat on the __” with the following probabilities:</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> $$q(\text{“mat”}) = 0.6, \quad q(\text{“floor”}) = 0.3, \quad q(\text{“table”}) = 0.1$$
</code></pre></div>    </div>

    <p>If the correct word is “mat,” the NLL for this prediction is simply:</p>

\[\text{NLL} = -\log_2(q(\text{“mat”})) = -\log_2(0.6) \approx 0.737\]

    <p>The NLL for a dataset averages these values across all predictions, measuring how well the model predicts the actual words.</p>
  </li>
</ul>

<p>Interpreting NLL directly can be unintuitive. To make it easier to understand, <strong>perplexity</strong> is used. Perplexity translates NLL into a measure that reflects how “confused” the model is—essentially, the average number of equally likely choices the model is effectively guessing from.</p>
<ul>
  <li>
    <p><strong>Why Does Perplexity Represent Choices?</strong>: If a model has a perplexity of $P$, it behaves as if it is guessing from $P$ equally likely options. This comes from the relationship between NLL and uniform distributions: for $P$ equally likely outcomes, $q(x) = 1/P$, and the NLL is:</p>

\[\text{NLL} = -\log_2(1/P) = \log_2(P)\]

    <p>Inverting this gives \(P = 2^{\text{NLL}}\)</p>
  </li>
</ul>

<p>Mathematically, perplexity is defined as:
  \(\text{Perplexity} = 2^H\)</p>

<p>where $H = \text{NLL}$. Lower perplexity indicates better performance, as the model is less “confused” and more confident in its predictions.</p>

<h5 id="3111-more-about-kl-divergence">3.1.1.1 More about KL divergence</h5>

<p>The KL Divergence is defined as:</p>

\[D_{KL}(p \parallel q) = \int p(x) \log \frac{p(x)}{q(x)} dx\]

<p>This measures the average difference in log probabilities between the true distribution $p(x)$ and the model distribution $q(x)$, weighted by $p(x)$. Two interpretations:</p>
<ol>
  <li><strong>Information Loss</strong>: $D_{KL}$ quantifies how much information is lost when $q(x)$(the model) is used to approximate $p(x)$ (the ground truth): In information theory, the information content (or “surprise”) of an event $x$ occurring under a probability distribution $p(x)$ is given by $-\log p(x)$. So $D_{KL}$ is the information difference when we use the model $q(x)$ instead of true model $p(x)$, i.e.,  $-\log q(x) - (-\log p(x))$, weighted and averaged by the by $p(x)$.</li>
  <li><strong>Encoding</strong>: How inefficient is it to encode samples from $p(x)$ using a code optimized for $q(x)$: In information theory, the length of a code for an event $x$ is proportional to $-\log p(x)$, minimizing the average code length (Shannon’s Source Coding Theorem). If you use a code based on $q(x)$ instead of $p(x)$, the expected length of the code will increase. The extra cost per event is: $\log \frac{p(x)}{q(x)} = \log p(x) - \log q(x)$. Then, the expected extra cost is the KL divergence: $D_{KL}(p \parallel q) = \int p(x) \big[\log p(x) - \log q(x)\big] dx$.</li>
</ol>

<h4 id="312-handling-continuous-data">3.1.2 Handling Continuous Data:</h4>

<p>In image and audio data, we have the following challenge with likelihood:</p>

<ul>
  <li>The <strong>model</strong> typically represents the data using a <strong>continuous probability density function (PDF)</strong> $p(x)$, where $x$ can take any real value.</li>
  <li>However, the <strong>data</strong> itself is discrete (e.g., pixel intensities are integers from 0 to 255).</li>
</ul>

<p>Since a PDF can take values greater than 1, the average log-likelihood for discrete data can become arbitrarily large, making direct evaluation difficult. To address this, <strong>uniform dequantization</strong> is used.</p>

<h5 id="3121-dequantization-when-handling-continuous-data">3.1.2.1 Dequantization when handling Continuous Data</h5>

<p>Dequantization is a method used in probabilistic modeling to handle discrete data (e.g., pixel intensities $0–255$) with continuous probability density functions (PDFs), such as in image and audio models. Directly modeling discrete data with continuous PDFs can lead to degenerate solutions where arbitrarily high likelihoods are assigned to discrete points. To mitigate this, uniform random noise is added to discrete values, transforming them into continuous values. This process avoids undefined densities and provides a lower bound for the discrete log-likelihood. Following are steps to take</p>

<ul>
  <li><strong>Input</strong>: Pixel values in ${0, 1, …, 255}$.</li>
  <li><strong>Dequantization</strong>:
    <ul>
      <li>Add uniform noise: $z = x + \mathcal{U}(0, 1)$.</li>
      <li>Normalize: $z = z / 256$, resulting in $z \in [0, 1]$.</li>
    </ul>
  </li>
  <li><strong>Flow Transformations</strong>:
    <ul>
      <li>Apply transformations like sigmoid scaling: $z = \sigma^{-1}\left(\frac{z - 0.5\alpha}{1 - \alpha}\right)$, mapping data from $[0, 1]$ to $(-\infty, \infty)$.</li>
      <li>Use flow layers (e.g., affine coupling layers) to map $z$ to a latent Gaussian space.</li>
    </ul>
  </li>
  <li><strong>Training Objective</strong>:
    <ul>
      <li>
        <p>Maximize likelihood: 
  $\log p(x) \geq \mathbb{E}_{q(z\vert x)} \left[\log p(z) - \log q(z\vert x)\right]$</p>

        <p>Proof:</p>

        <p>$p(x) = \int p(x\vert z)p(z)dz = \int q(z\vert x) \frac{p(x\vert z)p(z)}{q(z\vert x)}dz$</p>

        <table>
          <tbody>
            <tr>
              <td>$\log p(x) = \log \int q(z</td>
              <td>x) \frac{p(x</td>
              <td>z)p(z)}{q(z</td>
              <td>x)} \, dz$</td>
            </tr>
          </tbody>
        </table>

        <p>Jensen’s inequality states that for a convex function $f$  is</p>

        <p>$f\left(\mathbb{E}[X]\right) \leq \mathbb{E}[f(X)]$</p>

        <p>Since the logarithm is a concave function, we can apply Jensen’s inequality:</p>

        <p>$\log p(x) \geq \int q(z\vert x) \log \frac{p(x\vert z)p(z)}{q(z\vert x)} \, dz$</p>

        <p>Expand the term inside the logarithm:</p>

        <p>$\int q(z\vert x) \log \frac{p(x\vert z)p(z)}{q(z\vert x)} \, dz = \int q(z\vert x) \left[\log p(x\vert z) + \log p(z) - \log q(z\vert x)\right] \, dz$</p>

        <table>
          <tbody>
            <tr>
              <td>The first term, $\log p(x\vert z)$, integrates to zero because $p(x\vert z) = \delta(x - \text{round}(z))$, and $q(z</td>
              <td>x)$ is only defined over valid $z$. As a result</td>
            </tr>
          </tbody>
        </table>

        <p>$\log p(x) \geq \mathbb{E}_{q(z\vert x)} \left[\log p(z) - \log q(z\vert x)\right]$</p>

        <p><strong>The prior likelihood term</strong>: $\log p(z)$ encourages the latent variable $z$ (the output of the flow transformations applied to the input $x$) to follow a predefined distribution, such as a Gaussian.
  <strong>The dequantization likelihood term</strong>: $-\log q(z\vert x)$ models the distribution $q(z\vert x)$, which is the distribution of the dequantized variable $z$ given the discrete input $x$.</p>
      </li>
    </ul>
  </li>
</ul>

<h4 id="313-likelihood-can-be-hard-to-compute">3.1.3 Likelihood can be hard to compute</h4>

<p>In many generative models, we want to compute the <strong>likelihood</strong>  $p(x)$ , which tells us how well the model explains the data  $x$. Computing  $p(x)$  often requires evaluating a <strong>normalization constant</strong></p>

<p>$p(x) = \frac{\tilde{p}(x)}{Z}, \quad Z = \int \tilde{p}(x) dx$</p>

<p>where $\tilde{p}(x)$  is an unnormalized probability, and  $Z$  ensures the total probability integrates to $1$. Computing  $Z$  involves an integral over the entire data space, which can be very expensive, especially for high-dimensional data (e.g., images or text).</p>

<h5 id="3131-example">3.1.3.1 Example</h5>

<p>In a model with latent variables  $z$ , $ p(x)$  is computed as:</p>

<p>$p(x) = \int p(x\vert z)p(z) dz$</p>

<p>This requires integrating over all possible  $z$ , which can be computationally infeasible for complex models. We basically need to find all $z$ that result in that generated data $x$.</p>

<h5 id="3132-solution-1-variational-inference">3.1.3.2 Solution 1: <strong>Variational Inference</strong></h5>

<p><strong>Variational Inference (VI)</strong> is a technique to approximate  $p(x)$  without explicitly calculating the normalization constant. It introduces a simpler distribution $q(z\vert x)$  to approximate the true posterior  $p(z\vert x)$. Instead of directly computing  $\log p(x)$ , we compute a <strong>lower bound</strong> (called the ELBO):</p>

<p>We start with:
$p(x) = \int p(x, z) \, dz =  \int q(z|x) \frac{p(x, z)}{q(z\vert x)} \, dz$</p>

<p>Applying Jenson’s inequality;</p>

<p>$\log p(x) = \log \int q(z\vert x) \frac{p(x, z)}{q(z\vert x)} \, dz \geq \int q(z\vert x) \log \frac{p(x, z)}{q(z\vert x)} \, dz$</p>

<p>Noting that:</p>

<p>$\log \frac{p(x, z)}{q(z\vert x)} = \log p(x\vert z) + \log p(z) - \log q(z\vert x)$</p>

<p>We find</p>

<p>$\log p(x) \geq \int q(z\vert x) \log p(x\vert z) \, dz + \int q(z\vert x) \log p(z) \, dz - \int q(z\vert x) \log q(z\vert x) \, dz$</p>

<p>Apply the KL Divergence</p>

<p>$\text{KL}(q(z\vert x) | p(z)) = \int q(z\vert x) \log \frac{q(z\vert x)}{p(z)} \, dz$</p>

<p>Final ELBO</p>

<p>$\log p(x) \geq \mathbb{E}_{q(z\vert x)}[\log p(x\vert z)] - \text{KL}(q(z\vert x) | p(z))$</p>

<p>This avoids the expensive integral over  $z$  and allows us to optimize the model using the lower bound. In the ELBO expression above</p>
<ul>
  <li>$\mathbb{E}_{q(z\vert x)}[\log p(x\vert z)]$ : Encourages  $q(z\vert x)$  to explain the observed data well.</li>
  <li>$\text{KL}(q(z\vert x) | p(z))$ : Ensures $q(z\vert x)$  stays close to the prior  $p(z)$ , avoiding overfitting.</li>
</ul>

<p>For example, in Variational Autoencoders (VAEs), we:</p>
<ol>
  <li>Approximate the true posterior $p(z\vert x)$ with a simpler  $q(z\vert x)$ (like a Gaussian)</li>
  <li>Optimize the ELBO to train the model without computing the exact  $p(x)$</li>
</ol>

<h5 id="3133-solution-2-annealed-importance-sampling-ais">3.1.3.3 Solution 2: <strong>Annealed Importance Sampling (AIS)</strong></h5>

<p>In this method, we estimate the log likelihood using Monte Carlo sampling.</p>

<h4 id="314-likelihood-and-sample-quality">3.1.4 Likelihood and sample quality</h4>

<p>A model can achieve high likelihood but produce perceptually poor samples and vice versa. Likelihood alone is not a reliable indicator of the perceptual quality of generated samples.</p>

<h5 id="3141-example-of-high-likelihood-but-poor-samples">3.1.4.1 Example of High Likelihood but Poor Samples</h5>

<p>Consider the following</p>
<ul>
  <li>Model $q_0$: A good density model that performs well in terms of average log-likelihood.</li>
  <li>Model $q_1$: A bad model that generates white noise.
Now imagine a mixture model $q_2$
• Mixture Model $q_2$: Combines these models:
\(q_2(x) = 0.01q_0(x) + 0.99q_1(x)\)
This means 99% of the samples will be poor (from $q_1$). Since $q_1$ is coming from uniform distribution (white noise), and for high-dimensional data (like images with many pixels) it would be a very small number, so negligible in comparison with $q_0$, so we will have</li>
</ul>

<p>\(\log q_2(x) = \log[0.01q_0(x) + 0.99q_1(x)] \geq \log[0.01q_0(x)] = \log q_0(x) - 2\)
which would be a large log likelihood for $q_2$, however, the sample quality is pretty bad.</p>

<h5 id="3142-example-of-low-likelihood-but-great-sample-quality">3.1.4.2 Example of Low Likelihood but Great Sample quality</h5>

<p>Imagine a Gaussian Mixture Model defined as</p>

<p>\(q(x) = \frac{1}{N} \sum_{n=1}^{N} N(x \vert x_n, \epsilon^2 I)\)
The model consists of a mixture of <strong>N Gaussians</strong>. Each <strong>Gaussian</strong>  $N(x \vert x_n, \epsilon^2 I)$  is centered on a training image  $x_n$ . Note that $\epsilon^2 I$  represents small Gaussian noise added around each training image. If  $\epsilon$  <strong>is very small</strong>, each Gaussian is tightly concentrated around the training images. This means that when we <strong>sample from this model</strong>, we get images that are <strong>almost identical to training images</strong>. <strong>Perceptually</strong>, the generated samples look great because they resemble real training images. Likelihood measures <strong>how well the model generalizes to new data</strong>. In this case, since the model is just a bunch of Gaussians centered on training images, its density function will <strong>assign high probability to training images.</strong> and <strong>assign very low probability to test images,</strong> which means <strong>poor likelihood on the test set</strong>.</p>

<h3 id="32-perceptual-metrics">3.2 Perceptual Metrics</h3>

<p>Evaluating generative models (like GANs and VAEs) is challenging because traditional metrics like likelihood do not always reflect the perceptual quality of generated images. Instead of directly comparing raw pixel values, researchers use <strong>perceptual distance metrics</strong>, which compare feature representations of real and generated images. These features are extracted using neural networks, often from <strong>pretrained classifiers</strong> like the Inception model.</p>

<p>(A) <strong>Inception Score (IS)</strong>: This score measures how well a generative model produces diverse and recognizable images. It uses a classifier (like the Inception network) to predict class labels for generated images.</p>

\[IS = \exp (E_{p_\theta(x)} D_{KL} (p_{\text{disc}}(Y \vert x) \parallel p_\theta(Y)))\]

<p>where:</p>
<ul>
  <li>$p_\theta(x)$  is the probability distribution of images generated by the model.</li>
  <li>$p_{\text{disc}}(Y \vert x)$  is the probability distribution over class labels <strong>given an image</strong>  $x$ . This is obtained from a <strong>pretrained classifier</strong> (like Inception).</li>
  <li>$p_\theta(Y)$  is the <strong>marginal class distribution</strong> of generated images:
\(p_\theta(y) = \int p_{\text{disc}}(y \vert x) p_\theta(x) dx\)</li>
</ul>

<p>What is the Inception Score (IS) trying to do?</p>

<p>The Inception Score is trying to answer two questions about the images generated by a model:</p>
<ol>
  <li><strong>Are the generated images clear and recognizable?</strong> (Do they belong to a specific class with high confidence?)</li>
  <li><strong>Are the generated images diverse?</strong> (Do they cover a wide range of different classes?)</li>
</ol>

<p>To measure this, it <strong>compares two distributions</strong>:</p>
<ul>
  <li>$p_{\text{disc}}(Y \vert x)$  -&gt; This is the <strong>classifier’s prediction</strong> for a generated image  $x$ . It tells us how confident the classifier is that the image belongs to a certain class (e.g., “cat” or “dog”).</li>
  <li>$p_\theta(Y)$  -&gt; This is the <strong>overall distribution of generated class labels</strong> across many images. It tells us whether the model is generating a balanced mix of different classes.</li>
</ul>

<p>The score is calculated using <strong>KL divergence</strong>, which measures how different these two distributions are. This happens in two steps</p>
<ol>
  <li><strong>Check if each image belongs to a clear class.</strong> –&gt; If an image is confidently recognized as a <strong>specific</strong> class (e.g., “cat” with 99% probability), it is a <strong>high-quality sample</strong>. If an image is blurry or unrecognizable, the classifier will be <strong>uncertain</strong> which is <strong>bad</strong>.</li>
  <li><strong>Check if the model generates a variety of different classes.</strong>: If the model generates <strong>only cats</strong>, it is <strong>not diverse</strong>, which is <strong>bad</strong>. If the model generates a <strong>mix of different animals</strong>, it is <strong>diverse</strong>, which is <strong>good</strong>.</li>
  <li>Combining the above two: <strong>KL divergence compares how different the per-image class prediction</strong>  $p_{\text{disc}}(Y \vert x)$  <strong>is from the overall class distribution</strong>  $p_\theta(Y)$ <strong>.</strong> If the two distributions are very different, it means the images are <strong>recognizable and diverse</strong>, which gives a <strong>high score</strong>. If the distributions are similar, it means the images are <strong>blurry or all from the same class</strong>, which gives a <strong>low score</strong>.</li>
</ol>

<p>This can also be seen with a bit of derivation. The KL divergence in the inception score can be written as 
	\(D_{KL} (p_{\text{disc}}(Y \vert x) \parallel p_\theta(Y)) = \sum_y p_{\text{disc}}(y \vert x) \log \frac{p_{\text{disc}}(y \vert x)}{p_\theta(y)}\)</p>

<p>So the expected value is 
		\(E_{p_\theta(x)} D_{KL} (p_{\text{disc}}(Y \vert x) \parallel p_\theta(Y)) = \int p_\theta(x) \sum_y p_{\text{disc}}(y \vert x) \log \frac{p_{\text{disc}}(y \vert x)}{p_\theta(y)} dx\)</p>

<p>Rearranging, we obtain 
	\(E_{p_\theta(x)} D_{KL} (p_{\text{disc}}(Y \vert x) \parallel p_\theta(Y)) = \sum_y \int p_\theta(x) p_{\text{disc}}(y \vert x) \log \frac{p_{\text{disc}}(y \vert x)}{p_\theta(y)} dx\)</p>

<p>Note that $p_\theta(y) = \int p_{\text{disc}}(y \vert x) p_\theta(x) dx$. So the above would mean
		\(E_{p_\theta(x)} D_{KL} (p_{\text{disc}}(Y \vert x) \parallel p_\theta(Y)) = H(p_\theta(Y)) - E_{p_\theta(x)} [H(p_{\text{disc}}(Y \vert x))]\)</p>

<p>So in here</p>
<ul>
  <li>$H(p_\theta(Y))$ is the <strong>entropy of the marginal class distribution</strong>: <strong>High</strong>  $H(p_\theta(Y))$ <strong>(high marginal entropy) -&gt; Ensures diversity</strong></li>
  <li> $H(p_{\text{disc}}(Y \vert x))$  is the <strong>conditional entropy</strong> of class predictions per image: <strong>Low</strong>  $H(p_{\text{disc}}(Y \vert x))$  <strong>(low per-image entropy) -&gt; Ensures realism</strong></li>
</ul>

<p>This represents the overall class distribution of the generated images.
A high score means the model generates <strong>varied</strong> images across different classes (<strong>high entropy</strong> of predicted labels). Each individual image should be <strong>easily classifiable</strong> (low entropy per image). One big <strong>limitation</strong> is that it does not measure overfitting—if a model memorizes one perfect image per class, it can still score well.</p>

<p>(B) <strong>Fréchet Inception Distance (FID)</strong>: Instead of class labels, it compares statistical properties of deep features (mean and covariance) between real and generated images.</p>

\[FID = \|\mu_m - \mu_d\|^2_2 + \text{tr} (\Sigma_d + \Sigma_m - 2(\Sigma_d \Sigma_m)^{1/2})\]

<p>where</p>

<ul>
  <li>$\mu_m, \Sigma_m$  = Mean and covariance of generated images</li>
  <li>$\mu_d, \Sigma_d$  = Mean and covariance of real images</li>
</ul>

<p>Lower FID is better because it means generated images closely resemble real images in feature space. One <strong>limitation</strong> of this score is that it is sensitive to the number of samples used—results can vary due to statistical bias.</p>

<p>(C) <strong>Kernel Inception Distance (KID)</strong>: This score improves on FID by using <strong>Maximum Mean Discrepancy (MMD)</strong> to measure the similarity between distributions. This reduces bias issues in FID by comparing feature distributions more robustly. MMD measures the distance between two distributions <strong>without assuming they are Gaussian</strong>. Instead of just comparing the <strong>mean and covariance</strong> (like FID), MMD measures how well two sets of samples <strong>match</strong> using a <strong>kernel function</strong>.</p>

\[\text{MMD}^2(X, Y) = E[k(x, x{\prime})] + E[k(y, y{\prime})] - 2E[k(x, y)]\]

<p>where:
	* $X$  = set of features from real images.
	* $Y$  = set of features from generated images.
	* $k(x, y)$  = a kernel function that measures similarity (usually a <strong>polynomial or Gaussian kernel</strong>).
	* $E[k(x, x{\prime})]$  = similarity within real images.
	* $E[k(y, y{\prime})]$ = similarity within generated images.
	* $E[k(x, y)]$  = similarity between real and generated image</p>

<h3 id="33-precision-and-recall-metrics">3.3 Precision and recall metrics</h3>

<p>The <strong>Fréchet Inception Distance (FID)</strong> measures the <strong>distance between the real and generated data distributions</strong> but does <strong>not tell us why a model is failing</strong>. A <strong>bad (high) FID</strong> could mean:</p>
<ol>
  <li>The model <strong>produces low-quality samples</strong> (they don’t look realistic).</li>
  <li>The model <strong>places too much probability mass around the data distribution</strong>, meaning it only captures a limited part of the real data.</li>
  <li>The model <strong>only generates a subset of the real data</strong> (a problem called <strong>mode collapse</strong> in GANs).</li>
</ol>

<p>Precision (sample quality), and recall (sample diversity) are introduced to resolve this differentiation issue</p>
<ul>
  <li><strong>*Precision</strong> -&gt; Are generated samples <strong>high quality</strong> (similar to real data)?</li>
  <li>
    <ul>
      <li><strong>Recall</strong> -&gt; Is the <strong>diversity</strong> of generated samples good (does it cover the full real data distribution)?</li>
    </ul>
  </li>
</ul>

<p><strong>Precision and recall</strong> work by using a <strong>pretrained classifier</strong> (like Inception) to extract <strong>features</strong> of both real and generated images. Then, <strong>nearest neighbor distances</strong> are used to compare them. Let’s define the notation:</p>
<ul>
  <li>$\Phi_{\text{model}}$  = Set of feature vectors from generated images.</li>
  <li>$\Phi_{\text{data}}$  = Set of feature vectors from real images.</li>
  <li> $\text{NN}_k(\phi{\prime}, \Phi)$  = The  $k$-th nearest neighbor of  $\phi{\prime}$  in  $\Phi$  (used to measure how close a sample is to its nearest neighbors).</li>
</ul>

<p>To determine whether a generated image is <strong>close enough</strong> to real data, we define the function:</p>

\[f_k(\phi, \Phi) =

\begin{cases}

1, &amp; \text{if } \exists \phi{\prime} \in \Phi \text{ such that } \|\phi - \phi{\prime}\|_2^2 \leq \|\phi{\prime} - \text{NN}_k(\phi{\prime}, \Phi)\|_2^2 \\

0, &amp; \text{otherwise}

\end{cases}\]

<p>This function</p>
<ul>
  <li>checks whether a generated sample $ \phi$  is as <strong>close to real data as real data is to itself</strong></li>
  <li>if $\phi$  is <strong>close enough</strong> to any real data point  $\phi{\prime}$ , it is counted as <strong>a valid sample</strong>.</li>
</ul>

<p><strong>Precision (Sample Quality)</strong>: Precision tells us <strong>how many generated samples</strong> are close to real data.</p>

\[\text{precision}(\Phi_{\text{model}}, \Phi_{\text{data}}) = \frac{1}{|\Phi_{\text{model}}|} \sum_{\phi \in \Phi_{\text{model}}} f_k(\phi, \Phi_{\text{data}})\]

<ul>
  <li><strong>High precision</strong> means most generated images are <strong>high-quality</strong> and resemble real data.</li>
  <li><strong>Low precision</strong> means many generated images are <strong>not realistic</strong>.</li>
</ul>

<p><strong>Recall (Sample Diversity)</strong>: Recall tells us <strong>whether real data points are well represented</strong> by the model.</p>

\[\text{recall}(\Phi_{\text{model}}, \Phi_{\text{data}}) = \frac{1}{|\Phi_{\text{data}}|} \sum_{\phi \in \Phi_{\text{data}}} f_k(\phi, \Phi_{\text{model}})\]

<ul>
  <li><strong>*High recall</strong> means the model generates <strong>a diverse set of samples that cover all real data</strong>.</li>
  <li><strong>Low recall</strong> means the model <strong>misses</strong> important variations in the real dataset (<strong>mode collapse</strong>).</li>
</ul>

<p>Now with precision and recall we can separate between the issues that the generative model has. For example, in <strong>GANs</strong>, <strong>mode collapse</strong> happens when the model only generates a <strong>few types of images</strong>.</p>
<ul>
  <li><strong>*High precision but low recall</strong> = The GAN generates <strong>very realistic but repetitive</strong> images (e.g., only faces of young white males).</li>
  <li><strong>Low precision but high recall</strong> = The GAN generates <strong>a wide variety of images, but many are blurry</strong>.</li>
</ul>

<h3 id="34-statistical-tests">3.4 Statistical Tests</h3>

<p>A <strong>two-sample test</strong> is a <strong>statistical method</strong> used to determine whether two datasets (sets of samples) come from the <strong>same underlying distribution</strong>.</p>
<ul>
  <li><strong>*Null Hypothesis (</strong> $H_0$ <strong>)</strong>: The two sets of samples come from the <strong>same</strong> distribution.</li>
  <li><strong>Alternative Hypothesis (</strong> $H_A$ <strong>)</strong>: The two sets of samples come from <strong>different</strong> distributions.</li>
</ul>

<p>For example, in <strong>Generative Adversarial Networks (GANs)</strong> and other generative models, we want to check:</p>
<ol>
  <li><strong>Are the generated samples statistically similar to real data?</strong></li>
  <li><strong>How different is the model’s output from real data?</strong></li>
</ol>

<p>To do this, we apply two-sample tests using:</p>
<ol>
  <li><strong>Classifier-based statistics</strong> -&gt; Train a classifier to distinguish real vs. generated images.</li>
  <li><strong>Maximum Mean Discrepancy (MMD)</strong> -&gt; A kernel-based test to compare distributions.</li>
</ol>

<p>Since <strong>deep learning works with high-dimensional data</strong> (e.g., images with millions of pixels), two-sample tests often use <strong>learned feature representations</strong> (from pretrained networks like Inception) instead of comparing raw pixel values.</p>

<p>Statistical tests let users control <strong>Type 1 error</strong> ( $\alpha$ ), which is <strong>the probability of wrongly rejecting the null hypothesis</strong> (i.e., concluding that the samples are different when they are actually from the same distribution).</p>

<h3 id="35-maximum-likelihood-estimation-mle-for-generative-models">3.5 Maximum Likelihood Estimation (MLE) for Generative Models</h3>

<p>MLE is a <strong>statistical method</strong> used to train probabilistic models by <strong>maximizing the likelihood</strong> of observed data under the model’s distribution. For a dataset with samples  $x \sim p(x)$ , where:</p>
<ul>
  <li>$p(x)$  is the <strong>true data distribution</strong> (which we want to approximate).</li>
  <li>$q(x)$  is the <strong>model distribution</strong> (which we are learning).</li>
</ul>

<p>The objective in MLE is:</p>

\[\max_q \mathbb{E}_{p(x)} [\log q(x)]\]

<p>which means adjusting  $q(x)$  to <strong>maximize the log-likelihood</strong> of real data. <strong>Why MLE is Equivalent to Minimizing KL Divergence?</strong> We can rewrite the MLE objective using the <strong>Kullback-Leibler (KL) divergence</strong>:</p>

\[\mathbb{E}{p(x)} [\log q(x)] = - D{\text{KL}}(p \parallel q) + \text{const}\]

<p>where:</p>

\[D_{\text{KL}}(p \parallel q) = \mathbb{E}_{p(x)} \left[ \log \frac{p(x)}{q(x)} \right]\]

<p>Since the constant term does not depend on  $q$ , <strong>MLE is equivalent to minimizing</strong>  $D_{\text{KL}}(p \parallel q)$. <strong>KL divergence measures how different</strong>  $q(x)$  <strong>(the learned model) is from</strong>  $p(x)$  <strong>(the real data distribution).</strong> MLE <strong>pulls</strong>  $q(x)$  <strong>towards</strong> $ p(x)$  so that the model generates realistic samples.</p>

<ul>
  <li><strong>*Advantage of MLE</strong>: It ensures that  $q(x)$  does not ignore any part of  $p(x)$ , avoiding <strong>mode collapse</strong> (a common issue in GANs).</li>
  <li><strong>Limitation</strong>: It can fail when  $p(x)$  <strong>lies on a low-dimensional manifold within a high-dimensional space</strong>.</li>
</ul>

<p><strong>What is the Manifold Hypothesis?</strong> The <strong>manifold hypothesis</strong> states that <strong>real-world high-dimensional data (e.g., images, text, speech) actually lies on a much lower-dimensional manifold embedded in the full space</strong>. Formally:</p>

<ul>
  <li>Real data  $x$  lives in a <strong>subspace</strong>  $\mathcal{M}$  of dimension  $d^*$  (<strong>low-dimensional</strong>).</li>
  <li>The surrounding space  $\mathbb{R}^D$ (<strong>ambient space</strong>) has dimension  $D$ , where  $d^* &lt; D$</li>
  <li>Probability mass is <strong>concentrated only on</strong>  $\mathcal{M}$ <strong>, not the entire</strong> $\mathbb{R}^D$ .</li>
</ul>

<p>For example, a 1,000 × 1,000 pixel grayscale image technically lives in a <strong>1,000,000-dimensional space</strong>. However, not all <strong>possible pixel combinations</strong> form valid images. Real images exist in a much lower-dimensional manifold within this huge space.</p>

<p><strong>Why Does MLE Fail in This Case?</strong> MLE assumes  $p(x)$  is <strong>defined everywhere in</strong>  $\mathbb{R}^D$. But <strong>in reality,</strong>  $p(x) &gt; 0$  <strong>only on</strong>  $\mathcal{M}$ , making MLE problematic. As a result, the Likelihood Objective is Ill-Defined.  MLE maximizes:</p>

\[\mathbb{E}_{p(x)} [\log q(x)]\]

<p>For this to be well-defined:</p>
<ul>
  <li>$q(x)$  must be <strong>nonzero</strong> everywhere that  $p(x)$  is nonzero. Note that, if $p(x)$ is non-zero, then $q(x)$ should be non-zero, otherwise, the above expectation becomes ill-defined or large.</li>
  <li>If  $q(x)$  is defined over the full  $\mathbb{R}^D$ , it <strong>fails to properly learn the structure of</strong>  $\mathcal{M}$ . If $q(x)$ is not defined everywhere (and is only defined over data), then the generative model does not generalizes.</li>
</ul>

<h4 id="351-three-solutions-to-mle-failure-in-high-dimensional-data">3.5.1 Three Solutions to MLE Failure in High-Dimensional Data</h4>

<p>Three solutions address this problem:</p>
<ol>
  <li>(A)  <strong>Adding Noise (Diffusion Models, Spread KL Divergence)</strong></li>
  <li>(B) <strong>Using Alternative Divergences (Wasserstein Distance, MMD, GANs)</strong></li>
  <li>(C) <strong>Two-Step Methods (Autoencoders + Latent Space Learning)</strong></li>
</ol>

<p>Each method <strong>modifies the training objective or the model structure</strong> to handle the mismatch between  $p(x)$  and  $q(x)$.</p>

<p>(A) <strong>Adding Noise to Fill the Space</strong>: Since real data  $p(x)$  only exists on a <strong>thin manifold</strong>, the likelihood objective is problematic because  $q(x)$  is defined over the full space. <strong>A simple fix</strong> is to <strong>add noise</strong> to the data, artificially expanding the distribution to fill  $\mathbb{R}^D$. Instead of working directly with  $p(x)$  and  $q(x)$, we define <strong>smoothed versions</strong> by convolving them with a Gaussian:</p>

\[p_\sigma = p \ast \mathcal{N}(0, \sigma^2 I_D), \quad q_\sigma = q \ast \mathcal{N}(0, \sigma^2 I_D)\]

<p>Then, we redefine <strong>KL divergence</strong> as:
\(D_{\text{KL}, \sigma}(p || q) = D_{\text{KL}}(p_\sigma || q_\sigma)\)</p>

<p>Since  $p_\sigma$  and  $q_\sigma$ now have <strong>support over the full space</strong>, KL divergence is always finite. Examples of such implementations are</p>
<ol>
  <li><strong>Diffusion Models</strong>: Add noise at various levels and learn to <strong>reverse the diffusion process</strong> (denoising).</li>
  <li>
    <table>
      <tbody>
        <tr>
          <td><strong>Delta-VAE (Latent Variable Model with Noise Injection)</strong>: $q(x) = \mathcal{N}(x</td>
          <td>g_\theta(z), \sigma^2 I)$, where  $g_\theta(z)$  is a <strong>decoder</strong>, and  $z \sim \mathcal{N}(0, I_d)$ is a low-dimensional latent variable. During training, the model <strong>includes noise</strong> to ensure proper likelihood calculation. After training, noise is “turned off,” ensuring the model correctly learns the data manifold.</td>
        </tr>
      </tbody>
    </table>
  </li>
</ol>

<p>(B) <strong>Using Alternative Divergences Instead of KL</strong>: The problem with KL divergence is that it <strong>penalizes missing support harshly</strong> (assigning infinite loss). Some divergences <strong>do not require overlapping supports</strong>, making them better suited for generative modeling. Two <strong>alternative divergences</strong> are</p>

<ol>
  <li><strong>Wasserstein Distance (Optimal Transport)</strong>: Measures the <strong>minimal cost of transporting mass from</strong>  $p(x)$  <strong>to</strong>  $q(x)$ . More stable than KL and does not require absolute density matching. Used in <strong>Wasserstein GANs (WGANs)</strong>.</li>
  <li><strong>Maximum Mean Discrepancy (MMD)</strong>: Measures the <strong>distance between distributions in feature space</strong> using kernel methods. Useful for non-adversarial generative models.</li>
</ol>

<p>(C) <strong>Two-Step Methods (Learning the Manifold + Density Estimation)</strong>: Instead of <strong>modeling</strong>  $p(x)$  <strong>in</strong>  $\mathbb{R}^D$  <strong>directly</strong>, we first <strong>learn the lower-dimensional latent manifold</strong>  $\mathcal{M}$ , then estimate a probability distribution in this space. Train an <strong>autoencoder</strong> to map data to a lower-dimensional space:</p>

\[z = f_\phi(x), \quad x = g_\theta(z)\]

<p>The encoder  $f_\phi$  learns a <strong>compressed representation</strong>  $z$  in a space  $\mathbb{R}^d$ , where  $d \ll D$ . Then, define a probability distribution over  $z$ :</p>

\[q_\theta(z) = p(f_\phi(x))\]

<p>Since this is now in <strong>low-dimensional space</strong>, MLE is <strong>safe to apply</strong>. The final generative model is:</p>

\[q(x) = q_\theta(z) g_\theta(z)\]

<p>Some examples are:</p>
<ol>
  <li><strong>Variational Autoencoders (VAEs)</strong>: Learn a <strong>latent space representation</strong> while maximizing likelihood. Uses a <strong>Gaussian prior over latent space</strong> to regularize learning.</li>
  <li><strong>Latent Diffusion Models</strong>: Train an autoencoder first, then <strong>apply diffusion</strong> in latent space.</li>
</ol>

<h1 id="variational-autoencoders">Variational AutoEncoders</h1>

<p><strong>What is a Deep Latent Variable Model (DLVM)?</strong> A <strong>Deep Latent Variable Model (DLVM)</strong> is a <strong>probabilistic generative model</strong> that assumes:</p>

<ol>
  <li>There is a <strong>latent variable</strong>  $z$  (an unobserved representation).</li>
  <li>The observed data  $x$  is generated <strong>from</strong>  $z$  <strong>through a deep neural network (decoder)</strong>.</li>
</ol>

<p>Formally, the <strong>generative process</strong> is:</p>

<p>(A) <strong>Sample a latent code</strong>  $z$  <strong>from a prior</strong>  $p_\theta(z)$ <strong>:</strong>
\(z \sim p_\theta(z)\)
This is usually a <strong>Gaussian prior</strong>:</p>

\[p_\theta(z) = \mathcal{N}(z \vert 0, I)\]

<p>(B) <strong>Generate data</strong>  x  <strong>from</strong>  z  <strong>using an exponential family distribution</strong>:</p>

\[x | z \sim \text{ExpFam}(x | d_\theta(z))\]

<p>Here,  $d_\theta(z)$  is a deep <strong>neural network</strong> (called the <strong>decoder</strong>) that maps  $z$  to the parameters of the likelihood distribution. <strong>ExpFam</strong> refers to the <strong>exponential family of distributions</strong>, which includes: <strong>Gaussian</strong> for continuous data;  <strong>Bernoulli</strong> for binary data; <strong>Categorical</strong> for discrete data</p>

<p>For example, a <strong>VAE for image generation</strong> might work as follows:</p>

<ol>
  <li>Sample a <strong>latent code</strong>  $z$  <strong>(compressed representation of the image)</strong>.</li>
  <li>Use a <strong>decoder (deep neural network)</strong> to transform  $z$  into an image.</li>
  <li>The output image is drawn from a <strong>Gaussian likelihood</strong>, meaning:</li>
</ol>

\[x \vert z \sim \mathcal{N}(d_\theta(z), \sigma^2 I)\]

<p><strong>Why Exact Inference is Intractable</strong>? In generative models, we are often interested in the <strong>posterior distribution</strong>:</p>

\[p_\theta(z \vert x) = \frac{p_\theta(x \vert z) p_\theta(z)}{p_\theta(x)}\]

<p>which represents the probability of a latent variable  $z$  given an observed data point  $x$ . This posterior is crucial because it allows us to understand the hidden structure behind the data and enables efficient sampling of new data points. However, computing this posterior directly requires knowledge of the <strong>marginal likelihood</strong> (or <strong>evidence</strong>):</p>

\[p_\theta(x) = \int p_\theta(x \vert z) p_\theta(z) dz\]

<p>which integrates over all possible latent variables  $z$  to determine the total probability of observing  $x$ . Unfortunately, computing  $p_\theta(x)$  is <strong>intractable</strong>, making exact posterior inference impossible. The intractability arises due to several reasons:</p>

<ol>
  <li><strong>The Decoder Network</strong>  $d_\theta(z)$  <strong>is Nonlinear and Complex</strong>: In modern deep generative models, $p_\theta(x \vert z)$  is parameterized by a <strong>deep neural network</strong>, called the <strong>decoder</strong>. This means that the function mapping  $z$  to  $x$  is highly <strong>nonlinear</strong> and complex, making it <strong>impossible to integrate analytically</strong>. Even if  $p_\theta(x \vert z)$  is a simple Gaussian, when  $z$  is transformed by a deep network, the resulting likelihood function becomes <strong>highly non-Gaussian</strong> and difficult to evaluate.</li>
  <li><strong>The Integral is High-Dimensional</strong>: If  $z$  is a low-dimensional variable (e.g., a scalar), integrating over all values of  $z$  might be feasible. However, in practice,  $z$  often has <strong>hundreds or thousands of dimensions</strong>, depending on the complexity of the data. Computing an exact integral in such a high-dimensional space requires summing over <strong>exponentially many possible values</strong>, making direct evaluation computationally infeasible.</li>
  <li><strong>The Curse of Dimensionality</strong>: In high-dimensional spaces, standard numerical integration techniques (such as grid-based integration) fail because the number of required computations grows <strong>exponentially</strong> with the number of dimensions. Monte Carlo sampling methods, while useful, become inefficient because the probability mass is often concentrated in small regions, making it difficult to obtain accurate estimates without a massive number of samples.</li>
</ol>

<p>Due to these challenges, we cannot compute the exact posterior  $p_\theta(z \vert x)$  directly. Instead, we resort to <strong>approximate inference methods</strong>, such as <strong>Variational Inference (VI)</strong> or <strong>Monte Carlo methods</strong>, which allow us to estimate the posterior efficiently while keeping computations feasible.</p>

<p><strong>Approximate Inference with Variational Autoencoders (VAEs)</strong> or <strong>Amortized Variational Inference</strong>: Instead of computing the true posterior  $p_\theta(z \vert x) $, we introduce an <strong>approximate posterior</strong>:</p>

\[q_\phi(z \vert x)\]

<p>This is a <strong>neural network (called the inference network or encoder)</strong> that learns to approximate  $p_\theta(z \vert x)$ . Instead of computing an <strong>exact</strong> posterior for each  $x$ , we train  $q_\phi(z \vert x)$  to perform <strong>fast inference for any input</strong>—this is called <strong>amortized inference</strong>.</p>

<p><strong>Variational Autoencoder (VAE)</strong>: A <strong>Variational Autoencoder (VAE)</strong> consists of:</p>
<ol>
  <li><strong>Encoder (Inference Network</strong>  $q_\phi(z \vert x)$ <strong>)</strong>: Learns a probabilistic mapping from data  x  to latent codes  z . Typically modeled as $q_\phi(z \vert x) = \mathcal{N}(z \vert \mu_\phi(x), \sigma_\phi^2(x) I)$,  where  $\mu_\phi(x)$  and  $\sigma_\phi^2(x)$  are computed by a <strong>neural network</strong>.</li>
  <li>
    <table>
      <tbody>
        <tr>
          <td><strong>Decoder (Generative Model</strong>  $p_\theta(x</td>
          <td>z)$ <strong>)</strong>: Learns to reconstruct  x  from latent variable  $z$. Defines a <strong>likelihood function</strong> for generating data.</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li><strong>Latent Prior</strong>  $p(z)$ : Typically a <strong>standard normal distribution</strong>  $\mathcal{N}(0, I)$.</li>
</ol>]]></content><author><name></name></author><summary type="html"><![CDATA[This is my note for my journey in getting deeper in Generative AI.]]></summary></entry><entry><title type="html">Adversarial thinking with AI</title><link href="https://azareei.github.io/blog/2024/Adversarial-thinking-ai/" rel="alternate" type="text/html" title="Adversarial thinking with AI" /><published>2024-03-03T18:00:00+00:00</published><updated>2024-03-03T18:00:00+00:00</updated><id>https://azareei.github.io/blog/2024/Adversarial-thinking-ai</id><content type="html" xml:base="https://azareei.github.io/blog/2024/Adversarial-thinking-ai/"><![CDATA[<p>Today, I tuned into a podcast episode from <a href="https://tbf.fm/episodes/299-adversarial-thinking-in-entrepreneurship">Boostrapped Founder</a>, featuring Arvid discussing the power of AI in fostering adversarial thinking for entrepreneurs. He highlighted using AI, like ChatGPT, to critically assess our ideas and messages. This means having ChatGPT spot potential misunderstandings in our emails, critique our writing, or evaluate our tweets for possible criticisms. This method not only uncovers flaws in our logic but also helps us fix these issues, with AI offering suggestions for improvements. These strategies are part of what’s called prompt engineering, and mastering several can be quite beneficial.</p>

<p>Another prompt engineering technique I find really helpful is this: I ask ChatGPT a question and at the end I ask it to come up with ten clarifying yes/no questions  and only after I answered those questions, provide me an answer. This ensures the AI completely understands my question, resulting in responses that are more precise and tailored to my needs. Using this method has consistently improved the feedback I receive. This shows the power of AI in refining our thought processes and decision-making!</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Today, I tuned into a podcast episode from Boostrapped Founder, featuring Arvid discussing the power of AI in fostering adversarial thinking for entrepreneurs. He highlighted using AI, like ChatGPT, to critically assess our ideas and messages. This means having ChatGPT spot potential misunderstandings in our emails, critique our writing, or evaluate our tweets for possible criticisms. This method not only uncovers flaws in our logic but also helps us fix these issues, with AI offering suggestions for improvements. These strategies are part of what’s called prompt engineering, and mastering several can be quite beneficial.]]></summary></entry><entry><title type="html">From Bias Variance Trade Off to Double Descent</title><link href="https://azareei.github.io/blog/2024/Bias-Variance-Trade-off/" rel="alternate" type="text/html" title="From Bias Variance Trade Off to Double Descent" /><published>2024-02-20T18:00:00+00:00</published><updated>2024-02-20T18:00:00+00:00</updated><id>https://azareei.github.io/blog/2024/Bias-Variance-Trade-off</id><content type="html" xml:base="https://azareei.github.io/blog/2024/Bias-Variance-Trade-off/"><![CDATA[<p>This whole section is adapted from <a href="https://udlbook.github.io/udlbook/">Understanding Deep Learning</a>.</p>

<h2 id="test-error-formulation">Test Error Formulation</h2>

<p>Let’s start with a 1D regression problem. Consider</p>

\[y_i = f(x_i) + \epsilon\]

<p>as a true model, where \(\epsilon\) is the noise with mean 0 and variation \(\sigma^2\). Given a dataset \(\mathcal{D} = \{(x_i, y_i)\}_{i=1}^N\), the prediction model’s goal is to estimate \(f\) . Assume a Model \(\phi\) that given some data that it uses for training, can make prediction for each \(x_i\). So \(\phi(x_i; \mathcal{D})\) is the output of our model which is trained on dataset \(\mathcal{D}\) predicting the output for \(x_i\). The loss of our model can be written as</p>

\[L = \left( \phi(x; \mathcal{D}) - y \right)^2\]

<p>The loss here is stochastic, and we need to take the expectation over all possible outputs \(y\) and all possible datasets \(\mathcal{D}\) used in training. Lets start by replacing for \(y\) with the ground truth model first</p>

<p>\(L = \left( \phi(x; \mathcal{D}) - y \right)^2 =  \left( \phi(x; \mathcal{D}) - f(x) - \epsilon \right)^2\) 
\(L = \left( \phi(x; \mathcal{D}) - f(x) \right)^2 - 2 \left( \phi(x; \mathcal{D}) - f(x) \right) \epsilon  + \epsilon^2\)</p>

<p>taking the expectation over all possible outputs \(y\) given some data \(x\), we find</p>

\[\mathbb{E}_y[ L |x] = \mathbb{E}_y \left[ \left( \phi(x; \mathcal{D}) - f(x) \right)^2 \right] -2 \mathbb{E}_y \left[ \left( \phi(x; \mathcal{D}) - f(x) \right) \epsilon\right]  + \mathbb{E}_y \left[ \epsilon ^2\right]\]

<p>\(\mathbb{E}_y[ L |x] = \left( \phi(x; \mathcal{D}) - f(x) \right)^2  -2  \left( \phi(x; \mathcal{D}) - f(x) \right) \mathbb{E}_y \left[ \epsilon\right]  + \sigma^2\) 
Since \(\mathbb{E}[\epsilon] =0\), then</p>

\[\mathbb{E}_y[ L |x] = \left( \phi(x; \mathcal{D}) - f(x) \right)^2  + \sigma^2\]

<table>
  <tbody>
    <tr>
      <td>Last but not least, we need to take the expectation over all possible datasets \(\mathcal{D}\) used for training our model \(\phi\). We first call $$\mathbb{E}\left[ \phi(x;\mathcal{D})</td>
      <td>\mathcal{D}\right] = \bar{f}(x)$$, this is basically the expected performance of our model given all possible data that it can see. Given this definition, we find that</td>
    </tr>
  </tbody>
</table>

\[\mathbb{E}_\mathcal{D} \left[ \mathbb{E}_y[ L |x] | \mathcal{D}\right]  = \left( \phi(x; \mathcal{D}) - f(x) \right)^2  + \sigma^2\]

\[\mathbb{E}_\mathcal{D} \left[ \mathbb{E}_y[ L |x] | \mathcal{D}\right]  = \mathbb{E}_\mathcal{D} \left[ \left( \phi(x; \mathcal{D}) -\bar{f}(x) + \bar{f}(x) - f(x) \right)^2\right]  + \sigma^2\]

\[\mathbb{E}_\mathcal{D} \left[ \mathbb{E}_y[ L |x] | \mathcal{D}\right]  = \left( \phi(x; \mathcal{D}) -\bar{f}(x)\right)^2 + 2 \mathbb{E}_\mathcal{D} \left[ \phi(x; \mathcal{D}) -\bar{f}(x)\right] \left( \bar{f}(x) - f(x) \right)  + \left( \bar{f}(x) - f(x) \right)^2  + \sigma^2\]

\[\mathbb{E}_\mathcal{D}\left[  \mathbb{E}_y \left[ L \right] \right] = \left( \phi(x; \mathcal{D}) -\bar{f}(x)\right)^2  + \left( \bar{f}(x) - f(x) \right)^2  + \sigma^2\]

<p>That’s it! So the expected loss after considering the uncertainty in the data \(\mathcal{D}\) and the output test data \(y\) consists of three additive parts: The first term  \(\left( \phi(x; \mathcal{D}) -\bar{f}(x)\right)^2\) is the variance of the fitted model due to a particular training dataset that we sample; The second term  \(\left( \bar{f}(x) - f(x) \right)^2\)  is the bias, which is the systematic deviation of the model from the mean of the functions that we model; The last term is just the inherent noise in the data or inherent uncertainty in the true mapping from input to output in the model.</p>

<h2 id="variance">Variance</h2>

<p>So the variance results from seeing limited noisy training data. Fitting the model \(\phi(x\mathcal{D})\) depends on the training sets, and slight difference results in different parameters. We can reduce the variance by increasing the size of data \(\mathcal{D}\). This averages out the inherent noise and ensured that the input space is well sampled.</p>

<p>See the following figure from the book. It shows the effect of training with 6, 10, and 100 samples at each column. The best-fitting model varies a lot when we use 6 points, and the variation reduces with increasing the number of samples. When we use 100 samples, the model almost does not change at all.</p>

<figure>
    <picture>
        

        <!-- Fallback to the original file -->
        <img src="/assets/img/posts/bias_variance_trade_off/20240221000130.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

    </picture>

</figure>

<h2 id="bias">Bias</h2>

<p>The bias term comes from the inability of the model to describe the true underlying function. If we increase the complexity of our model, and as a result make it more flexible the bias reduces. This is usually done by increasing the number of parameters of the model.</p>

<p>Check out the following figure again from the book. In this model, linear line line model is used in 3, 5, and 10 regions (dividing the interval of \([0,1]\) into 3, 5, 10 regions). As expected, increasing the number of regions, the model can better match with the original data. However as you see in the second row, the variance of the model is increased, since the model overfits to the data used. This is known as bias-variance trade-off.</p>

<figure>
    <picture>
        

        <!-- Fallback to the original file -->
        <img src="/assets/img/posts/bias_variance_trade_off/20240221000927.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

    </picture>

</figure>

<h2 id="bias-variance-trade-off">Bias Variance Trade-off</h2>

<p>The above figure showed a side effect of increasing the model complexity. Given a fixed-size training data, as we increase the complexity the variance term increases. So increasing the model complexity does not necessarily reduce the test error. This is what is known as <strong>bias variance trade-off</strong>.</p>

<p>The following figure shows this trade-off in another way. The first row shows that we fit three linear region to a sampled 15 points data (sampled three different times). All the time we find almost the same set of linear lines, meaning that variance is small. However, in the second row, we increase the number of regions to 15. Now the model better fits to the data points we sampled, however, each time we sample another dataset, we literally fit to the data, and we find a totally different fit. The model output varies given different datasets and shows the increase in the variance of the model given different sampled data. This is also known as overfitting. 
![[Pasted image 20240221001728.png]]</p>

<h2 id="double-descent">Double descent</h2>

<p>Consider this experiment: Consider the MNIST-1D dataset involving 10,000 training and 5,000 test examples. We then increase the model’s capacity and observed its impact on performance of the model. As the number of parameters in the model increases (model capacity increases), then the training error decreases to nearly zero (even before reaching a capacity equal to the number of training examples). Also we observe that the test error also decreases, which contradicts the expected increase in test error due to the bias-variance trade-off. Instead, test error continued to decrease, showcasing an unusual pattern (see following figure from the book)</p>

<p>A follow-up experiment with 15% randomized training labels reveals a similar trend in training error reduction. However, the test error initially followed the anticipated bias-variance pattern, increasing up to a point, but then unexpectedly decreased again with added capacity, even falling below earlier minimum levels. This “double descent” phenomenon, where error rates drop after initially increasing as capacity grows, was observed in both the original and noisy datasets, indicating distinct under-parameterized and over-parameterized regimes, with a critical regime in between where error rates peak. Similar patters also is seen on CIFAR-100 data with Resnet-18 network.</p>

<figure>
    <picture>
        

        <!-- Fallback to the original file -->
        <img src="/assets/img/posts/bias_variance_trade_off/20240221002957.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

    </picture>

</figure>

<h2 id="but-why">But why?</h2>

<p>The concept of double descent challenges traditional understanding by showing that test performance first worsens as models gain just enough capacity to memorize data, then improves even after achieving perfect training performance. This contradicts expectations since over-parameterized models, with parameters outnumbering training data points, should not improve due to lack of constraints.</p>

<p>So when the number of parameters increases the model has enough capacity to fit the whole data with zero training loss. So it can fit the training data perfectly. So increasing the number of parameters would not result in the model fitting the training data better (since the loss is already zero)! So if anything happens is because of some-change that occurs for in-between training data, or how the model prioritize one solution over another as it extrapolates between data points (this is known as inductive bias). Inductive bias is the assumption that a learning algorithm uses to predict outputs given inputs that it has not encountered before.</p>

<p>Note that the data is in high dimension. Considering the number of possibilities for input data and the number of data points we have, you can easily see that we have sparse data in high dimension, so the ability of the model to predict in-between training data points is very important. This situation is simplified to the following figure. we have a limited number of data points. Now you can see that as we increase the number of hidden-units in NN, the model predicts smoother functions between the datapoints. Commonly it is thought that in double descent as we increase the number of parameters in our model, it interpolates more smoothly between training data points, and hence generalize better to new data. Interestingly as seen in the following figure, when the number of hidden units are exactly the same as the number of datapoints, the output distorts to fit the data (similar to increase we saw in the test error for bias-variance trade-off cases above), but as we increase the number of parameters the function becomes smoother.</p>

<figure>
    <picture>
        

        <!-- Fallback to the original file -->
        <img src="/assets/img/posts/bias_variance_trade_off/20240221004513.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

    </picture>

</figure>

<p>As capacity increases, models can create smoother interpolations between data points, which is believed to enhance generalization to new data. This phenomenon suggests that model capacity contributes to a form of regularization, guiding models towards smoother functions that better predict unseen data. However, the mechanisms driving this smoothness, whether through network initialization or the training algorithm’s inherent preferences, remain uncertain.</p>

<p>Essentially, the discovery of double descent reveals that adding parameters to a model beyond the point of memorization can lead to better performance, due to the model’s capacity for smoother function interpolation in the vast, sparse high-dimensional input space.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[This whole section is adapted from Understanding Deep Learning.]]></summary></entry><entry><title type="html">Cross Entropy Loss Derivation</title><link href="https://azareei.github.io/blog/2024/Cross-Entropy-loss/" rel="alternate" type="text/html" title="Cross Entropy Loss Derivation" /><published>2024-02-14T14:30:00+00:00</published><updated>2024-02-14T14:30:00+00:00</updated><id>https://azareei.github.io/blog/2024/Cross-Entropy-loss</id><content type="html" xml:base="https://azareei.github.io/blog/2024/Cross-Entropy-loss/"><![CDATA[<p><a href="https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html">Cross entropy loss</a> is defined as</p>

\[L = \frac{1}{N} \sum_{n=1}^N l_n, \qquad l_n = -  \frac{\exp(x_{n,c})}{\sum_i \exp(x_{n,i})}, \text{where } y_n=c\]

<p>where \(x\) is the input, \(y\) is the target, \(C\) is the number of classes, \(N\) is the mini-batch size. So the network for each case of \(n\), predicts values of \([x_{n,1}, ..., x_{n,C}]^T\), and we pass it to log-soft-max, and then depending on what class it belongs to \(y_{n,c}\) use that value, and then average over all the cases of mini-batch \(n=1, ..., N\).  Note that \(y_{n}\) here represents the group that it belongs to, in terms of one-hot vector it can also be written as</p>

\[L = \frac{1}{N} \sum_{n=1}^N l_n, \qquad l_n = -  \sum_{c=1}^C \frac{\exp(x_{n,c})}{\sum_i \exp(x_{n,i})} y_{n,c}\]

<p>where here we used the one-hot representation of \(y_n\).</p>

<p>Our goal here is to do a derivation, to show why is the cross-entropy loss is defined as above.</p>

<p>The Kullback-Leibler (KL) divergence between the two probability distribution \(q(z)\) and \(p(z)\) is defined as</p>

\[D_{KL}[q||p] = \int_{-\infty}^{\infty} q(z) \log \frac{q(z)}{p(z)} dz\]

<p>Now consider that we observe an empirical data \(\{y_i\}_{i=1}^{N}\) (which are the classes for each case of the data). We can consider the output distribution is a weighted sum of the point masses as</p>

\[q(y) = \frac{1}{N} \sum_{i=1}^N \delta (y-y_{i})\]

<p>where \(\delta(\cdot)\) is the delta Dirac function. We want to minimize the KL divergence between the output of the neural network 
\(P(y|\theta)\), 
and this empirical distribution,</p>

\[\hat{\theta} = \arg\min_\theta \left[ \int_{-\infty}^{\infty} q(y) \log {q(y)} dy - \int_{-\infty}^{\infty} q(y) \log {p(y)} dy \right]\]

\[\hat{\theta} = - \arg\min_\theta  \int_{-\infty}^{\infty} q(y) \log {P(y|\theta)} dy\]

<p>Now, we replace for \(q(y)\) to find</p>

\[\hat{\theta} = - \arg\min_\theta \int_{-\infty}^{\infty} \left( \frac{1}{N} \sum_{n=1}^N \delta (y-y_{n}) \right)  \log {P(y|\theta)} dy\]

\[\hat{\theta} = - \arg\min_\theta \frac{1}{N}  \sum_{n=1}^N \log {P(y_n|\theta)}\]

<p>Note that the output of the network is  \([x_{n,1}, ..., x_{n,C}]^T\), that is transformed into probabilities using a soft-max function as</p>

\[P(y_n|\theta) = \sum_{c=1}^C \frac{\exp(x_{n,c})}{\sum_i \exp(x_{n,i})} y_{n,c}\]

<p>So as can be seen above the loss can be written as</p>

\[L = \frac{1}{N} \sum_{n=1}^N l_n, \qquad l_n = -  \sum_{c=1}^C \frac{\exp(x_{n,c})}{\sum_i \exp(x_{n,i})} y_{n,c}\]

<p>So that’s it. Basically cross-entropy loss is the KL divergence between the point-mass distribution and the output probability prediction of the network (using a soft-max probability assignment).</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Cross Entropy Loss]]></summary></entry><entry><title type="html">Goals and The Drift That Directs Your Life’s Random Walk</title><link href="https://azareei.github.io/blog/2023/Goals-drift/" rel="alternate" type="text/html" title="Goals and The Drift That Directs Your Life’s Random Walk" /><published>2023-05-21T14:30:00+00:00</published><updated>2023-05-21T14:30:00+00:00</updated><id>https://azareei.github.io/blog/2023/Goals-drift</id><content type="html" xml:base="https://azareei.github.io/blog/2023/Goals-drift/"><![CDATA[<p>Life can often feel like a random walk, a journey where every step is influenced by countless variables, many beyond our control. In this context, imagine each step as a day, and each direction as a decision that either takes us in positive (+1) or negative direction (-1).</p>

<p>When we don’t have a clear goal or purpose, our life is like a random walk with equal probabilities. Some days we make progress (+1), while on others we face setbacks (-1). Each day our steps will be</p>

\[\text{step} = \begin{cases} +1, &amp;  p=0.5 \\ -1, &amp;  p=-0.5 \end{cases}\]

<p>Over time, after  \(n\) days, the average progress is zero - meaning we stay roughly where we started - and the range of places where we might end up (the standard deviation) is quite large (proportional to \(\sqrt{n}\)). It’s unpredictable and can feel like we’re drifting aimlessly.</p>

\[\mathbb{E}[\text{distance}] = \mathbb{E}[\text{step}_1 + \text{step}_2 + … + \text{step}_n] = n \mathbb{E}[step] = n  (-1 \times 0.5 + 1 \times 0.5) = 0\]

\[Var[\text{distance}] = Var[\text{step}_1 + \text{step}_2 + … + \text{step}_n] = n Var[step] = n \cdot 1 =n\]

<p>where we used the fact that</p>

\[Var[step] =  \mathbb{E}[step^2] - (\mathbb{E}[step])^2 = 1\]

<p>However, when we do have a goal, it introduces a drift, a subtle push for our walk in one direction. This goal doesn’t remove the randomness or unpredictability of life; there will still be steps forward and backward. But the drift gently nudges us towards making progress \(+1\) more often than experiencing setbacks \(-1\). It’s like a compass guiding us through the randomness. We call this a drift \(d\), that pushes us more toward one direction. So the steps each day are</p>

\[\text{step} = \begin{cases} +1, &amp;  p=0.5+d/2 \\ -1, &amp;  p=-0.5 - d/2 \end{cases}\]

<p>Now let’s see what happens, after  \(n\) days. This time the progress is not zero, in fact after \(n\) days,</p>

\[\mathbb{E}[\text{distance}] = \mathbb{E}[\text{step}_1 + \text{step}_2 + … + \text{step}_n] = n \mathbb{E}[step] = n  (-1 \times (0.5-d/2) + 1 \times (0.5+d/2)) = n\cdot d\]

<p>which means we are not at zero anymore, and in fact with that slight drift, now we are and \(n\cdot d\). It’s interesting to see that the randomness, or the standard deviation of where we are also decreases,</p>

\[Var[\text{distance}] = Var[\text{step}_1 + \text{step}_2 + … + \text{step}_n] = n Var[step] = n \cdot (1-d^2)\]

\[Var[step] =  \mathbb{E}[step^2] - (\mathbb{E}[step])^2 = 1 - d^2\]

<p>Let’s simulate this to see it in action. We create a simulation of both a random walk example, and a drifted random walk, with setting the drift value only to ! meaning that you take a positive direction action with probability of only \(p=0.55\) (a bit more than average)!</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="c1"># Number of steps
</span><span class="n">n</span> <span class="o">=</span> <span class="mi">10000</span>

<span class="c1"># Number of random walks
</span><span class="n">num_walks</span> <span class="o">=</span> <span class="mi">500</span>

<span class="c1"># The drift term, which makes positive steps more likely
</span><span class="n">drift</span> <span class="o">=</span> <span class="mf">0.05</span>

<span class="n">distances_random</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">num_walks</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>
<span class="n">distances_drifted</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">num_walks</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>

<span class="c1"># Perform the random walks
</span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_walks</span><span class="p">):</span>
    <span class="n">steps_random</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">choice</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
    <span class="n">steps_drifted</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">choice</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="o">-</span><span class="n">drift</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="mf">0.5</span><span class="o">+</span><span class="n">drift</span><span class="o">/</span><span class="mi">2</span><span class="p">])</span>
    
    <span class="n">distances_random</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">cumsum</span><span class="p">(</span><span class="n">steps_random</span><span class="p">)</span>
    <span class="n">distances_drifted</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">cumsum</span><span class="p">(</span><span class="n">steps_drifted</span><span class="p">)</span>

<span class="c1"># Calculate the mean and standard deviations of the distances at each step
</span><span class="n">mean_distances_random</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">distances_random</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">mean_distances_drifted</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">distances_drifted</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">mean_distances_random_theory</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
<span class="n">mean_distances_drifted_theory</span> <span class="o">=</span> <span class="n">drift</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>

<span class="n">std_distances_random</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">std</span><span class="p">(</span><span class="n">distances_random</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">std_distances_drifted</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">std</span><span class="p">(</span><span class="n">distances_drifted</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Create an array representing sqrt(n) for comparison
</span><span class="n">sqrt_n</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">n</span><span class="p">))</span>
<span class="n">sqrt_n_drift</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">n</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="n">drift</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>

<span class="c1"># Plot the mean and standard deviation of the distances and sqrt(n) for comparison
</span><span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">mean_distances_random</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Mean of random walk distances</span><span class="sh">'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">blue</span><span class="sh">'</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">mean_distances_drifted</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Mean of drifted walk distances</span><span class="sh">'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">mean_distances_random_theory</span><span class="p">,</span> <span class="sh">'</span><span class="s">--</span><span class="sh">'</span><span class="p">,</span>  <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">green</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">mean_distances_drifted_theory</span><span class="p">,</span> <span class="sh">'</span><span class="s">--</span><span class="sh">'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">green</span><span class="sh">'</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">fill_between</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="n">n</span><span class="p">),</span> <span class="n">mean_distances_random</span> <span class="o">-</span> <span class="n">std_distances_random</span><span class="p">,</span> <span class="n">mean_distances_random</span> <span class="o">+</span> <span class="n">std_distances_random</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">blue</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">fill_between</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="n">n</span><span class="p">),</span> <span class="n">mean_distances_drifted</span> <span class="o">-</span> <span class="n">std_distances_drifted</span><span class="p">,</span> <span class="n">mean_distances_drifted</span> <span class="o">+</span> <span class="n">std_distances_drifted</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">mean_distances_random_theory</span> <span class="o">+</span> <span class="n">sqrt_n</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="sh">'</span><span class="s">:</span><span class="sh">'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">green</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">mean_distances_random_theory</span> <span class="o">-</span> <span class="n">sqrt_n</span><span class="p">,</span>  <span class="n">linestyle</span><span class="o">=</span><span class="sh">'</span><span class="s">:</span><span class="sh">'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">green</span><span class="sh">'</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">mean_distances_drifted_theory</span> <span class="o">+</span> <span class="n">sqrt_n_drift</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="sh">'</span><span class="s">:</span><span class="sh">'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">green</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">mean_distances_drifted_theory</span> <span class="o">-</span> <span class="n">sqrt_n_drift</span><span class="p">,</span>  <span class="n">linestyle</span><span class="o">=</span><span class="sh">'</span><span class="s">:</span><span class="sh">'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">green</span><span class="sh">'</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Number of steps</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Distance</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Comparison of Random Walk and Drifted Walk Distance with sqrt(n)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span></code></pre></figure>

<p>The blue curve shows a person doing random walk, always around \(0\) with a standard deviation of \(\sqrt{n}\). The more they have lived, the more probability of being somewhere further out from \(0\) on the positive or negative side! however, when taking small actions (drift) toward a goal daily, after \(n\) days, linearly proportional to the number of days, \(n\), they are distanced from \(0\), and further more the standard deviation of their place has been reduced by \(\sqrt{n(1-d^2)}\). So take small actions daily toward a goal, as they matter a lot over a long run.</p>

<figure>
    <picture>
        

        <!-- Fallback to the original file -->
        <img src="/assets/img/posts/goals_random_walk/random_walk.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

    </picture><figcaption class="caption">ETF sponsors and products</figcaption>

</figure>

<h2 id="so-goals-can-be-the-small-guiding-drift-that-shapes-our-lifes-random-walk-journey">So goals can be the small guiding drift that shapes our life’s random walk journey.</h2>]]></content><author><name></name></author><summary type="html"><![CDATA[Goals and Random Walk]]></summary></entry><entry><title type="html">Qabus-name (in Farsi)</title><link href="https://azareei.github.io/blog/2023/qabus-name/" rel="alternate" type="text/html" title="Qabus-name (in Farsi)" /><published>2023-03-26T02:30:00+00:00</published><updated>2023-03-26T02:30:00+00:00</updated><id>https://azareei.github.io/blog/2023/qabus-name</id><content type="html" xml:base="https://azareei.github.io/blog/2023/qabus-name/"><![CDATA[<p>This is Qabus name</p>

<p style="text-align:right;dir:rtl;">
ویرایش کتاب قابوس‌نامه به گیت‌هاب اضافه شد. این کتاب سال ۲۰۲۱ در دور همی مجازی خوانده شد و توسط خوانندگان ویرایش شد. در زیر مقدمه تدوین رو میذارم:ـ
</p>

<p><br /></p>
<p style="text-align:right;dir:rtl;">
<a href="https://github.com/azareei/Qabus-nama">گیت‌هاب قابوسنامه</a>
</p>
<p><br /></p>

<p style="text-align:right;dir:rtl;">
کتاب قابوس‌نامه نیاز به معرفی ندارد که مقدمه‌ای از تدوینگران لازم داشته باشد. صرفا در این چند سطر، چندُ‌و‌چون شکل‌گیری این تدوین و خاطرات خواندن اثر را به یادگار مینویسم. در جمعی از دوستان، معروف به کوهنوردان سابق این اثر هفنگی، به صورت مجازی، در دوران پندمیک کویید۱۹ خوانده شد. 
در ابتدای پندمیک، گلستان مقبول نظر جمع بود و خوانده شد. اگر خواننده این سطور تا کنون گلستان را نخوانده، اکیدا توصیه میشود که ابتدای امر آن کتاب حضرت عجل خوانده شود. بعد از خوانش گلستان سعدی، این اثر مقبول نظر جمع کوهنورد افتاد. از آنجا که دسترسی به این کتاب در آن زمان به سادگی میسر نبود و از آنجا که نویسنده سال‌های سال بود که دار فانی را وداع گفته بود، نظر جمع بر آن گشت که تلاشی در جهت جمع‌آوری این مطالب و تدوین آن به اندازه تلاش 
خود شود. تدوینگران اثر بر اساس اندک سواد و ذوقی که داشتند اثر را جمع‌آوری و تدوین کردند. خواننده محترم برای نظر کارشناسی پیرامون مدخلات به ادیبان حاذق ارجاع داده میشود. فلذا این اثر، ذوق چند تنی دوست‌دار ادبیات میباشد که در دور‌همی‌های مجازی پدید آمده است.ـ
در خلال این جلسات، متاسفانه دوستی از حلقه خوانش دچار سرطانی لاعلاج گردید و همه را در تاثر و شگفتی از حکمت روزگار گذاشت. شوربختانه، عزیز ما درگذشت و همه ما را در غم دوری خود گذاشت. این تدوین ابتدای امر دور هم برای ذوق خود خوانندگان گردآوری شده بود و قصد انتشاری وجود نداشت. ولی برای زنده نگه داشتن یاد و خاطره آن عزیز رفته هم که شده،‌ تصمیم ما به انتشار این تدوین شد. فلذا تقدیم به شما دوست عزیز و با یاد آن دوست رفته.
<br />
<br />

تقدیم به میثم عزیز
<br />
<br />

از طرف کوهنوردان سابق
</p>

<p><br />
<br /></p>

<p><a href="https://github.com/azareei/Qabus-nama">Github Link for Qabus-nama</a></p>]]></content><author><name></name></author><summary type="html"><![CDATA[Qabusname]]></summary></entry><entry><title type="html">My Notes on Investments by Bodie</title><link href="https://azareei.github.io/blog/2023/Bodie-Investments/" rel="alternate" type="text/html" title="My Notes on Investments by Bodie" /><published>2023-03-11T02:30:00+00:00</published><updated>2023-03-11T02:30:00+00:00</updated><id>https://azareei.github.io/blog/2023/Bodie-Investments</id><content type="html" xml:base="https://azareei.github.io/blog/2023/Bodie-Investments/"><![CDATA[<p>In this post, I share my notes from when I was reading the book Investments by Bodie ~2014. Please refer to the latest edition of the book for updated information.</p>

<ul>
  <li>
    <p>Investments</p>

    <ul>
      <li>
        <p>Real Assets vs Financial Assets
  real assets and financial assets and how they contribute to the material wealth of a country. Real assets, such as land, buildings, machines, and knowledge, determine a country’s productive capacity and generate net income. On the other hand, financial assets, such as stocks and bonds, are merely securities that allow people to hold claims on real assets or income.</p>

        <p>Individuals can choose to invest their wealth in financial assets by buying securities. Companies then use this money to purchase real assets and share the income with the investors. This means that the returns for investors come from the income generated by real assets.</p>

        <p>There are three main types of financial assets: fixed income, equity, and derivatives. Fixed income securities, such as corporate bonds, promise a fixed stream of income, while equity, or common stock, represents a share in a corporation and its real assets. Derivatives, such as options or futures contracts, derive their value from the price of other assets, such as bonds or stocks. These securities are used to hedge risks or transfer them to other parties.</p>

        <p>In addition to these financial assets, corporations regularly engage in currency transfers and investors can directly invest in real assets, such as commodities traded on exchanges. Firms also use commodities and derivatives to manage their exposure to business risks.</p>
      </li>
      <li>
        <p>Financial Markets and the Economy</p>

        <p>Financial markets play a crucial role in allocating capital in market economies through stock prices. The collective assessment of a firm’s current performance and future prospects reflected in stock prices can directly impact a firm’s ability to raise capital and encourage investment. Stock prices can also allow individuals to transfer purchasing power from their youth to older days by storing wealth in financial assets.</p>

        <p>Diverse financial instruments in financial markets also allow investors with different risk tolerance to bear risk. For instance, a firm like Ford can raise funds through both stocks and bonds, with more risk-tolerant investors choosing to buy stocks and less risk-tolerant ones choosing bonds. This allows the inherent risk of the investment to be borne by those most willing to bear it.</p>

        <p>The separation of ownership and management in large corporations also provides stability to the market. Ownership is distributed among a large group of individuals who elect a board of directors to manage the firm. However, there can be conflicts of interest between management and owners known as “agency problems.” To mitigate these issues, firms may tie executive compensation to the success of the company, have a board of directors that can force out underperforming management, and be subject to close monitoring by security analysts and institutional investors. Unhappy shareholders can also launch a proxy contest to elect a new board, or the firm may be at risk of takeover by other companies.</p>

        <p>Transparency in the market is also crucial for informed decision-making by investors. The Sarbanes-Oxley Act of 2002 aimed to tighten rules of corporate governance and prevent misleading information. The act requires corporations to have more independent directors, tighter accounting standards, and increased oversight of public companies. These measures aim to promote ethical and responsible corporate behavior.</p>
      </li>
      <li>
        <p>The Investment Process</p>

        <p>The process of investing involves building a portfolio, a collection of investment assets, which can be updated over time by selling existing securities and using the proceeds to purchase new securities. Investors make two key decisions in constructing their portfolios: asset allocation and security selection.</p>

        <p>Asset allocation involves deciding the proportion of one’s portfolio to allocate to different asset classes, such as stocks, bonds, or safe assets like bank accounts or money market securities. This decision is a crucial factor in determining the overall risk and return of the portfolio.</p>

        <p>Security selection, on the other hand, involves choosing specific securities within each asset class to hold in the portfolio. This requires security analysis to determine the value of the individual securities.</p>

        <p>There are two main approaches to portfolio construction: top-down and bottom-up. The top-down approach starts with the asset allocation decision and then moves on to security selection. The bottom-up approach focuses more on security selection and less on asset allocation, constructing the portfolio from securities that seem attractively priced.</p>
      </li>
      <li>
        <p>Markets Are Competitive</p>

        <p>Financial markets are constantly monitored by intelligent and well-funded analysts, meaning that there are no easy wins or “free lunches”. This idea has two important implications:</p>

        <p>The Risk-Return Trade-Off: Investments come with a degree of risk and investors want to earn the highest returns they can. However, if an investment offers higher returns without taking on extra risk, many investors will jump on the opportunity, driving up the price and reducing the expected return. This means that there is a trade-off between risk and return in the securities market. Higher-risk assets offer higher expected returns, while lower-risk assets have lower expected returns.</p>

        <p>Efficient Markets: The no-free-lunch proposition also implies that it’s rare to find bargains in the security markets. The financial markets process information about securities quickly and efficiently, meaning that security prices usually reflect all the information available to investors about their value. This is known as the efficient market hypothesis. If the markets are indeed efficient, it might be better to follow a passive investment strategy rather than trying to actively identify mispriced securities.</p>
      </li>
      <li>
        <p>Financial Market Players</p>

        <p>Financial markets are made up of three major players: firms, households, and governments. Firms need capital to fund their investments in plant and equipment and they raise this capital by issuing securities. Households, on the other hand, are the net suppliers of capital as they purchase these securities issued by firms. Governments can play both the role of borrowers and lenders, depending on their tax revenue and expenditures.</p>

        <p>However, firms and governments do not sell their securities directly to the public. Instead, they hire financial intermediaries, such as banks, investment companies, insurance companies, and credit unions, to act as the go-between. Financial intermediaries issue their own securities to raise funds to purchase the securities of other corporations. They offer several advantages, including pooling the resources of many small investors, achieving significant diversification, and building expertise through the volume of business they do.</p>

        <p>Investment bankers also play a crucial role in the financial market as they specialize in services for businesses, such as issuing securities, advising on prices and interest rates, and handling the marketing of securities in the primary market. Meanwhile, start-up companies rely on venture capital and private equity investments to fund their operations. These investments are usually made by dedicated venture capital funds, wealthy individuals known as angel investors, or institutions like pension funds.</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Asset Classes and Financial Instruments</p>

    <ul>
      <li>
        <p>Money Market</p>

        <p>The money market is a subsector of the fixed income market that includes highly marketable short-term debt securities. Many of these securities are traded in large denominations, making them unavailable to individual investors. To access these securities, investors can turn to mutual funds, which pool the resources of many individuals to purchase a diverse range of money market securities on their behalf.</p>

        <ul>
          <li>
            <p>T-bill</p>

            <p>One of the most marketable money market instruments is the Treasury bill (T-bill), which is issued by the U.S government. T-bills are sold at a discount from their maturity value and provide a payment equal to the face value of the bill at maturity. They are issued with maturities of 4, 13, 26, and 52 weeks and can be purchased at auction or in the secondary market. T-bills are highly liquid, have little risk, and are usually denominated in $100, $10,000, or even $100,000. The income earned from T-bills is exempt from state and local taxes.</p>

            <p>T-bills are typically quoted using the bank-discount method, which calculates the yield as a fraction of the face value and assumes a 360-day year. The bid price is the price at which a dealer is willing to purchase a T-bill, while the ask price is the price at which the T-bill is offered for sale. The difference between the bid and ask price is the bid-ask spread, which is the source of the dealer’s profit. The bond equivalent yield calculates the yield based on a 365-day year and is found by dividing the face value by the ask price and multiplying by 365/156.</p>
          </li>
          <li>
            <p>Ceritficate of Deposti</p>

            <p>A Certificate of Deposit (CD) is a fixed-term deposit with a bank. The investor cannot access the funds until the end of the specified term, at which point the bank pays both the interest and the principal value to the depositor. CDs are typically issued in denominations of $100,000 or more and are negotiable, meaning that the investor can sell the certificate before its maturity if necessary.</p>

            <p>Short-term CDs are highly marketable and are easily sold, while longer-term CDs with a maturity of three months or more become less marketable. The Federal Deposit Insurance Corporation considers CDs to be bank deposits and insures them up to $250,000.</p>
          </li>
          <li>
            <p>Commercial Paper</p>

            <p>Companies that are well established often issue their own short-term debt notes, known as commercial papers, as an alternative to borrowing from banks. To ensure that they have the necessary funds to pay off the commercial paper at maturity, they may secure backing from a bank or a line of credit. The maturities of commercial papers typically range up to 270 days, with most maturities being less than 1 or 2 months and issued in multiples of $100,000. The Securities and Exchange Commission requires registration for maturities longer than 270 days, which is almost never done.</p>

            <p>Individuals can invest in commercial papers through money market mutual funds. Because the firm’s performance can be monitored and predicted over a short term, such as 1 month, commercial papers are considered safe assets, often issued by nonfinancial firms. However, financial firms such as banks may issue asset-backed commercial papers to raise funds for investing in other assets, such as subprime mortgages. These assets were used as collateral for the commercial paper, which led to difficulties starting in 2007 when subprime mortgagors began defaulting and the banks were unable to issue new commercial paper to refinance their positions as the old paper matured.</p>
          </li>
          <li>
            <p>Banker’s Acceptance</p>

            <p>Banker’s Acceptance is a type of financial instrument in which a bank customer orders the bank to pay a specific amount at a future date, usually 6 months. The bank’s endorsement of the order signifies its responsibility for the ultimate payment to the holder of the acceptance. These instruments are often used in foreign trade to ensure payment when the creditworthiness of the counterparty is unknown. Upon endorsement, the Banker’s Acceptance can be traded in the secondary market. They are considered safe assets as they are backed by the credit of the bank rather than the borrower’s. Banker’s Acceptances are sold at a discount from the face value and are mostly used in international trade.</p>
          </li>
          <li>
            <p>Eurodollars</p>

            <p>Eurodollars are U.S. dollar-denominated deposits held in foreign branches of American banks. These banks are able to evade regulations imposed by the Federal Reserve by operating outside of its jurisdiction. Typically, Eurodollars are large deposits with short maturities of less than 6 months. Similar to domestic certificates of deposit, Eurodollar CDs are issued by a non-U.S. branch of a bank, usually located in London. Due to their lower liquidity and higher risk, Eurodollar CDs offer higher yields compared to domestic CDs. While Eurodollar bonds are also an option, they are excluded from the money market due to their longer maturities.</p>
          </li>
          <li>
            <p>Repos and Reverses</p>

            <p>Dealers in government securities often utilize repurchase agreements, also referred to as repos or RPs, as a short-term borrowing solution, typically for just one night. In a repo transaction, the dealer sells government securities to an investor at an agreed upon price, with a commitment to buy back the securities the next day at a slightly higher price, which represents the overnight interest. This operates similarly to a one-day loan from the investor, with the government securities serving as collateral.</p>

            <p>For longer borrowing needs, a term repo operates in a similar manner, with the term of the loan lasting from 30 days or more. Repos are considered very secure as they are backed by government securities.</p>

            <p>A reverse repo, on the other hand, is the opposite of a repo. In this transaction, the dealer buys securities from an investor, with an agreement to sell them back at a higher price in the future.</p>
          </li>
          <li>
            <p>Federal Funds</p>

            <p>The Federal Reserve System, also known as “the Fed,” is a network of banks that work together to ensure the stability and reliability of the US financial system. As part of this system, each member bank is required to maintain a minimum balance in a reserve account with the Fed. These funds in the bank’s reserve account are called “Federal funds” or “fed funds.”</p>

            <p>At any given time, some banks may have more funds in their reserve accounts than required, while others may have a shortage. Big banks in New York tend to have a shortage of fed funds. In the Federal Funds market, banks with excess funds lend to those with a shortage. These loans are overnight transactions and are made at a rate of interest called the federal funds rate.</p>

            <p>The fed funds was initially created as a way for banks to transfer balances to meet their reserve requirements. However, today, the market has evolved and many large banks use federal funds as a component of their sources of income. The fed funds rate is the rate of interest for short-term loans among institutions. Although most investors cannot participate in this market, the fed funds rate is still of great interest as it is seen as a key indicator of monetary policy.</p>
          </li>
          <li>
            <p>Broker’s Call</p>

            <p>Individuals who purchase stocks using margin borrow part of the funds from their broker. The broker may then borrow these funds from a bank, agreeing to repay the loan on demand if the bank requests it. The interest rate on these loans is typically 1% higher than the rate on short-term Treasury bills (T-bills).</p>
          </li>
          <li>
            <p>The LIBOR Market:</p>

            <p>The London Interbank Offered Rate (LIBOR) is a benchmark interest rate at which large banks in London are willing to lend money to one another. It is widely used as a reference rate in the money market and is tied to multiple currencies, including the US dollar. With trillions of dollars and various derivative assets tied to it, the LIBOR is a crucial reference rate in the financial industry.</p>
          </li>
          <li>
            <p>Yiels on Money Market Instruments</p>

            <p>Most money market instruments are considered low-risk, but it’s important to note that they are not     completely risk-free. While these securities typically offer yields higher than default-free T-Bills, investors usually prioritize liquidity, leading them to opt for lower yield options such as T-Bills. As shown in Figure 1, there is typically a gap between CD yields and T-Bills, and this gap widens during times of financial crisis. Similarly, the difference between LIBOR rates and T-Bills also increases during periods of financial stress.</p>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<figure>
    <picture>
        

        <!-- Fallback to the original file -->
        <img src="/assets/img/bodie/fig1-spread-cd-tbills.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

    </picture>

</figure>

<ul>
  <li>
    <p>The Bond Market</p>

    <p>The bond market is a market for long-term debt instruments, as opposed to the short-term debt instruments found in the money market. The bond market includes Treasury notes, Treasury bonds, Corporate bonds, Municipal bonds, Mortgage securities, and federal agency debts. These debt instruments are often referred to as fixed-income capital market securities because they generally offer a fixed stream of income. However, in some cases, the formulas that determine the income stream may result in a flow of income that is far from fixed. As a result, it is more appropriate to refer to these securities as debt instruments or bonds.</p>

    <ul>
      <li>
        <p>Treasury Notes and Bonds</p>

        <p>The U.S. government borrows money through the sale of Treasury Notes and Treasury Bonds. T-Notes have maturities of up to 10 years, while T-Bonds have maturities ranging from 1 to 30 years. They are usually quoted in denominations of $100 or $1000, with the latter being more common. Both T-Notes and T-Bonds make semiannual coupon payments, representing the interest earned on the investment.</p>

        <p>An example of a T-Bill entry can be found in financial publications such as the Wall Street Journal, where its maturity date, coupon rate, bid price, asked price, change in price, and yield to maturity are displayed. The yield to maturity is calculated by determining the semiannual yield and then doubling it, instead of compounding it for two half-year periods. This results in an annual percentage rate (APR) rather than an effective annual yield.</p>

        <p>It’s important to note that T-Bills are considered low-risk investments, but are not risk-free. The prices are quoted as a percentage of par-value, usually $1000, and can fluctuate based on market conditions.</p>
      </li>
      <li>
        <p>Inflation-Protected Treasury Bonds</p>

        <p>Many governments, including the U.S., offer bonds known as Inflation-Protected Treasury Bonds or TIPS as a way for citizens to hedge against inflation. These bonds are linked to the Consumer Price Index and their principal amount is adjusted accordingly. The yield on TIPS bonds represents real, inflation-adjusted rates and is a great starting point for building a low-risk investment portfolio.</p>
      </li>
      <li>
        <p>Federal Agency Debt</p>

        <p>Government agencies often issue their own securities to finance their operations, particularly in sectors that may not receive adequate credit through traditional private sources. Some of the major mortgage-related agencies include the Federal Home Loan Bank (FHLB), Federal National Mortgage Association (FNMA or Fannie Mae), Government National Mortgage Association (GNMA or Ginnie Mae), and the Federal Home Loan Mortgage Corporation (FHLMC or Freddie Mac). The FHLB, for example, raises funds by issuing securities and lending the money to savings and loan institutions, which then lend it to individuals for home mortgages. Although the debt of these federal agencies is not explicitly insured by the government, it was traditionally assumed that the government would assist an agency in the event of default. This assumption was validated in September 2008 when Fannie Mae and Freddie Mac experienced severe financial difficulties.</p>
      </li>
      <li>
        <p>International Bonds</p>

        <p>The international capital market, largely centered in London, provides opportunities for firms to borrow and for investors to purchase bonds from foreign issuers. A Eurobond is a bond denominated in a currency other than that of the country in which it is issued. For example, a bond denominated in dollars and sold in Britain would be considered a Eurobond. On the other hand, Yankee bonds are bonds issued by non-U.S. companies but denominated in dollars and sold in the U.S., while Samurai bonds are bonds issued by non-Japanese companies but denominated in yen and sold in Japan.</p>
      </li>
      <li>
        <p>Municipal Bonds</p>

        <p>Municipal bonds, also known as “munis,” are debt securities issued by state or local governments. They offer interest income that is exempt from federal and, in most cases, state and local taxes, making them attractive to many investors. There are two types of municipal bonds: General Obligation bonds, which are backed by the full faith and credit of the issuer, and Revenue Bonds, which are backed by the revenue from a specific project or agency.</p>

        <p>Short-term Tax Anticipation Notes and long-term bonds are both available in the municipal bond market, with maturities ranging from a few months to 30 years. The tax-exempt status of municipal bonds is the main advantage that attracts investors, but to determine if they are a better investment option than taxable bonds, it’s important to consider an investor’s tax bracket and the equivalent taxable yield. The tax bracket at which an investor is indifferent between taxable and tax-exempt bonds can also be calculated by determining the yield ratio.</p>

        <p>In general, the higher an investor’s tax bracket, the more attractive tax-exempt municipal bonds become. However, it’s important to consider the risk profile of the bond and the issuer’s creditworthiness before making any investment decisions.</p>

        <p>The key feature of municipal bonds is their <em>tax exemption</em>
  status. Since investors are not paying any form of federal or local
  taxes, they are willing to accept lower rates on these securities.</p>

        <p>How to compare between taxable and tax-exempt bond: let \(t\)
  denote the investor’s combined federal plus state tax bracket and \(r\) denote the total before tax rate of return available on taxable
  bond, then \(r(1-t)\) is the after-tax rate available on those
  securities. If this value exceeds the rate on municipal bond rate \(r_m\), then the investor does better holding the taxable
  bond. Another way to determine te interest rate on taxable bond that
  would be nevessary to provide an after-tax return equal to that of
  municipals. This value would be equal to \(r = r_m/(1-t)\). This
  is called <em>equivalent taxable yield</em>. Note that in order to find \(t\), a simple way is to add federal plus local tax rate together as
  \(t = t_{federal} + t_{state}\) . A more precise approach would
  recognize that the state taxes are deductible at the federal
  level. You owe federal taxes only on income net of state
  taxes. Therefore for every dollar of income, your after-tax proceeds
  would be \((1- t) (1-t_{federal})\times(1-t_{state})\). This way
  you could calculate combined federal and local taxes.</p>

        <p>Note that the more your tax bracket is the more you are interested
  in holding municipal bonds that are tax-exempt. Because for every
  tax-exempt rate you need to get more yield for taxable yield.</p>

        <p>Another, factor that can be computed is the tax bracket at which
  investors are indifferent between taxable and tax-exempt bonds. This
  bracket could be found as \(t = 1 - \frac{r_m}{r}\). The yield
  ratio, \(r_m/r\) is a key determinant of the attractiveness of
  municipal bonds. The higher the ratio, the lower the cutoff tax
  bracket, and then more individuals will prefer to hold municipal
  bonds.</p>
      </li>
      <li>
        <p>Corporate Bonds</p>

        <p>Corporate bonds are a type of debt securities issued by private companies to raise funds from the public. They work similarly to Treasury bonds, paying out semi-annual coupons and returning the face value to the bondholder at maturity. However, they are riskier than Treasury bonds due to the creditworthiness of the issuing company.</p>

        <p>There are several types of corporate bonds, including secured bonds, which have specific collateral backing them in case of bankruptcy, unsecured bonds or debentures, which have no collateral, and subordinated debentures, which have a lower priority claim to the firm’s assets in the event of bankruptcy.</p>

        <p>Additionally, some corporate bonds come with options attached. Callable bonds give the company the option to repurchase the bond from the holder at a predetermined price. Convertible bonds allow the bondholder to convert each bond into a specific number of shares of stock.</p>
      </li>
      <li>
        <p>Mortgages and Mortgage-Backed Securities</p>

        <p>Investing in mortgage-backed securities, which represent ownership or obligation claims in a pool of mortgages, has become a common aspect of the fixed-income market. Traditionally, these securities, also known as pass-throughs, were made up of conforming mortgages that met strict underwriting guidelines set by organizations such as Fannie Mae or Freddie Mac. However, in the lead up to the financial crisis, a significant amount of subprime mortgages were bundled and sold as mortgage-backed securities. These loans, made to financially weaker borrowers, were encouraged by the government to increase housing affordability for low-income households. However, they ended up causing huge losses, not just for banks, hedge funds and other investors, but also for Fannie Mae and Freddie Mac, which incurred billions of dollars in losses on the subprime mortgage pools they purchased.</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Equity Securities</p>

    <ul>
      <li>
        <p>Common stocks</p>

        <p>Common stocks, also known as equity securities or equities, represent ownership in a corporation. When you own a share of common stock, you are entitled to a vote in corporate governance matters and a share of the company’s financial benefits. Some corporations issue two classes of common stock, one with voting rights and one without. The one with restricted voting rights may sell at a lower price.</p>

        <p>The corporation is governed by a board of directors elected by shareholders. The board meets several times a year to select managers who run the day-to-day operations of the company and ensure that it acts in the best interests of shareholders. Shareholders who cannot attend the annual meeting can vote by proxy, giving another party the power to vote on their behalf. Management typically solicits proxies from shareholders and typically receives a large majority of proxy votes.</p>

        <p>There are several ways to make sure that management is following the
  goal of shareholders want, otherwise <em>agency problems</em> arises. There
  are several mechanisms that alleviate the agency problem, such (i)
  compensation schemes that link the success of the manager to that of
  the firm; (ii) oversight by the board of directors as well as
  outsiders such as security analysts, creditors, or large
  institutional investors; (ii) the threat of a proxy contest in which
  unhappy shareholders attempt to replace the current management team;
  or (iii) the threat of a takeover by another firm</p>

        <p>The common stock of most large corporations can be bought and sold
  freely on one or more stock exchanges. A corporation whose stock is
  not publicly traded is said to be <em>closely held</em>. In most of closely
  held corporations, the owners of the firm also take an active role in
  its management. Therefore take overs are generally not a concern.</p>

        <ul>
          <li>
            <p>Characteristics of Common Stock</p>

            <p>The two most important characteristics of common stock as an
  investment are (i) <em>residual claim</em> and <em>limited liability</em>.</p>

            <p><em>Residual claim</em> means that stock holders are the last ones in line
  among all those who have a claim on the assets and income of the
  corporation. In <em>liquidation</em> of the firm’s assets the shareholders
  have a claim to what is left after all other claims, such as <em>tax authorities</em>, <em>employees</em>, <em>suppliers</em>, <em>bondholders</em>, and other
  credits that have been paid. For a firm not in liquidation,
  shareholders have claim to the part of operating income left over
  after interest and taxes havebeen paid. Management can pay either
  pay this residual as <em>cash dividends</em> to the shareholders or
  <em>reinvest</em> in the business to increase the value of shares.</p>

            <p><em>Limited liability</em> means that the most shareholders can loose in
  the event of failure of the corporation is their original
  investment. Unlike owners of unincorporated businesses, whose
  creditors can lay claim to the personal assets of the owner (like
  house, car, or furniture), corporate shareholders may at worst have
  worthless stock. They are not personally liable for the firm’s
  obligation.</p>
          </li>
          <li>
            <p>Stock Market Listings</p>

            <p>The New York Stock Exchange (NYSE) is one of the platforms where investors can buy and sell stocks. A sample listing of a stock, such as General Electric (GE), might look like this:</p>

            <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  - The closing price of GE stock is 19.72 dollars.
  - The net change from the previous trading day is +0.13 dollars.
  - On this day, 45.3 million shares of GE were traded.
  - The 52-week high and low prices of the stock are 21.00 dollars and 14.02 dollars, respectively.
  - The last quarterly dividend payment was 0.17 dollars per share (0.68 dollars divided by 4).
  - The annual dividend yield is 3.45%, calculated as 0.68 dollars divided by 19.62 dollars.
  - The price-earnings ratio is 16.01, which is the ratio of the current stock price to last year's earnings per share.
  - The stock has increased by 10.11% since the beginning of the year.
</code></pre></div>            </div>

            <p>It’s important to note that the dividend yield is part of the return on a stock investment. If a company pays a lower dividend, it’s expected to offer greater prospects for capital gains. The price-earnings ratio is a metric that tells us how much investors must pay for each dollar of earnings generated by the firm. A lower P/E ratio is generally seen as better.</p>
          </li>
        </ul>
      </li>
      <li>
        <p>Preferred Stock 
  Preferred stock is a hybrid investment that combines features of both equity and debt. Like a bond, it offers a fixed, annual income payment and does not grant the holder voting rights in the management of the company. However, the company is not obligated to pay the preferred dividends and they are usually cumulative, meaning any unpaid dividends must be paid before common stock dividends are paid. On the other hand, the firm has a contractual obligation to make interest payments on its debt and failure to do so may result in bankruptcy proceedings.</p>

        <p>The tax treatment of preferred stock is also different than bonds, as the payments are considered dividends instead of interest and are not tax-deductible for the company. However, corporations may exclude 70% of dividends received from domestic corporations when computing their taxable income, making preferred stock a desirable fixed-income investment for some corporations. For individual investors who cannot use the 70% tax exclusion, preferred stock yields may not be as attractive as other available assets.</p>

        <p>Preferred stock can also be callable by the issuing company or convertible into common stock at a specified ratio. Adjustable-rate preferred stock links its dividend to current market interest rates, similar to adjustable-rate bonds.</p>
      </li>
      <li>
        <p>Depository Receipts</p>

        <p>American Depository Receipts (ADRs) are a convenient way for US investors to own shares in foreign companies. These certificates, traded in US markets, represent ownership in a foreign company’s shares. Each ADR can correspond to a fraction of a foreign share, one share, or multiple shares. ADRs were introduced to simplify the process of complying with US security registration requirements for foreign firms, making it easier for US investors to invest in international companies.</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Stock and Bond Market Indexes</p>

    <p>Stock Market Indexes are a measure of the overall performance of the stock market. The most well-known index is the Dow Jones Industrial Average, which tracks the performance of 30 large corporations. Additionally, there are foreign market indexes such as the Nikkei Average in Tokyo and the Financial Times Indexes in London, providing a glimpse into the performance of stock markets around the world.</p>

    <ul>
      <li>
        <p>Dow Jones Industrial Average</p>

        <p>Aka <em>DJIA</em> is the average of 30 “blue-chip” corporations that is
  computed since 1896. DJIA covered only 20 stocks untill 1928 and
  then chaged to 30 stocks.</p>

        <p>Originally, the DJIA was calculated as the average price of the
  stocks included in the index! Just adding the prices of these 30
  stocks and dividing by 30. The percentage change in DJIA would
  then be the percentage change in the average price of the 30
  shares. This means that the percentage change in DJIA measures the
  return (excluding dividends) on a portfolio that invests one share
  in each of the 30 stocks in the index. The value of such portfolio
  is the sum of the 30 prices (one share of each stock). Since the
  percentage change in the average of the 30 prices is the same as
  the percentage change in the sum, the index and the portfolio
  would have the same percentage change!</p>

        <p>Since DJIA corresponds to a portfolio that holds one share of each
  component stock, the investment is proportional to the company’s
  share price! Therefore it is a <em>price-weghted average</em>.</p>

        <p>The DJIA is now (Apr 2017) at a level of 20,000 and it is supposed
  to be average of only 30 stocks! Actually DJIA no longer equals to
  the average price of the 30 stocks, since the averaging procedure
  is adjusted whenever a <em>stock splits</em> or <em>pay a stock dividend of</em>
  <em>more than 10%</em>, or /when the company in the list is replaced by
  another firm/. When these events occur, the divisor used to
  compute the average is adjusted so to leave the index unaffected.</p>

        <table>
          <thead>
            <tr>
              <th>Company</th>
              <th>Exchange</th>
              <th>Symbol</th>
              <th>Industry</th>
              <th>Date Added</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>3M</td>
              <td>NYSE</td>
              <td>MMM</td>
              <td>Conglomerate</td>
              <td>1976-08-09</td>
            </tr>
            <tr>
              <td>American Express</td>
              <td>NYSE</td>
              <td>AXP</td>
              <td>Consumer finance</td>
              <td>1982-08-30</td>
            </tr>
            <tr>
              <td>Apple</td>
              <td>NASDAQ</td>
              <td>AAPL</td>
              <td>Consumer electronics</td>
              <td>2015-03-19</td>
            </tr>
            <tr>
              <td>Boeing</td>
              <td>NYSE</td>
              <td>BA</td>
              <td>Aerospace and defense</td>
              <td>1987-03-12</td>
            </tr>
            <tr>
              <td>Caterpillar</td>
              <td>NYSE</td>
              <td>CAT</td>
              <td>Construction and mining equipment</td>
              <td>1991-05-06</td>
            </tr>
            <tr>
              <td>Chevron</td>
              <td>NYSE</td>
              <td>CVX</td>
              <td>Oil &amp; gas</td>
              <td>2008-02-19</td>
            </tr>
            <tr>
              <td>Cisco Systems</td>
              <td>NASDAQ</td>
              <td>CSCO</td>
              <td>Computer networking</td>
              <td>2009-06-08</td>
            </tr>
            <tr>
              <td>Coca-Cola</td>
              <td>NYSE</td>
              <td>KO</td>
              <td>Beverages</td>
              <td>1987-03-12</td>
            </tr>
            <tr>
              <td>DuPont</td>
              <td>NYSE</td>
              <td>DD</td>
              <td>Chemical industry</td>
              <td>1935-11-20</td>
            </tr>
            <tr>
              <td>ExxonMobil</td>
              <td>NYSE</td>
              <td>XOM</td>
              <td>Oil &amp; gas</td>
              <td>1928-10-01</td>
            </tr>
            <tr>
              <td>General Electric</td>
              <td>NYSE</td>
              <td>GE</td>
              <td>Conglomerate</td>
              <td>1907-11-07</td>
            </tr>
            <tr>
              <td>Goldman Sachs</td>
              <td>NYSE</td>
              <td>GS</td>
              <td>Banking, Financial services</td>
              <td>2013-09-20</td>
            </tr>
            <tr>
              <td>The Home Depot</td>
              <td>NYSE</td>
              <td>HD</td>
              <td>Home improvement retailer</td>
              <td>1999-11-01</td>
            </tr>
            <tr>
              <td>IBM</td>
              <td>NYSE</td>
              <td>IBM</td>
              <td>Computers and technology</td>
              <td>1979-06-29</td>
            </tr>
            <tr>
              <td>Intel</td>
              <td>NASDAQ</td>
              <td>INTC</td>
              <td>Semiconductors</td>
              <td>1999-11-01</td>
            </tr>
            <tr>
              <td>Johnson &amp; Johnson</td>
              <td>NYSE</td>
              <td>JNJ</td>
              <td>Pharmaceuticals</td>
              <td>1997-03-17</td>
            </tr>
            <tr>
              <td>JPMorgan Chase</td>
              <td>NYSE</td>
              <td>JPM</td>
              <td>Banking</td>
              <td>1991-05-06</td>
            </tr>
            <tr>
              <td>McDonald’s</td>
              <td>NYSE</td>
              <td>MCD</td>
              <td>Fast food</td>
              <td>1985-10-30</td>
            </tr>
            <tr>
              <td>Merck</td>
              <td>NYSE</td>
              <td>MRK</td>
              <td>Pharmaceuticals</td>
              <td>1979-06-29</td>
            </tr>
            <tr>
              <td>Microsoft</td>
              <td>NASDAQ</td>
              <td>MSFT</td>
              <td>Software</td>
              <td>1999-11-01</td>
            </tr>
            <tr>
              <td>Nike</td>
              <td>NYSE</td>
              <td>NKE</td>
              <td>Apparel</td>
              <td>2013-09-20</td>
            </tr>
            <tr>
              <td>Pfizer</td>
              <td>NYSE</td>
              <td>PFE</td>
              <td>Pharmaceuticals</td>
              <td>2004-04-08</td>
            </tr>
            <tr>
              <td>Procter &amp; Gamble</td>
              <td>NYSE</td>
              <td>PG</td>
              <td>Consumer goods</td>
              <td>1932-05-26</td>
            </tr>
            <tr>
              <td>Travelers</td>
              <td>NYSE</td>
              <td>TRV</td>
              <td>Insurance</td>
              <td>2009-06-08</td>
            </tr>
            <tr>
              <td>UnitedHealth Group</td>
              <td>NYSE</td>
              <td>UNH</td>
              <td>Managed health care</td>
              <td>2012-09-24</td>
            </tr>
            <tr>
              <td>United Technologies</td>
              <td>NYSE</td>
              <td>UTX</td>
              <td>Conglomerate</td>
              <td>1939-03-14</td>
            </tr>
            <tr>
              <td>Verizon</td>
              <td>NYSE</td>
              <td>VZ</td>
              <td>Telecommunication</td>
              <td>2004-04-08</td>
            </tr>
            <tr>
              <td>Visa</td>
              <td>NYSE</td>
              <td>V</td>
              <td>Consumer banking</td>
              <td>2013-09-20</td>
            </tr>
            <tr>
              <td>Wal-Mart</td>
              <td>NYSE</td>
              <td>WMT</td>
              <td>Retail</td>
              <td>1997-03-17</td>
            </tr>
            <tr>
              <td>Walt Disney</td>
              <td>NYSE</td>
              <td>DIS</td>
              <td>Broadcasting and entertainment</td>
              <td>1991-05-06</td>
            </tr>
          </tbody>
        </table>

        <p>In order to better understand how DJIA works, lets suppose two
  stocks, ABC and XYS shwon in the following table. If we are
  introducing the DJIA for this table, the inital index and the
  final indexes are 
  Initial Index Value \(= (25+100)/2 = 62.5\) and 
  Final Index Value  \(= (30+90) /2 = 60\). So at the
  end, we have Percentage Change \(= -2.5/62.5= -4\)%. Note that this does not represent the total market change,
  since the total market chages as 
  Percentage Change in total market \(= \frac{690-600}{600} =
  +15\%\). This is because DJIA is price averaged, instead of the
  contribution that the stock is making to the market due to number
  of it shares in the market.</p>

        <table>
          <thead>
            <tr>
              <th>Stock</th>
              <th>Initial Price</th>
              <th>Final Price</th>
              <th>Shares</th>
              <th>Initial Value of Outstanding Stock</th>
              <th>Final Value of Outstanding Stock</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>ABC</td>
              <td>$25</td>
              <td>$30</td>
              <td>20 m</td>
              <td>$500 m</td>
              <td>$600 m</td>
            </tr>
            <tr>
              <td>XYZ</td>
              <td>$100</td>
              <td>$90</td>
              <td>1 m</td>
              <td>$100 m</td>
              <td>$90 m</td>
            </tr>
          </tbody>
          <tbody>
            <tr>
              <td>Sum</td>
              <td> </td>
              <td> </td>
              <td> </td>
              <td>$600 m</td>
              <td>$690 m</td>
            </tr>
          </tbody>
        </table>

        <p>Now, suppose that the company XYZ splits it shares to two. The new
  values are shown in the following table. DJIA, will find a new divisor \(d\), such
  that the DJIA does not change afterward, as follows
  \begin{equation}
  \frac{\text{Price of ABS} + \text{Price of XYZ}}{d} = 62.5
  \end{equation}
  Note that \(62.5\) is the initial DJIA that we had. The new
  devisor is then obtained as \(d = 1.2\). With this new divisor
  the final DJIA would be \((30 + 45)/1.2 = 62.5\), the same value
  at the start of the year. This would mean that the rate of return
  for such DJIA portfolio is zero. Note that still the whole market
  with these new values still have \(15\%\) return, if the
  portfolio was weigthed on the number of shares.</p>

        <table>
          <thead>
            <tr>
              <th>Stock</th>
              <th>Initial Price</th>
              <th>Final Price</th>
              <th>Shares</th>
              <th>Initial Value of Outstanding Stock</th>
              <th>Final Value of Outstanding Stock</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>ABC</td>
              <td>$25</td>
              <td>$30</td>
              <td>20 m</td>
              <td>$500 m</td>
              <td>$600 m</td>
            </tr>
            <tr>
              <td>XYZ</td>
              <td>$50</td>
              <td>$45</td>
              <td>2 m</td>
              <td>$100 m</td>
              <td>$90 m</td>
            </tr>
          </tbody>
          <tbody>
            <tr>
              <td>Sum</td>
              <td> </td>
              <td> </td>
              <td> </td>
              <td>$600 m</td>
              <td>$690 m</td>
            </tr>
          </tbody>
        </table>

        <p>The same story happens when we replace a firm. The denominator is
  updated to leave the average unchanged. By 2017, the divisor of
  the DJIA has fallen to a value of \(0.146\). Since, DJIA is the
  average of small number of firms, representing the broad market,
  they change the composition every so often to reflect the changes
  in economy.</p>
      </li>
      <li>
        <p>Standard &amp; Poor’s Indexes* or <em>S&amp;P 500</em></p>

        <p>The S&amp;P 500 is a market-value-weighted index of 500 firms, which means that the weight of a firm in the index is proportional to its market value, calculated as the product of its stock price and number of shares outstanding. The index is computed daily by adding up the total market value of the 500 firms and comparing it to the total market value on the previous day of trading. An investment in the index is equivalent to holding a portfolio of all 500 firms in proportion to their market value, excluding cash dividends.</p>

        <p>Most modern indexes use a modified version of market-value weights, known as free float market value, which only considers the value of shares that are freely available for investors to trade. This distinction is particularly important in Japan and Europe where a larger fraction of shares are held by non-tradable portfolios.</p>

        <p>Both market-value-weighted and price-weighted indexes are straightforward to follow as investment strategies. A market-value-weighted index perfectly tracks the capital gain of a portfolio comprised of shares in each component firm in proportion to its market value. A price-weighted index tracks the returns of a portfolio comprised of an equal number of shares of each firm.</p>

        <p>Investors can easily invest in market indexes by purchasing mutual funds or exchange-traded funds (ETFs). Index funds yield a return equal to the index, making them a low-cost investment strategy for equity investors. ETFs are portfolios of shares that can be bought and sold as a single unit, and there are a variety of ETFs available, from broad global market indexes to narrow industry indexes.</p>

        <p>In addition to the S&amp;P 500, Standard and Poor’s also publishes other stock indexes including the 400-stock Industrial Index, the 20-stock Transportation Index, the 40-stock Utility Index, and the 40-stock Financial Index.</p>
      </li>
      <li>
        <p>Other U.S. Market-Value Indexes</p>

        <p>The New York Stock Exchange (NYSE) publishes a composite index of all stocks listed on the NYSE, which is market-value weighted. This composite index includes subindexes for industrial, utility, transportation, and financial stocks. These indexes provide a broader view of the stock market than the S&amp;P 500.</p>

        <p>The National Association of Securities Dealers (NASD) publishes an index of more than 3,000 firms traded on the NASDAQ market.</p>

        <p>The Wilshire 5000 index is considered the ultimate US equity index, as it tracks the market value of essentially all actively traded stocks in the US. It actually includes more than 5000 stocks. The performance of these indexes can be found in The Wall Street Journal.</p>
      </li>
      <li>
        <p>Equally Weighted Indexes</p>

        <p>Market performance can be measured using an equally-weighted average of the returns of each stock in an index. This averaging technique gives equal weight to each stock’s return, which corresponds to an implicit investment strategy of putting equal dollar amounts into each stock. This is different from both price weighting, which requires an equal number of shares of each stock, and market-value weighting, which requires investments in proportion to a stock’s outstanding value.</p>
      </li>
      <li>
        <p>Foreign and International Stock Market Indexes</p>

        <p>The growth of financial markets worldwide has led to the creation of indexes to track their performance. Some examples of these indexes include the Nikkei in Japan, the FTSE in the UK, the DAX in Germany, the Hang Seng in Hong Kong, and the TSX in Canada. Morgan Stanley Capital International (MSCI) is a leader in the creation of international indexes and calculates over 50 country indexes and several regional indexes.</p>
      </li>
      <li>
        <p>Bond Market Indicators</p>

        <p>Just as stock market indexes provide insight into the performance of the overall stock market, bond market indicators measure the performance of various categories of bonds. The three most well-known groups of bond market indexes are those of Merrill Lynch, Barclays (previously the Lehman Brothers index), and Salomon Smith Barney (now part of Citigroup).</p>

        <p>However, there is a major challenge with bond market indexes: accurately computing the true rates of return on many bonds. This is because the infrequency of bond trades makes it difficult to obtain reliable, up-to-date prices. As a result, some prices must be estimated using bond valuation models, which may not reflect the true market values.</p>
      </li>
      <li>
        <p>Derivative Markets</p>

        <p>The derivative market consists of two main instruments: futures and options. These financial instruments provide payouts that are based on the  values of underlying assets, such as commodity prices, bond and stock prices, or market index values. Because the value of these instruments depends on the value of other assets, they are referred to as derivative assets.</p>

        <ul>
          <li>
            <p>Options</p>

            <p>A call option gives its holder the right to purchase an asset, such as stock, at a specified exercise price, also known as the strike price, before or on a specified expiration date. For example, a July call option on IBM stock with an exercise price of $180 allows the holder to buy IBM stock for $180 at any time until the expiration date in July. Each option contract covers the purchase of 100 shares, but quotations are made on a per-share basis. The holder of the call option does not have to exercise it, and it will only be profitable to do so if the market value of the asset is higher than the exercise price. When the market price exceeds the exercise price, the option holder can “call away” the asset for the exercise price and receive a payoff equal to the difference between the stock price and the exercise price. If not exercised before the expiration date, the option simply expires and becomes worthless. Call options are bullish investment vehicles that provide greater profits when stock prices increase.</p>

            <p>In contrast, a put option gives its holder the right to sell an asset for a specified exercise price before or on a specified expiration date. For example, a July put option on IBM with an exercise price of $180 allows the holder to sell IBM stock for $180 to the put writer at any time before the expiration date in July, even if the market price of IBM is lower than $180. Profits on put options increase when the asset decreases in value, unlike call options that benefit from an increase in the asset’s value. The put option is exercised only if its holder can deliver an asset worth less than the exercise price in return for the exercise price.</p>

            <p>It is important to note that the price of a call option decreases as the exercise price increases. For instance, a call option for May 5, 2017 with an exercise price of $144 is only $3.13. This makes sense because the right to purchase a share at a higher price is less valuable.</p>

            <p>On the other hand, the price of a put option increases with the exercise price. For example, the right to sell APPL shares for $130 is $0.31, while the right to sell shares for $143 is $3.07.</p>

            <p>Another factor that affects option prices is the expiration date. Option prices increase as the expiration date approaches. For instance, a call option for $130 a share is worth $17.75 if the expiration date is in November, compared to $13.10 if the expiration date is in May.</p>
          </li>
          <li>
            <p>Future Contracts</p>

            <p>A futures contract requires delivery of an asset (or its cash value) on a specified delivery or maturity date, for an agreed-upon price, called the futures price, to be paid at contract maturity.</p>

            <p>The trader who holds the long position commits to purchasing the asset on the delivery date, while the trader who takes the short position commits to delivering the asset at contract maturity.</p>

            <p>Table 8 shows some futures contracts for crude Brent oil listed on the Chicago Mercantile Exchange. Each contract calls for delivery of 1,000 barrels of oil. The table lists the prices for contracts expiring on various dates, with the first row being the nearest or front contract with a maturity date of June 2017. For example, the most recent price was $54.89 per barrel, an increase of $0.3 from the previous day’s close. The table also shows the opening price, as well as the high and low prices for the trading day. The volume column shows the number of contracts traded that day, but there is no column for “Open Interest” which represents the number of outstanding contracts.</p>

            <table>
              <thead>
                <tr>
                  <th>Month</th>
                  <th>Last</th>
                  <th>Change</th>
                  <th>Prior Settle</th>
                  <th>Open</th>
                  <th>High</th>
                  <th>Low</th>
                  <th>Volume</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>JUN 2017</td>
                  <td>55.19</td>
                  <td>0.3</td>
                  <td>54.89</td>
                  <td>54.75</td>
                  <td>56.07</td>
                  <td>54.57</td>
                  <td>33006</td>
                </tr>
                <tr>
                  <td>JUL 2017</td>
                  <td>55.55</td>
                  <td>0.38</td>
                  <td>55.17</td>
                  <td>55.08</td>
                  <td>56.23</td>
                  <td>54.86</td>
                  <td>12892</td>
                </tr>
                <tr>
                  <td>AUG 2017</td>
                  <td>55.64</td>
                  <td>0.29</td>
                  <td>55.35</td>
                  <td>55.37</td>
                  <td>56.46</td>
                  <td>55.15</td>
                  <td>7571</td>
                </tr>
                <tr>
                  <td>SEP 2017</td>
                  <td>55.65</td>
                  <td>0.2</td>
                  <td>55.45</td>
                  <td>56.2</td>
                  <td>56.27</td>
                  <td>55.45</td>
                  <td>6660</td>
                </tr>
              </tbody>
            </table>

            <p>The trader holding the long position in a futures contract profits from price increases. For example, if at contract maturity, the price of oil is $55.50 per barrel and the trader entered the contract at a future price of $55.19 per barrel on June 2017, they would pay the agreed-upon price of $55.19 for each barrel of Brent oil, which would then cost $55.50 at contract maturity. In this case, the profit for the long position would be $2100 (1000 x ($55.50 - $55.19)). Conversely, the short position trader must deliver 1,000 barrels at the previously agreed-upon futures price, and their loss would equal the long position trader’s profit.</p>

            <p>The key difference between a call option and a long position in a futures contract is the obligation to purchase the asset. While a futures contract obliges the long position trader to purchase the asset at the futures price, a call option conveys the right to purchase the asset at the exercise price. A call option holder has a better position than the holder of a long position in a futures contract with a futures price equal to the option’s exercise price, but this advantage comes at a cost. Call options must be purchased, whereas futures contracts are entered into without cost. The purchase price of an option, called the premium, represents the compensation the call option holder must pay for the ability to exercise the option only when it is profitable to do so. Similarly, the difference between a put option and a short futures position is the right, as opposed to the obligation, to sell an asset at an agreed-upon price.</p>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>How Securities are Traded</p>

    <ul>
      <li>
        <p>How Firms Issue Securities</p>

        <p>Firms need capital to finance their investments, which they can raise by either borrowing money or selling shares. Investment bankers are hired to handle the sale of these securities in the primary market, where newly issued securities are sold to the public. After the initial sale, investors can trade their shares of existing securities in the secondary market.</p>

        <p>Publicly listed firms’ shares can be continuously traded on well-known stock markets such as the New York Stock Exchange (NYSE) or NASDAQ Stock Market. Any investor can purchase shares for their own portfolio from these markets. Companies traded on these markets are referred to as publicly traded, publicly owned, or simply public companies. In contrast, private corporations have shares that are held by a small group of managers and investors.</p>
      </li>
      <li>
        <p>Privately Held Firms</p>

        <p>A privately held company is owned by a relatively small group of shareholders, who are not required to publicly disclose financial statements and other information as frequently as publicly traded companies. This allows the company to pursue long-term goals without the pressure of quarterly earnings announcements.</p>

        <p>However, private companies are limited to having up to 499 shareholders, which restricts their ability to raise large amounts of capital. To overcome this restriction, middlemen may form partnerships to buy shares in private companies, which counts as only one investor even though many individuals may participate.</p>

        <p>When a private company needs to raise funds, it sells shares directly to a small number of institutional or wealthy investors in a private placement. The SEC’s Rule 144A allows these companies to make these placements without having to prepare extensive and costly registration statements. Although attractive, shares of privately held companies do not trade in secondary markets such as the NYSE or NASDAQ Stock Exchange, reducing their liquidity and presumably lowering their prices.</p>

        <p>Recently, some firms have set up computer networks to enable private company stockholders to trade among themselves. However, unlike public stock exchanges regulated by the SEC, these networks require little disclosure of financial information and provide limited oversight of the market operations.</p>
      </li>
      <li>
        <p>Publicly Traded Companies</p>

        <p>When a private firm wants to raise capital from a wide range of investors, it may choose to go public by selling its securities to the general public and allowing them to freely trade shares in the established securities market. The first sale of shares to the public is called an Initial Public Offering (IPO). Later, the firm may issue more shares through a seasoned equity offering.</p>

        <p>Investment bankers are responsible for marketing public offerings of both stocks and bonds and are often referred to as underwriters. More than one investment banker may be involved in marketing the security, with a lead firm forming a syndicate of other investment bankers to share the responsibility of the stock issue.</p>

        <p>The investment bankers advise the firm on the terms of the sale and help prepare a preliminary registration statement that is filed with the Securities and Exchange Commission (SEC) to describe the issue and the prospects of the company. When the statement is in final form and accepted by the SEC, it is called a prospectus, and the price at which the securities will be offered to the public is announced.</p>

        <p>In a typical underwriting arrangement, the investment bankers purchase the securities from the issuing company and then resell them to the public. The issuing firm sells the securities to the underwriting syndicate for the public offering price, less a spread that serves as compensation for the underwriters. In addition to the spread, investment bankers may also receive shares of common stock or other securities from the firm.</p>
      </li>
      <li>
        <p>Shelf Registration</p>

        <p>In 1982, the SEC approved Rule 415, which enables firms to register securities and gradually sell them to the public over a period of 2 years after the initial registration. As the securities are registered, they can be sold quickly with limited additional documentation. These securities are referred to as “on the shelf” and ready for issuance, which gave rise to the term “shelf registration.</p>
      </li>
      <li>
        <p>Initial Public Offering</p>

        <p>Investment bankers play a crucial role in the process of issuing new securities to the public. They coordinate road shows to generate interest among potential investors and gather information about the demand and prospects of the security. The underwriters use the information gathered from these road shows, along with feedback from institutional investors, to determine the offering price and number of shares to be offered.</p>

        <p>Investors communicate their interest in purchasing shares of the IPO to the investment bankers through a process called book building. The allocation of shares to investors is partially based on the strength of their expressed interest in the offering. This creates an incentive for investors to truthfully reveal their interest, as underpriced IPOs often result in significant price jumps on the first day of trading.</p>

        <p>However, while IPOs often offer attractive first-day returns, they have been poor long-term investments on average. According to research by Ritter, a portfolio of equal amounts of each U.S. IPO between 1980 and 2009, held for three years, would have underperformed the broad U.S. stock market by 19.8%. The 2011 IPO of Groupon is an example of underpricing, while the IPO of Facebook is an example of overpricing.</p>
      </li>
    </ul>
  </li>
  <li>
    <p>How Securities are Traded?</p>

    <ul>
      <li>
        <p>Types of Markets</p>

        <ul>
          <li>
            <p>There are four <em>types of markets</em>:
  1) Direct search markets
  2) Brokered Markets
  3) Dealer Markets
  4) Auction Markets</p>
          </li>
          <li>
            <p><em>Direct Search Markets</em>: are <em>the least organized</em> markets. Buyers and sellers seek each other out directly. An example of a transaction in such markets is the sale of a used TV on craigslist where the seller advertises for buyers in local area. These markets are characterized by <em>sporadic participation</em> (meaning scattered), <em>low-priced</em> and <em>non-standard goods</em>. Firms find it difficult to profit in a such environment.</p>
          </li>
          <li>
            <p><em>Brokered Markets</em>: are <em>the next level of organization</em>. Brokers offer search serives to buyers and sellers, in markets where trading a good is active. An example, is <em>real state market</em>, where buyers make it worthwhile for participants to pay broker to help them conduct the search. Another example, is the <em>primary market</em> where new issues of securities are offered to the public. Investment bankers act as brokers as they seek investors to purchase securities directly from the issuing corporation.</p>
          </li>
          <li>
            <p><em>Dealers Market</em>: When trading activity increases in a particular type of asset, then <em>dealer markets</em> arise. Dealers specialized in various assets, buy these assets for their own, and later sell them for a profit from their inventory. The spread between dealer’s buy (or “bid”) and sell (or “ask”) prices are a source of profit They save traders the <em>search costst</em>, because one can easily look up their prices. An example is the “second hand car dealers”. Also most bonds trade in over-the-counter dealer markets.</p>
          </li>
          <li>
            <p><em>Auction Markets</em>: The most <em>integrated market</em> is an <em>auction market</em>, where traders converge at on eplace (either “physically” or “electronically”) to buy and sell asset. An example of such markets is <em>New York Stock Exchange (NYSE)</em>. An advantage of auction markets to dealer markets is that one need not search across dealers to find the best price for a good. If all participants converge, they can arrive at mutually agreeble prices and save the bid-ask spread.</p>
          </li>
        </ul>
      </li>
      <li>
        <p>Types of Orders</p>

        <p>There are different types of trades an investor is eager to execute in these markets. Broadly speaking we have two types of orders: (i) Market orders and (ii) Price Contingetn Orders.</p>

        <ul>
          <li>
            <p>Market Orders</p>

            <p>Market orders are buy or sell orders that are to be executed immediately. For example, an investor might call his broker and ask for the market price of APPL. The broker will reort back that the best <em>bid price</em> is 140$ (the price to buy shares) and the best ask price is 141$ (the price to buy shares). The <em>bid-ask spread</em> in this case is 1$.</p>

            <p>There are several complications here: First, the posted price quote actually represent commitments to trade up to a secific number of shares. If the market order is more than this number of shares, multiple may be filled at multiple prices. For example, if the investor wants to buy 1,500 shares and the ask price is good for 1,000 shares, it may be necessary to pay a slightly higher price for the last 500 shares. The <em>depth</em> of the markets for shares of stock, shows the total number of shares offered for trading at each bid and ask price. <em>Depth is considered a component of liquitidty</em>. Second, another trader may beat the investor to the quote, this means that the investor’s order would then be executed at a worse price. Third and finally, the best price quote might change before the order arrives, causing execution at a price different from the one at the moment of order.</p>
          </li>
          <li>
            <p>Price Contingent Orders</p>

            <p>Investors may also place orders specifying prices at which they are willing to buy or sell a security.</p>

            <p>A <em>limit-buy order</em> instructs the broker to buy some number of shares if the stock price may be obtained <em>at or below</em> a stipulated price.</p>

            <p>Conversely, <em>limit-sell order</em> instructs the broker to sell if and when the stock price rises above a specified limit.</p>

            <p><em>limit-order book</em> is a collection of limit-orders to be executed. The best orders are at the top of the list. Offers to buy at the highest price, and offers to sell at the lowest price. The buy and sell orders at the top of the list are called <em>inside quotes</em>. The order sizes for the inside quotes can be fairly small. Therefore, investors interested in larger trades face an <em>effective spread</em> greater than the nominal one because they cannot execute their entire trade at the inside quote.</p>

            <p><em>Stop-orders</em> are similar to limit orders in that the trade is not to be executed unless the stock price hits a limit. For <em>Stop-loss orders</em>, the stock is to be sold if its price falls below a stipulated price. As the name suggests, this order is executed to stop furthe loss accumulation. Similarly <em>Stop-buy orders</em> specify a stock should be bought when the its rice rises above a limit.</p>

            <p>These stop orders often accompany <em>short sales</em> (sales of securities when you don’t own but have borrowed from your broker) and are used to limit potential losses from short position.</p>

            <p>All these price contingent orders all together</p>

            <table>
              <thead>
                <tr>
                  <th> </th>
                  <th>Price Below the limit</th>
                  <th>Price above the limit</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>Buy</td>
                  <td>limit-Buy Order</td>
                  <td>Stop-buy order</td>
                </tr>
                <tr>
                  <td>Sell</td>
                  <td>Stop-loss order</td>
                  <td>limit-sell order</td>
                </tr>
              </tbody>
            </table>
          </li>
        </ul>
      </li>
      <li>
        <p>Trading Mechanisms</p>

        <p>An investor who wants to buy or sell stocks, will ask the broker. The broker charges a commission fee for arranging the trade on client’s behalf. Brokers have several options, to execute the trade.</p>

        <p>There are three trading systems used in the US:
      * over the counter dealer markets
      * electronic communication networks
      * specialist markets</p>

        <p>NASDAQ and NYSE are the best well known markets. They use a variety of trading procedures.</p>

        <ul>
          <li>
            <p><em>Dealers Market</em></p>

            <p>Roughly <em>35,000</em> securities trade on <em>over-the-counter</em> or <em>OTC</em> markets. Thousands of brokers register with SEC as security dealers. Dealers quote prices they are willing to buy or sell. Then they contact a dealer listing an attractive quote and execute the trade.</p>

            <p>Before 1971, OTC quotions were recorded manually and published daily on so called pink-sheets. In 1971, the <em>National Association of Securities Dealers</em> introduced <em>Automatic Quotions</em> System, or <em>NASDAQ</em>, to link brokers an dealers in a computer network, to display<em>revise quotes on the network. Dealers used this system to post their bid</em>ask pric. The difference between bid and ask price, the bid-ask spread, is the source of dealer’s profit. Dealers examine prices online and then contact the delaer with the best quote and execute a trade.</p>

            <p>The NASDAQ as was originally desinged, was more of a price quotion system to post bid/ask prices. Brokers in the search of best trading opportunity, would contact the dealer and directly negotioate over the phone. NASDAQ Stock Market has now been added to NASDAQ and it allows for electronic execution of trades.</p>
          </li>
          <li>
            <p><em>Electronic Communivation Network (ECNs)</em></p>

            <p>ECN allows participants to post market limit orders over the computer networks. The limit order book is available for all of the participants. <em>NYSE Arca</em> is one of the leading ECNs. Orders are crossed, when they match on the limit-order book, without intervention of a broker. Therefore, ECNs are true trading systems, not merely price quotion systems.</p>

            <p>ECNs have several benefits: (i) Direct and automatic crossing without using a broker-dealer system (ii) Modest cost trades typically less than a penny per share, since they are automatic, (ii) elimination of bid-ask spread, since trades are crossed automatically, (iv) Fast speed at which trades are done, and (v) anonymity in the trades</p>
          </li>
          <li>
            <p><em>Specialist Markets</em></p>

            <p>This has been largely replaced by electronic communication networks. A decade ago, they were dominant form of market organization for rading stocks. In thi system, exchanges such as NYSE assign representativesfor managing the trade in each security to a specialist. Brokers wishing to buy/sell trades would contact the specialist on board of exchange. The specialist would manage all of the order book.The highest bid, and the lowest ask price would win the trade.</p>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>The Rise of Electronic Trading</p>

    <p>The NASDAQ and NYSE stock markets have undergone significant changes in the past few decades, transitioning from over-the-counter dealer markets and specialist markets to primarily electronic markets. Advances in technology and new regulations have brought about these changes. Regulations allowed brokers to compete for business, breaking their hold on information and reducing price increments. The integration of markets and the availability of technology to rapidly compare prices across markets has also reduced the cost of trade execution.</p>

    <p>In 1975, the fixed commission on the NYSE was eliminated and the Securities and Exchange Act was amended to create the National Market System, which aimed to partially centralize trading across exchanges and enhance competition. The implementation of a centralized reporting of transactions and price quotation system provided traders with a broader view of market opportunities.</p>

    <p>In 1994, a scandal at the NASDAQ involving dealers colluding to maintain wide bid-ask spreads led to the SEC instituting new order-handling rules. Published dealer quotes were now required to reflect customer limit orders and NASDAQ agreed to integrate quotes from electronic communications networks (ECNs) into its public display. This allowed ECNs to compete for trades and led to the SEC adopting Alternative Trading System Regulations, which gave ECNs the right to register as stock exchanges.</p>

    <p>The SEC has continued to reduce the minimum tick size, which has resulted in a reduction of bid-ask spreads. In the 1990s, exchanges around the world began adopting electronic trading systems and the NASDAQ Stock Market was established as a separate entity. In 2006, the NYSE acquired the electronic Archipelago Exchange and renamed it the NYSE Arca. In 2007, the SEC fully implemented Regulation NMS, which required exchanges to honor quotes from other exchanges when they could be executed automatically.</p>

    <p>Today, trading is almost exclusively electronic for stocks, with bonds still being traded in traditional dealer markets.</p>
  </li>
  <li>
    <p>U.S. Markets</p>

    <p>The NYSE and NASDAQ Stock Market are the two largest US stock markets. But other ECNs (namely BATS, NYSE Arca, Direct Edge,…) have steadily increased their market share.</p>

    <ul>
      <li>
        <p>NASDAQ</p>

        <p>The NASDAQ Stock Market lists 3,000 firms and its trading platform has improved over the years. Currently, the NASDAQ Market Center integrates NASDAQ’s previous electronic markets into a single system.</p>

        <p>In 2008, NASDAQ merged with OMX, a Swedish-Finnish company that controls seven Nordic and Baltic stock exchanges, to form NASDAQ OMX Group. This group manages not only the NASDAQ Stock Market, but also several stock markets in Europe, as well as options and futures exchanges in the US.</p>

        <p>NASDAQ has three levels of subscribers:</p>

        <ul>
          <li>
            <p>Level 3: The highest level of registered market makers. These firms create a market in securities, maintain inventories of securities, and post bid and ask prices at which they are willing to buy or sell shares. They can continuously enter and change bid-ask quotes and have the fastest execution of trades. They profit from the spread between bid and ask prices.</p>
          </li>
          <li>
            <p>Level 2: Receive all bid and ask quotes but cannot enter their own quotes. They can see which market makers are offering the best bid and ask prices. They are usually brokerage firms that execute trades for their clients but do not actively deal in stocks for their own account.</p>
          </li>
          <li>
            <p>Level 1: Receive only inside quotes, i.e., the best bid and ask prices, but do not see the number of shares being offered. They are usually investors who are not actively buying or selling, but want information on current prices.</p>
          </li>
        </ul>
      </li>
      <li>
        <p>NYSE</p>

        <p>The NYSE (New York Stock Exchange) is the largest stock exchange in the US, measured by the value of stocks listed on the exchange. On a daily basis, the NYSE has a trading volume of approximately one billion shares.</p>

        <p>In 2006, the NYSE merged with Archipelago Exchange to form NYSE Group, a publicly-held company. In 2007, NYSE Group merged with Euronet to form NYSE Euronext. In 2008, NYSE Euronext acquired the American Stock Exchange, which was then renamed as NYSE Amex to focus on smaller firms. NYSE Arca is the firm’s electronic communication network, where the majority of exchange-traded funds are traded. In 2012, NYSE Euronext was acquired by International Exchange (ICE), a company primarily focused on energy-future trading. ICE plans to retain the NYSE Euronext name and the iconic trading floor on Wall Street.</p>

        <p>The NYSE has many trading specialists who rely heavily on human involvement in trade execution. The exchange began its transition to electronic trading in 1976 with the introduction of DOT (Designated Order Turnaround) and later the SuperDOT system, which routes orders directly to specialists. In 2000, the NYSE launched Direct+, which allowed for automatic cross of smaller trades (up to 1,099 shares) without human interaction. In 2004, Direct+ began eliminating the transaction size limit. The transition to electronic trading accelerated in 2006 with the introduction of the NYSE Hybrid Market, which allowed brokers to send orders for either immediate electronic execution or to a specialist for price improvement. The Hybrid System allowed the NYSE to remain as a fast market for purposes of Regulation NMS while still offering the benefits of human intervention for more complex trades. Note that NYSE Arca is fully electronic.</p>
      </li>
      <li>
        <p>ECNs</p>

        <p>Over time, automated markets have gained a larger market share. Today, some of the largest ECNs include BATS, Direct Edge, and NYSE Arca. Brokers affiliated with an ECN have computer access and can enter orders into the limit order book. When orders are received, if a matching trade is found, the trade is immediately executed.</p>

        <p>Initially, ECNs were only open to traders using the same system. However, after the implementation of Regulation NMS, ECNs started to list limit orders on other networks.</p>

        <p>These cross-market links have paved the way for more popular strategies, such as high-frequency trading, which aim to profit from even small price differences across the market. Speed is critical in these strategies, and ECNs compete based on the speed they can offer. Latency refers to the time it takes to accept, process, and execute a trading order. For example, BATS advertises latency times of around 200 milliseconds.</p>
      </li>
    </ul>
  </li>
  <li>
    <p>New Trading Strategies</p>

    <p>Electronic trading has introduced new opportunities for various trading strategies and tools. One such strategy is algorithmic trading, where the trading decisions are handed over to computer programs. Another type of algorithmic trading is high frequency trading, which involves the use of computer programs to initiate trades in a matter of milliseconds, much faster than a human could process. This type of trading brings a large amount of liquidity to the market, but it can also lead to a rapid withdrawal of liquidity, as seen in the flash crash of 2010. Dark pools are another aspect of electronic trading, where the trading takes place in an anonymous manner, but it can have an impact on market liquidity.</p>

    <ul>
      <li>
        <p>Algorithmic Trading</p>

        <p>Algorithmic Trading” involves using computer programs to make trading decisions. It is estimated that more than half of all equities traded in the US are initiated by algorithms. These strategies were made possible by the decimalization of the minimum tick size.</p>

        <p>There are different types of algorithmic trading, including exploiting short-term trends, pair trading to take advantage of temporary disruptions in the normal price relationship between stocks, and exploiting discrepancies between stock prices and stock index future contract prices.</p>

        <p>Some algorithms aim to profit from the bid-ask spread by quickly buying a stock at the bid price and selling it at the ask price before the price changes.</p>
      </li>
      <li>
        <p>High Speed Frequency Trading</p>

        <p>Algorithmic trading strategies often require extremely fast trade initiation and execution, and high-frequency trading is a subset of algorithmic trading that uses computer programs to make rapid decisions. These trades compete for opportunities that offer small profits, but they can add up to significant amounts.</p>

        <p>Some algorithmic strategies profit from the bid-ask spread, while others rely on cross-market arbitrage, taking advantage of even tiny price differences across markets. The firms that are quickest to identify and execute these trades win the profits. Today, trade execution times for high-frequency trades are measured in milliseconds or even microseconds, and firms are locating their trading centers near electronic exchange centers for faster access.</p>

        <p>The location of trading centers has become crucial in this high-speed competition. A trade order originated in Chicago, for example, takes 5 milliseconds to reach New York. During this time, another firm located in New York could win the trade. ECNs today claim latency periods of 1 millisecond.</p>
      </li>
      <li>
        <p>Dark Pools</p>

        <p>Many big traders prefer to remain anonymous when buying or selling large amounts of stocks as the public knowing about their transactions can affect the stock prices.</p>

        <p>Traditionally, large trades (known as “Blocks” with more than 10,000 shares) were handled by “block houses,” which are brokerage firms that specialize in matching buyers and sellers of large blocks. These brokerages execute trades privately, avoiding price movements against their clients.</p>

        <p>However, block trades have now been replaced by “Dark Pools,” which are trading systems where participants can buy or sell large blocks of securities without revealing their identities or the details of the trades. This contributes to the fragmentation of the markets, as fewer orders are visible on consolidated limit order books, potentially leading to an unfair public price that does not reflect all available information about the security demand.</p>

        <p>Another approach to dealing with large trades is to divide them into smaller trades, which can be executed on electronic markets, thereby hiding the fact that a large amount of shares have been bought or sold. This has led to a rapid decline in the average trade size, which is now around 300 shares.</p>
      </li>
      <li>
        <p>Bond Trading</p>

        <p>In 2006, the NYSE gained regulatory approval to list debt issues from any NYSE-listed company on its bond-trading system. This made it easier for bonds to be listed and resulted in the expansion of NYSE’s electronic bond-trading platform, now known as NYSE Bonds, which is now the largest centralized bond market in the US.</p>

        <p>It’s important to note that the majority of bond trading still takes place in the over-the-counter (OTC) market among bond dealers, even for bonds listed on the NYSE. Major players in the bond market include Merrill Lynch (now part of Bank of America), Salomon Smith Barney (a division of Citigroup), and Goldman Sachs.</p>

        <p>However, the bond market also has liquidity risks, which can make it difficult to sell holdings quickly if necessary.</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Flash Crash of May 2010</p>

    <p>On May 6, 2010, the Dow Jones Industrial average experienced a rapid drop in value. At 2:42 PM New York time, the market was down by approximately 300 points due to concerns about the European debt crisis. However, within the next five minutes, the Dow plummeted an additional 600 points. After 20 minutes, it regained most of those losses. This sudden drop caused a number of stocks, such as Accenture, to plummet, while others, such as Apple and Hewlett-Packard, experienced huge spikes.</p>

    <p>A subsequent report by the SEC revealed that many algorithmic trading programs were the cause of the market’s sudden drop. As these programs withdrew, liquidity evaporated and buyers disappeared. Trading was temporarily suspended, and when it resumed, buyers took advantage of the market and prices bounced back quickly. The NYSE and NASDAQ cancelled trades executed more than 60% away from the opening price of the day.</p>

    <p>In response to this event, the SEC approved a rule to halt trading for five minutes in stocks that experience a rise or fall of more than 10% in a five-minute period. This is intended to prevent algorithmic trading from rapidly moving share prices before human traders have a chance to determine if the changes are due to fundamental information.</p>
  </li>
  <li>
    <p>Globalization of Stock Markets</p>

    <p>NYSE-Euronext is the largest equity market as measured by total market value of listed firms.</p>

    <p>The securities market is facing pressure to form international alliances or mergers due to the rise of electronic trading. Traders view stock markets as computer networks that connect them to other traders, allowing them to trade a wider range of securities from around the world.</p>

    <p>To stay competitive, it is crucial to have efficient and cost-effective mechanisms for executing and clearing trades.</p>

    <ul>
      <li>
        <p>In the US:</p>

        <ul>
          <li>The NYSE merged with Archipelago ECN in 2006 and acquired the American Stock Exchange in 2008.</li>
          <li>NASDAQ acquired Instinet in 2005 and the Boston Stock Exchange in 2007.</li>
          <li>In the derivative market, the Chicago Mercantile Exchange acquired the Chicago Board of Trade in 2007 and the New York Mercantile Exchange in 2008.</li>
        </ul>
      </li>
      <li>
        <p>In Europe:</p>

        <ul>
          <li>Euronext was formed through the merger of the Paris, Brussels, Lisbon, and Amsterdam exchanges, and later purchased Liffe, a derivatives exchange based in London.</li>
          <li>The London Stock Exchange merged with Borsa Italiana, which operates the Milan exchange, in 2007.</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<figure>
    <picture>
        

        <!-- Fallback to the original file -->
        <img src="/assets/img/bodie/fig-3.8-biggest-stock-markets.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

    </picture><figcaption class="caption">The biggest stock markets in the world bby domestic market capitalization in 2012</figcaption>

</figure>

<ul>
  <li>
    <p>Intercontinental:</p>

    <ul>
      <li>The NYSE Group and Euronext merged in 2007.</li>
      <li>In 2011, Deutsche Borse and NYSE Euronext announced their intention to merge, but the proposed merger fell through in early 2012 after European Union antitrust regulators recommended blocking the combination.</li>
      <li>The NYSE and the Tokyo Stock Exchange have announced plans to link their networks, giving their customers access to both markets.</li>
      <li>NASDAQ Stock Market merged with OMX, which operates Nordic and Baltic stock exchanges, in 2007 to form NASDAQ OMX.</li>
      <li>In 2008, Eurex acquired International Securities Exchange (ISE) to form a major options exchange.</li>
    </ul>
  </li>
  <li>
    <p>Trading Costs</p>

    <p>When trading securities, there is always a fee involved, which is paid to the broker. There are two types of brokers: full-service and discount brokers.</p>

    <ul>
      <li>
        <p>Full-service brokers offer a range of services and are often referred to as account executives or financial consultants. In addition to executing orders, holding securities for safekeeping, offering margin loans, and facilitating short sales, they also provide investment information and advice. These brokers have a research team that prepares analysis and forecasts of general economics, industry, and company conditions, and makes specific buy or sell recommendations. Some customers establish discretionary accounts, which allow the broker to make buy and sell decisions on their behalf. However, this requires a high level of trust since the broker could execute trades solely for the purpose of commission.</p>
      </li>
      <li>
        <p>Discount brokers, on the other hand, offer basic services such as buying and selling securities, holding them for safekeeping, offering margin loans, and facilitating short sales. They do not provide any additional information or advice, only price quotes. Many banks, thrift institutions, and mutual fund management companies now offer these services. Some discount brokers, such as Schwab, E*Trade, or TD Ameritrade, now offer commissions below $10.</p>
      </li>
    </ul>

    <p>In addition to the explicit trading fee, which is the broker’s commission, there is also an implicit fee in the form of the dealer’s bid-ask spread. Some brokers may offer no commission, but instead collect their fee entirely in the form of the bid-ask spread.</p>
  </li>
  <li>
    <p>Buying on Margin</p>

    <p>Investors have the option to finance their securities purchases through a source of debt financing known as broker’s call loans or buying on margin. This means that the investor borrows part of the purchase price from a broker and only contributes a portion of the total cost, known as the margin. The broker then borrows the remaining amount from banks at a call money rate and charges their clients this rate, along with a service charge, for the loan.</p>

    <p>All securities purchased on margin must be kept with the brokerage firm and serve as collateral for the loan. The Federal Reserve System regulates the extent to which stock purchases can be financed through margin loans, with the current requirement being that the investor must pay 50% of the purchase price in cash.</p>

    <ul>
      <li>
        <p>Example on Margin Call</p>

        <p>The concept of percentage margin refers to the relationship between the equity value of an investment account and the market value of the securities it holds. It is calculated as the ratio of the net-worth of the account to the market value of the securities.</p>

        <p>For example, if an investor pays $6,000 towards the purchase of $10,000 worth of stock (100 shares at $100 each), and borrows the remaining $4,000 from the broker, the initial percentage margin would be 60% ($6,000/$10,000).</p>

        <p>However, if the stock price drops to $70 per share, the total value of the stock would be $7,000. With the loan from the broker still at $4,000, the investor’s equity would be $3,000 ($7,000 - $4,000), and the percentage margin would drop to 43% ($3,000/$7,000).</p>

        <p>To avoid the situation where the stock value falls below the loan from the broker, resulting in a negative equity, brokers set a maintenance margin. This requires the investor to add new cash or securities to the account if the percentage margin falls below a certain level. If the investor does not act, the broker may sell securities from the account to restore the margin to an acceptable rate.</p>

        <p>For instance, if the maintenance margin is 30%, the stock price can fall to $57.13 before the margin would fall below the required level.</p>
      </li>
      <li>
        <p>Why to buy in Margin</p>

        <p>Investors often buy securities on margin to invest more than their own money allows. This gives them the potential for greater upside, but also exposes them to greater downside risk.</p>

        <p>For example, an investor who buys 100 shares of stock A at $100 each (for a total cost of $10,000) would expect a 30% return if the price increases 30%. However, if the investor takes a margin call with 9% interest per year, they can buy 200 shares for $20,000. If the price of each share increases 30% to $130, the investor would make a profit of $15,100 ($26,000 worth of stock - $10,900 in principal and interest). This results in a 51% return on the initial $10,000 investment, compared to the original 30% return.</p>

        <p>However, if the price of each share drops 30% to $70, the 200 shares would be worth $14,000 and the investor would be left with only $3,100 after paying off the $10,900 in principal and interest, resulting in a 69% loss instead of the original 30% drop.</p>
      </li>
      <li>
        <p>Short Sales</p>

        <p>Short sales are the opposite of buying stocks. In a short sale, an investor borrows a stock from a broker and sells it with the expectation that the stock price will decrease. The investor then must buy the same stock to replace the borrowed one and make a profit if successful. The short seller must also pay any dividends paid during the short sale to the lender of the security. The profits from a short sale must be kept with the broker and the short seller must also provide margin to cover any potential losses if the stock price increases during the short sale. Short sellers must also be mindful of margin calls, just like investors who buy stocks on margin. If the stock price increases, the margin in their account will decrease and if it drops to the maintenance level, they will receive a margin call.</p>

        <p>The short sale process begins when the short seller borrows a stock from their brokerage firm, which holds a variety of securities for other investors. The short seller then sells the stock, hoping that the price will fall, allowing them to buy the same stock at a lower price to replace the borrowed one. If the brokerage cannot locate new shares to replace the ones sold, the short seller will need to purchase shares in the market to repay the loan. The exchange rules require that the profits from a short sale must be kept with the broker and cannot be invested. However, large investors may receive some income from the profits held by the broker. The short seller must also provide margin to cover any potential losses if the stock price increases during the short sale.</p>
      </li>
      <li>
        <p>Example</p>

        <p>Suppose you are pessimistic about a stock with 100$ price per share (you think the price will drop). You order short-sell on 1,000 stocks. Then the brokerage will borrow 1,000 stocks from another investor account or borrows the stock from another brokerage. Suppose, they ask for margin call of 0.5, this means that they require you to have at least 50,000$ in your account that can serve as margin on short-sell. Let’s say you have 50,000$ on T-Bills.</p>

        <p>First of all, your initial percentage of margin (the ratio of the equity in the account, 50,000$, to the current value of the shares you have borrowed and eventually must return, 10,000$) is as</p>

\[\text{Margin} = \frac{\text{Equity}}{\text{Value of stock owed}} = \frac{50,000}{100,000} = 0.5\]

        <p>Now, suppose the price of the stock drops to 70$ a share, this way, your profit would be 30,000$, since you need to buy 1,000 shares of stocks with 70$ a share to replace.</p>

        <p>Suppose, the broker has a maintenance margin of 30\% on short sales. This means that equity in your account must be at least 30\% of the value of your short position at all times. Then, you might ask, how much can the price increase before a margin call. Suppose \(P\), denotes the price of stock per share. We have</p>

\[\frac{150,000-1000P}{1000P} = 0.3 \text{ so } P=115.38\$\]

        <p>which means that \(P = 115.38\) per share, you would receive a margin call. This is the whole reason we have stop-buy orders. You can put a stop-buy order at 110$ a share, to limit your losses to 10$ per share, instead of loosing 15$ per share and receiving a margin call order.</p>

        <p>During the financial crisis, the SEC puts restriction on short-sells. For instance in 2008, the SEC voted to restrict short sales in stocks that decline by at least 10\% on a given day.</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Regulations of Securities Markets</p>

    <p>The United States has a number of laws that regulate the trading of securities. The two main pieces of legislation are the Securities Act of 1933 and the Securities Act of 1934.</p>

    <p>The Securities Act of 1933 requires companies to provide complete and accurate information about new securities they issue and to register these securities with the SEC. The SEC’s approval of the registration only means that all relevant information has been disclosed, not that the security is a good investment. Investors must make their own evaluation of the security’s value.</p>

    <p>The Securities Act of 1934 established the Securities and Exchange Commission (SEC) to enforce the provisions of the 1933 Act. It also requires companies to periodically disclose relevant financial information and gives the SEC the power to regulate securities exchanges, OTC trading, brokers, and dealers. The SEC works with other regulatory agencies, such as the Commodity Futures Trading Commission (CFTC) and the Federal Reserve, to regulate the securities market. The Federal Reserve is responsible for setting margin requirements for stocks and stock options and regulates bank lending to security market participants.</p>

    <p>The Securities Investor Protection Act of 1970 established the Securities Investor Protection Corporation (SIPC) to protect investors in the event of a failed brokerage firm. The SIPC ensures that securities held in street name by a failed brokerage firm will be returned to the investors up to a limit of $500,000 per investor. The SIPC is funded by insurance premiums levied on its member brokerage firms.</p>

    <p>In addition to federal regulations, state laws, known as blue sky laws, also regulate securities trading. These laws aim to provide investors with a clearer view of investment prospects. Many states have adopted portions of the Uniform Securities Act of 1956, which helped to unify state laws.</p>

    <p>The Financial Stability Oversight Council (FSOC) was established in 2008 as part of the Dodd-Frank Wall Street Reform and Consumer Protection Act to monitor the stability of the US financial system and identify risks posed by large, interconnected banks. The FSOC is comprised of the chairpersons of the major US regulatory agencies, and serves as a coordinating body for key financial regulators.</p>

    <p>Finally, two other agencies also protect investors. The Federal Deposit Insurance Corporation provides depositors with federal protection in the event of bank failures. The SIPC ensures that investors will receive their securities in the event of a failed brokerage firm.</p>

    <ul>
      <li>
        <p>Self-Regulation</p>

        <p>In addition to government regulation, the securities market has self-regulatory organizations. One of the most important is the Financial Industry Regulatory Authority (FINRA), which is the largest non-government regulator of all securities firms in the United States. FINRA was formed in 2007 through the consolidation of the National Association of Securities Dealers (NASD) and the self-regulatory arm of the New York Stock Exchange. Its main mission is to protect investors and maintain market integrity. It examines securities firms, creates and enforces rules regarding trading practices, and provides a dispute resolution forum for investors and registered firms.</p>

        <p>Another important self-regulatory organization is the CFA Institute, which has established standards of professional conduct for members with the Chartered Financial Analyst (CFA) designation. These standards govern the behavior of CFAs in the securities market.</p>
      </li>
      <li>
        <p>The Sarbanes-Oxley Act</p>

        <p>The stock market scandals of 2000-2002 were largely focused on three unethical practices: (1) unfair allocation of shares in initial public offerings (IPOs), (2) biased securities research, and (3) misleading recommendations to the public.</p>

        <p>In response to these problems, the Sarbanes-Oxley Act was passed by the US Congress in 2002, implementing several key reforms in the financial industry. The Act established the Public Company Accounting Oversight Board to oversee the auditing of public companies, and set rules for independent financial experts to serve on the audit committees of firms’ boards of directors. Additionally, CEOs and CFOs were required to personally certify the accuracy of their firms’ financial reports, and faced penalties if the reports turned out to be misleading. The Act also limited auditors’ ability to provide certain services to clients in order to prevent potential conflicts of interest. Finally, the Board of Directors must be comprised of independent directors and hold regular meetings without the presence of company management.</p>

        <p>However, in recent years, there have been pushbacks against the Sarbanes-Oxley Act. Some believe that the compliance costs imposed by the law are too high, particularly for smaller firms, and that this heavy-handed regulation is giving foreign countries an advantage over the US in attracting securities listings.</p>
      </li>
      <li>
        <p>Insider Trading</p>

        <p>Insider trading refers to the illegal practice of using confidential information to profit from securities transactions. This information, held by officers, directors, or major stockholders of a company, is not yet known to the public. The definition of who is considered an “insider” can be ambiguous, as it is clear that top executives are insiders, but the status of other individuals, such as major suppliers, may be less clear. The dividing line between legal private information and illegal inside information can be vague.</p>

        <p>The SEC requires insiders to report all transactions in the company’s stock and publishes a monthly summary of these transactions to inform the public. However, despite regulations, evidence suggests that insiders do exploit their knowledge for personal gain. This is evidenced by well-publicized convictions of individuals involved in insider trading schemes, evidence of information leaking to some traders before public announcements, and the returns earned on trades by insiders. A study by Jaffee found that stocks had an abnormal return of about 5% over the 8 months following insider purchases, and tended to perform poorly when insiders sold more than they bought.</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Mutual Funds and Other Investment Companies</p>

    <p>Investors typically work with intermediaries when investing their funds. The most common intermediaries are:</p>

    <ul>
      <li>Mutual Funds or open-end investment companies (the most important one)</li>
      <li>Unit investment trusts</li>
      <li>hedge funds</li>
      <li>close-end funds</li>
    </ul>
  </li>
  <li>
    <p>Investment Companies</p>

    <p>Investment companies are financial intermediaries that pool money from individual investors and invest those funds in a variety of securities and assets. The concept behind investment companies is to bring together the resources of many small investors to achieve the benefits of large-scale investing.</p>

    <p>These companies provide several important services, including:</p>

    <ul>
      <li>Record Keeping and Administration: Investment companies issue periodic reports, keep track of investments, dividends, and capital gains distributions, and may automatically reinvest dividends and interest income for shareholders.</li>
      <li>Diversification and Divisibility: By pooling their money, investment companies allow investors to own fractional shares of a variety of securities, acting as large investors even if an individual shareholder could not.</li>
      <li>Professional Management: Investment companies employ security analysts and portfolio managers to attempt to achieve superior investment results for their investors.</li>
      <li>Lower Transaction Costs: By trading large blocks of securities, investment companies can save on brokerage fees and commissions.</li>
    </ul>

    <p>Since investment companies pool assets of individual investors, they also need to divide those assets among investors. Investors buy shares in investment companies and ownership is proportional to the number of shares purchased. The value of each share is called <em>net asset value</em> or <em>NAV</em>. Net asset value equals assets minus liabilities expressed on a per-share basis.</p>

\[\text{Net Asset Value } = \frac{\text{Market value of assets minus liabilities}}{\text{Shares outstanding}}\]

    <p>For instance, suppose a mutual fund that manages protfolio of securities worth of 120$ million. The company owes 4$ million to investment advisors, and another 1$ million for rent, wages due, and miscellaneous expenses. The company has 5 million shares outstanding, so the net asset value is</p>

\[\text{Net Asset Value } = \frac{120-4-1}{5} = 23\$ \text{ per share}\]

    <ul>
      <li>
        <p>Types of Investment Companies</p>

        <p>The Investment Companies Act of 1940 classifies the investment companies as either <em>unit investment trusts</em> or <em>managed investment companies</em>.</p>

        <p>The portfolio of unit investment companies is fixed and thus are called “unmanaged”. In contrast, managed companies are so named because securities in their investment portfolios continually are bought and sold, hence “managed”. Managed companies are futhur classified as either <em>closed-end</em> or <em>open-end</em> companies. Open-end companies are what we commonly call mutual funds.</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Unit Investment Trusts</p>

    <p>Unit Investment Trusts (UITs) are investment vehicles that pool money from individual investors to purchase a fixed portfolio of securities. Unlike mutual funds, the composition of the portfolio remains unchanged for the life of the fund.</p>

    <p>UITs are sponsored by brokerage firms or other financial institutions, who purchase the underlying securities and deposit them into a trust. They then sell shares, called redeemable trust certificates, to investors. All income and payments of principal from the portfolio are distributed to the shareholders by the trustees, typically a bank or trust company.</p>

    <p>UITs are considered unmanaged, as there is no active management of the portfolio once it is established. They typically invest in one particular type of asset, such as municipal or corporate bonds, which provides investors with a pool of a specific asset class to invest in.</p>

    <p>The sponsors of UITs earn their profit by selling shares at a premium over the cost of acquiring the underlying assets. Investors who wish to sell their holdings can either receive payment from the trustee or have their shares sold to a new investor.</p>

    <p>However, UITs have steadily lost market share to mutual funds, declining from $105 billion in 1990 to $60 billion in 2012.</p>
  </li>
  <li>
    <p>Managed Investment Companies
  Actively managed investment companies come in two types: closed-end and open-end. Both types have a board of directors elected by shareholders who hire a management company to manage the portfolio for an annual fee, typically ranging from 0.2% to 1.5% of assets. The management company is often the firm that organized the fund, for example Fidelity Management and Research Corporation sponsors Fidelity mutual funds and manages them, assessing a management fee on each fund. In some cases, a mutual fund may hire an outside portfolio manager, such as Wellington Management for Vanguard.</p>

    <p>Open-end funds are always ready to issue or redeem shares at their net asset value, though both purchases and redemptions may come with sales charges. When an investor wants to cash out, they can sell their shares back to the fund at net asset value. Most mutual funds are open-end.</p>

    <p>Closed-end funds, on the other hand, do not issue or redeem shares. Investors who want to cash out must sell their shares to other investors. Shares of closed-end funds are traded on organized exchanges and can be purchased through brokers, like common stocks. Their price can vary from the net asset value. In 2013, closed-end funds held $265 billion in assets.</p>

    <p>Closed-end funds and open-end funds are two types of actively managed investment companies. The difference between the two is in how shares are bought and sold. A closed-end fund has a fixed number of shares that are traded on an organized exchange and can be purchased through a broker, just like a common stock. The price of these shares can vary from the net asset value (NAV) of the fund. When a closed-end fund is initially issued, the price may be above the NAV, but it often falls to a discount after some time.</p>

    <p>On the other hand, open-end funds have no fixed number of shares, and investors buy and sell shares directly from the investment company at NAV. The number of outstanding shares changes daily. Open-end funds do not trade on organized exchanges, but they may carry a load, which is a sales charge.</p>

    <p>When considering a list of closed-end funds, the first column shows the name and ticker symbol of the fund, followed by the most recent NAV and the closing share price. The premium or discount is the percentage difference between the price and NAV. The last column shows the 52-week return, which is the percentage change in the share price plus dividend income.</p>

    <p>It is important to note that closed-end funds usually sell at a discount to NAV, while the price of open-end funds cannot fall below NAV, as these funds are ready to redeem shares at NAV.</p>
  </li>
  <li>
    <p>Other Investment Organization</p>

    <p>Some intermediaries are not formally organized or regulated as investment companies, nevertheless they have similar functions. Three of the most important ones are: <em>Commingled Funds</em>, <em>Real Estate Investment Trusts</em>, and <em>Hedge Funds</em>.</p>

    <ul>
      <li>
        <p>Commingled Funds</p>

        <p>Commingled funds are investment partnerships in which investors pool their funds and the management firm, such as a bank or insurance company, manages the funds for a fee. They are similar to open-end mutual funds and offer units instead of shares, which are bought and sold at net asset value. These funds are often created for trust or retirement accounts that are too small to be managed separately but still larger than the portfolios of most individual investors. A bank or insurance company may offer a variety of commingled funds, including money market funds, bond funds, and stock funds.</p>
      </li>
      <li>
        <p>Real Estate Investment Trust (REITs)</p>

        <p>A Real Estate Investment Trust (REIT) is a type of investment company that invests in real estate or loans secured by real estate. It operates similarly to a closed-end mutual fund, where capital is raised through the issuance of shares and borrowing from banks, issuing bonds or mortgages. Most REITs are highly leveraged, with a typical debt ratio of 70%.</p>

        <p>There are two main types of REITs:</p>

        <ul>
          <li>Equity Trusts, which invest directly in real estate</li>
          <li>Mortgage Trusts, which primarily invest in mortgage and construction loans.</li>
        </ul>
      </li>
      <li>
        <p>Hedge Funds</p>

        <p>Hedge funds are investment vehicles that allow private investors to pool their assets and have them managed by a fund manager. Unlike mutual funds, hedge funds are structured as private partnerships and subject to minimal regulation by the SEC. They are usually only open to wealthy individuals or institutions and often require investors to agree to a lock-up period, where the investment cannot be withdrawn for a set amount of time.</p>

        <p>The lack of regulation allows hedge fund managers to pursue investment strategies that are not available to mutual fund managers, such as heavy use of derivatives, short sales, and leverage. Hedge funds can invest in a wide range of assets, with some focusing on derivatives, distressed firms, currency speculation, convertible bonds, emerging markets, merger arbitrage, and more. They are empowered to adjust their investment strategies as investment opportunities change.</p>

        <p>Hedge funds have experienced tremendous growth over the years, increasing from $50 billion in 1990 to $2 trillion in 2012.</p>
      </li>
      <li>
        <p>Mutual Funds</p>

        <p>Mutual funds are widely referred to as open-end investment companies. They are the leading type of investment companies, with a market share of over 90%. In 2013, they managed over $13 trillion in assets in the US and an additional $13.5 trillion in non-US assets.</p>

        <ul>
          <li>
            <p>Investment Policies</p>

            <p>Each mutual fund has a specific investment policy outlined in its prospectus. For example, money market funds invest in short-term low-risk money market instruments, while bond funds invest in fixed-income securities. Some funds may be more narrowly defined, such as a bond fund that invests primarily in Treasury bonds or mortgage-backed securities.</p>

            <p>Management companies manage a family or “complex” of funds and collect a management fee for operating them. By managing a collection of funds under one umbrella, they make it easy for investors to allocate assets across market sectors or switch assets across funds while still benefiting from centralized record-keeping. Well-known management companies include Fidelity, Barclays, and T. Rowe Price. In 2013, there were nearly 8,000 mutual funds in the US with over 700 fund complexes.</p>

            <p>Some west known management companies are <em>Fidelity</em>, <em>Barclays</em>, and * T Rowe Price*. Each offer an array of open-end mutual funds with different investment policies. In 2013m thre were nearly 8,000 mutual funds in US which offered more than 700 fund compleses.</p>
          </li>
        </ul>
      </li>
      <li>
        <p>Funds Categories</p>

        <p>By investment policies funds are commonly classified into one or more of the following groups:</p>

        <ul>
          <li>
            <p>Money Market Funds: These funds invest in short-term, low-risk money market securities such as commercial paper, repurchase agreements, or certificates of deposit. They usually offer check-writing features and have a fixed NAV of $1 per share, without any tax implications associated with redemption of shares.</p>
          </li>
          <li>
            <p>Equity Funds: These funds primarily invest in stocks and may also hold fixed-income or other types of securities at the discretion of the portfolio manager. Equity funds typically hold 4-5% of total assets in money market securities for liquidity. They can be further classified by their emphasis on capital appreciation versus current income and the level of risk they assume.</p>
          </li>
          <li>
            <p>Sector Funds: These are a type of equity funds that concentrate on a specific industry, such as biotechnology, utilities, energy, or telecommunications.</p>
          </li>
          <li>
            <p>Bond Funds: These funds specialize in fixed-income securities, including corporate bonds, Treasury bonds, mortgage-backed securities, or municipal bonds. Some funds also specialize by maturity or credit risk of the issuer.</p>
          </li>
          <li>
            <p>International Funds: These funds have an international focus and can be global, international, regional, or emerging market funds.</p>
          </li>
          <li>
            <p>Balanced Funds: These funds are designed to be candidates for an individual’s entire investment portfolio and hold both equities and fixed-income securities in stable proportions. Some balanced funds are also funds of funds, investing in shares of other mutual funds.</p>
          </li>
          <li>
            <p>Asset Allocation and Flexible Funds: These funds hold both stocks and bonds, but the proportions allocated to each market may vary in accordance with the portfolio manager’s forecast of their relative performance.</p>
          </li>
          <li>
            <p>Index Funds: These funds match the performance of a broad market index by buying shares in securities included in the index in proportion to their representation. Index funds can be tied to non-equity markets as well, such as bonds or real estate.</p>
          </li>
        </ul>

        <p>In 2012, 15% of equity funds were indexed. With nearly 8,000 mutual funds in the US offering over 700 fund complexes, there are many options for investors to choose from to match their investment goals.</p>
      </li>
    </ul>
  </li>
  <li>
    <p>How Funds are sold?</p>

    <p>Mutual funds can be sold either directly by the underwriter or through brokers acting on behalf of the underwriter.</p>

    <p>Funds that are sold directly are marketed through the mail, various offices of the fund, over the phone, or over the internet. Investors can purchase shares by contacting the fund directly.</p>

    <p>Around half of the mutual funds are sold through a sales force. Brokers or financial advisors receive a commission for selling shares to investors. This commission is ultimately paid by the investor. People who rely on their broker’s advice to choose mutual funds should be aware that brokers may have a conflict of interest when it comes to fund selection. This is because some fund companies practice “revenue sharing,” where they pay the brokerage firm for being favored in investment recommendations.</p>

    <p>Many mutual funds are also sold through “financial supermarkets,” which sell shares in funds from multiple complexes. Instead of charging customers a sales commission, the broker splits the management fees with the mutual fund company. This results in a unified record-keeping system for all funds purchased from the supermarket, even if the funds are offered by different complexes. However, these supermarkets lead to higher expenses ratios because mutual funds pass along the costs of participating in these programs in the form of higher management fees.</p>
  </li>
  <li>
    <p>Costs of Investing in Mutual Funds</p>

    <p>Fee Structure:</p>

    <p>When investing in a mutual fund, it’s important to consider factors like investment policy, past performance, and management fees and expenses. The mutual fund information can be found in the Morningstar’s Mutual Fund Sourcebook, which is widely available at libraries and universities.</p>

    <p>It’s essential for investors to be aware of the different types of fees involved in mutual funds:</p>

    <ul>
      <li>
        <p>Operating Expenses: These expenses include administrative costs and advisory fees paid to the investment managers. They are expressed as a percentage of total assets under management and can range from 0.2% to 2%. These expenses are periodically deducted from the fund’s assets, so shareholders pay for them through reduced portfolio value. The average expense ratio for equity funds in the US in 2011 was 1.43%, but larger funds have lower ratios, bringing the weighted average down to 0.79%. Actively managed funds tend to have higher expense ratios than indexed funds (0.93% versus 0.14%).</p>
      </li>
      <li>
        <p>Front-End Load: A front-end load is a sales charge or commission paid when you purchase shares. This charge is usually paid to brokers who sell the funds and can be up to 8.5%, but in practice, it’s usually no more than 6%. Low-load funds have loads of up to 3%, while no-load funds have no front-end sales charges.</p>
      </li>
      <li>
        <p>Back-End Load: A back-end load is a redemption or exit fee incurred when you sell your shares. Funds that impose back-end loads usually start at 5% or 6% and decrease by 1% each year that the fund is invested. These fees, also known as contingent deferred sales charges, decrease over time, for example, starting at 6% and reducing to 4% at the beginning of the third year.</p>
      </li>
      <li>
        <p>12b-1 Charges: The SEC allows the managers of 12b-1 funds to use fund assets to pay for distribution costs such as advertising, promotional literature, and commissions paid to brokers who sell the fund to investors. These 12b-1 charges, along with front-end loads, are used to pay brokers. Like front-end charges, 12b-1 charges are deducted from the fund’s assets and limited to 1% of an annual fund’s average net assets per year.</p>
      </li>
    </ul>

    <p>Many funds ofer “classes” that represent ownership in the same portfolio of securities, but with different combinations of fees. For instance look at the following table</p>

    <table>
      <thead>
        <tr>
          <th> </th>
          <th>Class A</th>
          <th>Class B</th>
          <th>Class C</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>Front-end load</td>
          <td>0-4.5\%</td>
          <td>0</td>
          <td>0</td>
        </tr>
        <tr>
          <td>Back-end load</td>
          <td>0</td>
          <td>0-1\%</td>
          <td>0</td>
        </tr>
        <tr>
          <td>12b-1 Fees</td>
          <td>0.25\%</td>
          <td>1.0\%</td>
          <td>0</td>
        </tr>
        <tr>
          <td>Expense Ratio</td>
          <td>0.70\%</td>
          <td>0.70\%</td>
          <td>0.70\%</td>
        </tr>
      </tbody>
    </table>

    <p>When investing in mutual funds, each investor must consider the cost and decide which combination of fees is best for them. Directly purchasing no-load funds from the mutual fund group is often the most cost-effective option, but many investors choose to pay for financial advice and the accompanying commission to their adviser.</p>

    <p>For investors who purchase funds through a broker, the choice between a front-end load and an annual 12b-1 fee will depend on their expected time horizon. Front-end loads are paid only once, while 12b-1 fees are paid annually. For a long-term investment, a one-time front-end load may be more favorable.</p>
  </li>
  <li>
    <p>Fees and Mutual Fund Returns</p>

    <p>The return on investment in a mutual fund is calculated as the change in the net asset value (NAV) plus any income distributions, such as dividends or capital gains, expressed as a percentage of the NAV at the beginning of the investment period.</p>

\[\text{Rate of Return} = \frac{\text{NAV}_1 - \text{NAV}_0 + \text{Income and capital gain distributions}}{\text{NAV}_0}\]

    <ul>
      <li>Example: if a fund has an initial NAV of $20 and makes an income distribution of $0.15 and a capital gain distribution of $0.05, and ends with an NAV of $20.10, the monthly rate of return would be calculated as:</li>
    </ul>

\[\text{Rate of return} = \frac{20.10 - 20.00 + 0.15 + 0.05}{20.00} = 0.015 \text{ or } 1.5\%\]

    <p>It’s important to note that the rate of return is also impacted by the fund’s expenses and 12b-1 fees, which are periodically deducted from the portfolio. The net return is the gross return on the underlying portfolio minus the total expense ratio.</p>
  </li>
  <li>
    <p>Taxation of Mutual Funds Income</p>

    <p>Mutual funds in the US have “pass-through status” under the tax code. This means that taxes are only paid by the investors in the fund, not the fund itself. The income is treated as passed through to the investors as long as the fund meets certain requirements, such as distributing almost all its income to shareholders. The short-term capital gains, long-term capital gains, and dividends are passed through to investors as though they earned the income directly.</p>

    <p>However, this pass-through status has a disadvantage for individual investors as they have no control over the timing of the sale of securities from the fund’s portfolio, reducing their ability to manage their tax liabilities. A fund with a high portfolio turnover rate can be particularly tax-inefficient as a high turnover rate means that capital gains or losses are constantly being realized, leaving the investor unable to time their realization for tax management.</p>

    <p>Index funds, on the other hand, have low turnover rates, making them tax-efficient and economical in terms of trading costs.</p>
  </li>
  <li>
    <p>Exchange-Traded Funds</p>

    <p>Exchange-Traded Funds (ETFs) are a type of investment product that operates like a mutual fund but can be traded like a stock. They were first introduced in 1993 and the first ETF, “SPDR” (Standard &amp; Poor’s Depository Receipt), tracks the S&amp;P 500 Index.</p>

    <p>Unlike mutual funds, which can only be traded at the end of the day after the net asset value (NAV) is calculated, ETFs can be bought and sold throughout the day, just like a stock. This gives investors greater flexibility and control over their investments.</p>

    <p>ETFs are also available for various indexes such as the Dow Jones Industrial Average (DIA) or the NASDAQ 100 Index (QQQ). There are many different ETFs and sponsors to choose from, and they are listed in the following image for easy reference.</p>

    <p>As of 2012, over 1,100 US ETFs had over $1 trillion invested in them. The majority of these ETFs track broad indexes, but there are also ETFs that focus on specific industries and commodities. The fastest growing sector of ETFs is commodities, with gold and silver ETFs being particularly popular. The growth of ETFs can be seen in the rapid increase of investment in this market, as shown in following figure.</p>

    <p>Barclays Global Investors was a market leader in the Exchange-Traded Fund (ETF) market, offering the popular product named “iShares”. In 2009, Barclays merged with Blackrock and iShares has since operated under the Blackrock name. Blackrock is a major sponsor of equity index funds and industry sector funds, both in the US and globally. To learn more, visit iShares.com.</p>

    <p>Exotic variations of ETFs, such as exchange-traded notes (ETNs) or exchange-traded vehicles (ETVs), are known as synthetic ETFs. These are debt securities that pay off based on the performance of an index, often measuring the performance of an illiquid and thinly traded asset class. Instead of directly investing in these assets, the ETF gains exposure through a “total return swap” with an investment bank. The bank agrees to pay the ETF the return on the index in exchange for a fixed fee. However, this approach becomes controversial during financial stress, as the ETF may be exposed to risk and the bank may be unable to fulfill its obligation, leaving investors without the promised return.</p>

    <p>ETFs have several advantages compared to mutual funds, including:</p>

    <ul>
      <li>Continuous trading: ETFs can be bought and sold continuously, while mutual funds have a single net asset value quoted at the end of each day.</li>
      <li>Trading options: ETFs can be sold short or bought on margin, similar to other stocks, while this is not possible with mutual funds.</li>
      <li>Tax advantages: When many mutual fund investors redeem their shares, the fund may need to sell securities to meet these redemptions, which can result in capital gains taxes passed on to remaining shareholders. On the other hand, if small investors wish to redeem their ETF shares, they can simply sell them to other traders. Large investors can also exchange their ETF shares for shares in the underlying portfolio, avoiding any tax implications.</li>
    </ul>

    <p>ETFs have some disadvantages compared to mutual funds, including:</p>

    <ul>
      <li>Commission fees: Unlike mutual funds, which can be purchased for free from no-load funds, ETFs must be purchased from brokers for a fee.</li>
      <li>Price fluctuations: The prices of ETFs can deviate from their net asset value (NAV) as they are traded as securities. Although this difference is usually small and only happens for a short period, it can become unpredictable during market stress. This can easily offset the cost advantage that ETFs offer.</li>
    </ul>

    <p>In times of market distress, it can be difficult to accurately measure the NAV of ETFs, especially those that track less liquid assets. Additionally, some ETFs may only have a small number of dealers supporting them. If these dealers exit the market, the price of the ETF can fluctuate wildly.</p>
  </li>
</ul>

<figure>
    <picture>
        

        <!-- Fallback to the original file -->
        <img src="/assets/img/bodie/eft-portfolio.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

    </picture><figcaption class="caption">ETF sponsors and products</figcaption>

</figure>

<figure>
    <picture>
        

        <!-- Fallback to the original file -->
        <img src="/assets/img/bodie/eft-growth.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

    </picture><figcaption class="caption">Growth of US ETFs overtime</figcaption>

</figure>

<ul>
  <li>
    <p>Information on Mutual Funds</p>

    <p>There are three main resources for finding information about mutual funds:</p>

    <ul>
      <li>
        <p>The first resource is the mutual fund’s prospectus. The SEC requires mutual funds to have a prospectus that includes a concise “Statement of Investment Objectives” and a detailed discussion of investment policies and risks, information about the investment adviser and portfolio manager, and a fee table that covers the costs associated with purchasing shares, front-end and back-end loads, and annual operating expenses such as management fees and 12b-1 fees.</p>
      </li>
      <li>
        <p>The second resource is the Statement of Additional Information (SAI), also known as Part B of the prospectus. It includes a list of the securities in the portfolio at the end of the fiscal year, audited financial statements, a list of the directors and officers of the fund and their personal investments in the fund, and data on brokerage commissions paid by the fund. Unlike the prospectus, the SAI is not automatically provided to investors and must be requested specifically.</p>
      </li>
      <li>
        <p>The third resource is the fund’s Annual Report, which includes portfolio composition and financial statements and a discussion of factors that influenced the fund’s performance over the last reporting period.</p>
      </li>
    </ul>

    <p>Several publications offer comprehensive information about mutual funds. One such source is Morningstar’s Mutual Fund Sourcebook, which can be found at www.morningstar.com. Another good source is Yahoo’s finance site at finance.yahoo.com/funds. The Investment Company Institute (www.ici.org), the national association of mutual funds, closed-end funds, and unit investment trusts, also publishes an annual Directory of Mutual Funds that includes information on fees and contact information for the funds.</p>
  </li>
  <li>
    <p>Risk, Return, and Historical Record</p>

    <ul>
      <li>
        <p>Level of Interest Rates</p>

        <p>The level of interest rates is a crucial factor in investment decisions and determining the future value of investments. However, forecasting interest rates is a challenging task in macroeconomics.</p>

        <p>There are three main factors that determine the level of interest rates:</p>

        <ul>
          <li>The supply of funds from households as savers</li>
          <li>The demand for funds from businesses for investment in real assets or capital information</li>
          <li>The government’s net demand for funds, which can be affected by the actions of the Federal Reserve Bank.</li>
        </ul>
      </li>
      <li>
        <p>Real and Nominal Interest Rates</p>

        <p>The interest rate is the promised rate of return on an investment expressed in a specific unit of account (such as US dollars, yen, euros, etc.) over a specified time period (such as a month, year, 20 years, etc.).</p>

        <p>It is important to note that an interest rate that is considered risk-free in one unit of account and time period may not be risk-free for another unit or period. For example, an interest rate that is considered safe in US dollars may be risky when evaluated in terms of purchasing power due to inflation uncertainty.</p>

        <p>The real return on an investment depends not only on the promised interest rate but also on the purchasing power of the money received. The Consumer Price Index (CPI) measures the purchasing power of money by averaging the prices of goods and services in the consumption basket of an average urban family of four. If the rate of inflation is 6%, it means that the purchasing power of money is reduced by 6% each year.</p>

        <p>For example, if you invest $1000 with an interest rate of 10% (default-free), at the end of the year you would receive $1100. However, if the rate of inflation is 6%, your real return on the investment would actually be 4%.</p>

        <p><em>Nominal interest rate, \(nr\),</em> is the growth rate of the investment and <em>Real interest rate, \(rr\),</em> is the growth rate of purchasing power. Assume \(i\) denotes the inflation rate, then</p>

\[rr \approx rn -i\]

        <p>In words, the real rate of interest is the nominal rate reduced by the loss of purchasing power. the exact relation is in fact given by</p>

\[1 + rr = \frac{1+rn}{1+i}\]

        <p>This basically says that \((1+rr)(1+i)\) is the real rate with considering the inflation and \(1+rn\) is the money you earn. working out the mass, we obtian</p>

\[rr = \frac{rn-i}{1+i} \approx rn-i -i (rn-i ) + \frac{1}{2}i^2(rn-i)+ ...\]

        <p>where we have expanded the fraction, assuming \(i \ll 1\).</p>
      </li>
    </ul>

    <p>The conventional certificate of deposit provides a guaranteed nominal interest rate. However, to determine the expected real rate of investment, one has to adjust for the expected inflation rate. The inflation rate is published by the Bureau of Labor Statistics (BLS). However, the future real rate is uncertain and one must rely on expectations. This means that the future inflation rate is uncertain and therefore the real rate of return is also uncertain, even if the nominal rate of return is risk-free.</p>
  </li>
  <li>
    <p>The Equilibrium Real Rate of Interest</p>

    <p>The nominal interest rate is determined by four factors: supply, demand, government actions, and expected inflation rate. The real rate of interest, which is the rate that takes into account the purchasing power of money, is determined by the first three factors: supply, demand, and government actions. The real interest rate is the foundation of the nominal interest rate, which is the real rate plus the expected rate of inflation.</p>

    <p>The supply and demand of funds determine the real rate of interest and can be represented by a supply and demand curve. The supply curve shows that as the amount of money invested increases, the interest rate will also increase. The demand curve shows that as the demand for funds from businesses increases, the interest rate will decrease. The intersection of these two curves represents the equilibrium real interest rate.</p>

    <p>Note that the future rate of inflation is unknown and is considered a risky factor, which in turn makes the real rate of return uncertain.</p>

    <p>The real interest rate is determined by the supply of funds from savers, the demand for funds from businesses, and government actions. The government and central bank (Federal Reserve) can influence these factors through fiscal and monetary policies, causing the real interest rate to change. For example, an increase in the government’s budget deficit will shift the demand curve to the right, causing the real interest rate to rise. The Fed can counteract this rise by implementing an expansionary monetary policy, which will shift the supply curve to the right. Therefore, while the real interest rate is primarily determined by the propensity of households to save and the expected profitability of investments in physical capital, it can also be influenced by government fiscal and monetary policies.</p>
  </li>
</ul>

<figure>
    <picture>
        

        <!-- Fallback to the original file -->
        <img src="/assets/img/bodie/fig-5-1-supply-demand.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

    </picture><figcaption class="caption">Determination of the Equilibrium real rate of interest</figcaption>

</figure>

<ul>
  <li>
    <p>The Equilibrium Nominal Rate of Interest</p>

    <p>We know that nominal rate of interest is the real rate of interest plux inflation.</p>

    <p>Irving Fisher (1930) argues that the nominal rate ought to increase one-to-one with the Expected inflation. The fisher equation is as</p>

\[rn = rr + E(i)\]

    <p>meaning that when the real rates are stable, changes in the nominal rates ought to predict the changes in the inflation rates. This claim has got mixed results empirically and is under the debate. Nominal rates can be viewed as the sum of the required real rate on nominally risk-free assets plus a noisy forecast of inflation.</p>
  </li>
  <li>
    <p>Tax and the Real Rate of Interest</p>

    <p>Tax liabilities are calculated based on nominal income and the tax rate is determined by the investor’s tax bracket. In 1986, the Tax Reform Act addressed the issue of “bracket creep,” where taxpayers move into higher tax brackets due to the growth of nominal income due to inflation.</p>

    <p>However, index-linked tax brackets do not address the effect of inflation on the taxation of savings. With a tax rate of \(t\) and a nominal interest rate of \(rn\), the after-tax interest is \(rn (1-t)\). The real after-tax rate is approximately the after-tax nominal rate minus the inflation rate, calculated as \((rr + i)(1-t) - i = rr(1-t) -it\). This means that as inflation increases, the after-tax real rate decreases.</p>

    <p>For example, suppose you have an investment with yield of \(12\%\), with inflation of \(8\%\). So you real rate is approximately \(4\%\). In an inflation-protected tax system, after taxes a real return of \(4\% (1-0.3) = 2.8\%\). But tax code does not recognizes the first 8\% of your return is just compensation for inflation–not real income–and hence your after tax return is reduced by \(8\% \times 0.3 = 2.4\%\), so that your after-tax real interest rate, at \(4 \%\) is almost wiped out.</p>
  </li>
  <li>
    <p>Rates of Return for Different Holding Periods</p>

    <p>Consider a safe investment in US Treasury securities with zero-coupon and several different maturities. T-bills are sold at a discount from par value and provide their entire return from the difference between the purchase price and the ultimate return payment. Give the price \(p(T)\), for a Treasury bond of \(100\$\) par value and maturity of \(T\) years, the risk free return available for a horizon of \(T\) years is as</p>

\[r_f (T) = \frac{100}{p(T)} -1\]

    <p>For \(T=1\), this equation provides the risk free for an investment with a horizon of 1 year.</p>

    <p>Obviously, longer horizons, provide greater total returns. The question then arises that how should we compare investment returns with different maturities? We typically express all investment returns as an <em>effective annual rate (EAR)</em>, defined as the percentage increase in funds invested over a 1-year horizon.</p>

    <p>For a 1-year investment, the EAR equals the total return \(r_f(1)\), and the gross return \((1 + \text{EAR} )\) s the terminal value of \(1\$\) investment. Now suppose for a 6-month bill, with \(2.71\%\) return, over two semi-annual periods, we obtain \(1 +\text{EAR} = (1.0271)^2 = 1.0549\) implying that \(\text{EAR} = 5.49\%\). Now, suppose for a 25-year bind, the return is \(329.18\%\). The \(\text{EAR}\), is then obtained as</p>

\[( 1 + \text{EAR})^{25} = 1 +3.2918\]

\[1 + \text{EAR} = 4.2918^{1/25} = 1.0600\]

    <p>meaning that the value of return over a year is \(\text{EAR} = 6\%\). Generally when the total return is \(r_f(T)\), over a holding with period length of \(T\), we obtain \(\text{EAR}\), as</p>

\[1+ \text{EAR} = [1+r_f(T)]^{1/T}\]
  </li>
  <li>
    <p>Annual Percentage Rates</p>

    <p>For shor-term investments \(T&lt;1\), annulaized return rates oftern are reported using a simple, rather than compound interes, called <em>Annual Percentage Rates</em> or <em>APR</em>. For example, the APR corresponding to a monthly rate such as that charged on a credit card is reported as \(12\) times the monthly rate. This means that, if there are \(n\) compounding periods in a year, and the per-period rate is \(r_f(T)\), then \(\text{APR} = n \times r_f(T)\). Conversely, you can find the per-period rate from the \(\text{APR}\) as \(r_f(T) = T \times \text{APR}\).</p>

    <ul>
      <li>Example: For a 6-month rate of \(2.71 \%\), discussed above, the \(\text{APR}\), is \(2\times 2.71 = 5.42 \%\). Compare this with the compound rate of \(5.49 \%\).</li>
    </ul>

    <p>Note that for a short-term investment of length \(T\), we have \(n= 1/T\) compounding periods. To generalize the relation between \(\text{APR}\) and \(\text{EAR}\) for a short-term investment of length \(T\) we have</p>

\[1 + \text{EAR} = [ 1+ r_f(T)]^n = [ 1+ r_f(T)]^{1/T} = [ 1+ T\times \text{APR}]^{1/T}\]

    <p>or equivalently,</p>

\[\text{APR} = \frac{(1+\text{EAR})^T-1}{T}\]
  </li>
  <li>
    <p>Continuous Compounding</p>

    <p>It is evident that the difference between \(\text{APR}\) and \(\text{EAR}\), grows with frequncy of compounding. This raises the question, how far will the two rates diverge as the compounding frequency continuous to grow.</p>

    <p>First lets write a python code, that compares these two values. We basically, fix the \(\text{EAR} = 5\%\), and then find the \(\text{APR}\) that we get for different investment period. We change the investment period from 1-day to 1-year. For the second plot, we fix the value of \(\text{EAR}\) at \(5\%\) and then see what values we get for the \(\text{APR}\). Note that, as is shown in [[fig-6-0][this figure]], the lne for \(\text{APR}\) always is lower than \(\text{EAR}\).</p>

    <p>Let’s see if we can find a mathematical formulae for that. As \(T\) approaches zero, we effectively are reaching the <em>continuous compounding (CC)</em>, and the relation between \(\text{EAR}\) to an annual percentage rate \(\text{APR} = r_{cc}\) (since it is a continuous compound), is given aby an exponential as</p>

\[1 + \text{EAR} = \lim_{T\rightarrow 0} (1 + T\times r_{cc})^{1/T} = \exp (r_{cc})\]

    <p>This means that the continuous annual percentage rate \(r_{cc}\) is as</p>

\[r_{cc} = \log ( 1+ \text{EAR})\]

    <p>where \(\log()\) is the natural logarithmic. So the maximum difference would be what we just calculated. For example, if the \(\text{EAR} = 5\%\), then \(r_{cc} = 4.88\%\) for the continuous limit, which can be seen in the left of next figure.</p>

    <p>One good application of \(r_{cc}\), is in calculating the total return for any period \(T\), this is simply \(\exp (T\times r_{cc} )\), since</p>

\[1 + \text{EAR}= \exp(r_{cc})\]

\[(1+\text{EAR})^T = \exp(T\times r_{cc})\]
  </li>
</ul>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
</pre></td><td class="code"><pre><span class="kn">import</span> <span class="n">matplotlib</span>
<span class="n">matplotlib</span><span class="p">.</span><span class="nf">use</span><span class="p">(</span><span class="sh">'</span><span class="s">Agg</span><span class="sh">'</span><span class="p">)</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="n">fig</span><span class="o">=</span><span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">4</span><span class="p">));</span>
<span class="c1"># T varies between a day (T = 1/365) up to a year (T=1).
</span><span class="n">T</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="mf">0.0027</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">);</span>
<span class="n">TT</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.0027</span><span class="p">,</span> <span class="mf">0.0833</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.50</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">];</span>
<span class="n">Tlabel</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">1 day</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">1 mon</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">1 quar</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">6 mon</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">1 yr </span><span class="sh">'</span> <span class="p">];</span>
<span class="c1"># Calculating APR for a fixed EAR = 5%
</span><span class="n">ear</span> <span class="o">=</span> <span class="mf">0.05</span><span class="p">;</span>
<span class="n">apr</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">power</span><span class="p">((</span><span class="mi">1</span><span class="o">+</span><span class="n">ear</span><span class="p">),</span><span class="n">T</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="n">T</span><span class="p">;</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">T</span><span class="p">,</span><span class="n">apr</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="sh">'</span><span class="s">r--</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">size</span><span class="p">(</span><span class="n">T</span><span class="p">))</span><span class="o">*</span><span class="n">ear</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="sh">'</span><span class="s">b--</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">APR and EAR (%)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">EAR is fixed at %s</span><span class="sh">'</span> <span class="o">%</span><span class="n">ear</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">T varies between a day to a year</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xticks</span><span class="p">(</span><span class="n">TT</span><span class="p">,</span> <span class="n">Tlabel</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="sh">'</span><span class="s">vertical</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">subplots_adjust</span><span class="p">(</span><span class="n">bottom</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">()</span>
<span class="c1"># Calculating EAR based on a fix APR = 5%
</span><span class="n">apr</span> <span class="o">=</span> <span class="mf">0.05</span><span class="p">;</span>
<span class="n">ear</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">power</span><span class="p">((</span><span class="mi">1</span><span class="o">+</span><span class="n">apr</span><span class="o">*</span><span class="n">T</span><span class="p">),</span><span class="mi">1</span><span class="o">/</span><span class="n">T</span><span class="p">)</span> <span class="o">-</span><span class="mi">1</span> <span class="p">;</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="n">EAR</span><span class="p">,</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">T</span><span class="p">,</span><span class="n">ear</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="sh">'</span><span class="s">b--</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">EAR</span><span class="sh">'</span><span class="p">)</span>
<span class="n">APR</span><span class="p">,</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">size</span><span class="p">(</span><span class="n">T</span><span class="p">))</span><span class="o">*</span><span class="n">apr</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="sh">'</span><span class="s">r--</span><span class="sh">'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">APR</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">APR is fixed at %s</span><span class="sh">'</span> <span class="o">%</span><span class="n">apr</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">T varies between a day to a year</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xticks</span><span class="p">(</span><span class="n">TT</span><span class="p">,</span> <span class="n">Tlabel</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="sh">'</span><span class="s">vertical</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">subplots_adjust</span><span class="p">(</span><span class="n">bottom</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">(</span><span class="n">handles</span><span class="o">=</span><span class="p">[</span><span class="n">APR</span><span class="p">,</span> <span class="n">EAR</span><span class="p">]);</span>
<span class="c1"># Saving and showing the result
</span><span class="n">plt</span><span class="p">.</span><span class="nf">savefig</span><span class="p">(</span><span class="sh">'</span><span class="s">img/apr-for-fixed-ear.png</span><span class="sh">'</span><span class="p">,</span><span class="n">bbox_inches</span><span class="o">=</span><span class="sh">'</span><span class="s">tight</span><span class="sh">'</span><span class="p">)</span>
<span class="c1">#'img/apr-for-fixed-ear.png' # return this to org-mode</span>
</pre></td></tr></tbody></table></code></pre></figure>

<figure>
    <picture>
        

        <!-- Fallback to the original file -->
        <img src="/assets/img/bodie/apr-for-fixed-ear.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

    </picture><figcaption class="caption">The figure displays the difference between the Annual Percentage Rate (APR) and the Effective Annual Rate (EAR) for T, for investment periods ranging from 1 day to 1 year. The APR is represented in red and the EAR is represented in blue.</figcaption>

</figure>

<ul>
  <li>
    <p>Bills and Inflation 1926-2012</p>

    <p>Financial time series often begin in July 1926 when Center for Research in Security Prices at University of Chicago started a widely used accurate return database.</p>

    <p>Looking at the next figure, we see the average annual rates for the various series. The average interest rate over the most recent half (i.e. 1969-2012), is \(5.25\%\), which is much higher than in the earlier half \(1.79\%\). The reason is inflation, which is the main driver of T-bill rates. Inflation, over the recent half has been \(4.26 \%\), compared to the first half of \(1.74 \%\). The average real rate, taking out the inflation from the nominal rate, for the recent half is still higher than the first half. Compare \(0.10\%\) with \(0.95\%\) for the recent half. Note that the real and nominal half are related as</p>

\[1 + r(\text{real}) = \frac{1 + r(\text{nominal})}{1 + i(\text{inflation})}\]
  </li>
</ul>

<figure>
    <picture>
        

        <!-- Fallback to the original file -->
        <img src="/assets/img/bodie/t-bill-rate.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

    </picture><figcaption class="caption">Statistics for T-bill rates, inflation rates, and real rates, First half is 1926-1965 and recent half is 1969-2012.</figcaption>

</figure>

<ul>
  <li>
    <p>History lesson:</p>

    <p>A moderate rate of inflation can reduce the nominal gains from low-risk investments, such as T-bills, to a significant extent. In both halves of the sample, the real return was less than one-fifth of the nominal return.</p>

    <p>The Wealth Index measures the cumulative gain from an investment over a certain period. It assumes a starting investment of $1 and compounds the investment value each year by adding the gross annual rate of return to 1. The Wealth Index at the end of the investment period shows the total increase in wealth per dollar invested.</p>

    <p>The previous figure illustrates the wealth index of a $1 investment in T-bills at the start of 1970. The nominal wealth index shows an impressive growth of $9.20 by 2012, but the inflation-adjusted real wealth index is only $1.20. Similarly, a $1 investment in T-bills from 1926 to 2012 would have reached $20.25 (as shown in the inset), but the inflation-adjusted real value would only be $1.55.</p>

    <p>Next figure shows that the standard deviation (SD) shows a lower SD of inflation in recent half \(2.82\%\), than in the earlier period \(4.66\%\). This is contributed to a lower standard deviation of the real rate in the recent half of teh sample, \(2.44 \%\), compared with the earlier half \(4.98 \%\). Notice that the SD of the nominal rate actually was higher in the recent period \(3.02\%\) than the earlier period \(1.56\%\), indicating that the lower variation in realized real returns must be attributed to T-bill rates more closely tracking inflation in that period.</p>

    <p>Investors presumably focus on the real returns they can earn on their investments. For them to realize acceptable real rate, they must earn a higher nominal rate when the inflation is excpected to be higher. Therefore, the nominal T-bill rate at the begining of a period should reflect anticipation of the inflation over that period. When the real rate is stable and realized inflation matches initial expections, <em>the correclation between inflation and nominal T-bill rates will be close to perfect 1.0</em>, while <em>the correlation between inflation and the realized real rate will be close to zero</em>.</p>

    <p>At the other extreme, if investors are ignoring or could not project the inflation at all, the correlation between inflation and nominal T-bill rates would be zero, and the correlation between inflation and real rates would be -1.0, since the real rate would then fall one-for-one with any increase in inflation.</p>

    <p>Looking the figure after, we see that the accuracy of investors predicting the inflation has increased. The correlation between inflation and nominal T-bill rate has increased from \(-0.03\) to \(0.48\) (perfectly it would be \(1.0\) ), and the correlation between inflation and real T-bill rate has approached the perfect value of \(0.0\) (it has changed from \(-0.98\) to \(-0.67\)).</p>
  </li>
</ul>

<figure>
    <picture>
        

        <!-- Fallback to the original file -->
        <img src="/assets/img/bodie/wealth-index.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

    </picture><figcaption class="caption">Nominal and real wealth indexes for investment in T-bil 1970-2012 (inset figure is for 1926-2012)</figcaption>

</figure>

<figure>
    <picture>
        

        <!-- Fallback to the original file -->
        <img src="/assets/img/bodie/correlation.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

    </picture><figcaption class="caption">Correlations between inflation &amp; real T-bill rate and nominal T-bill rates in two period</figcaption>

</figure>

<ul>
  <li>
    <p>Risk and Risk Premiums</p>

    <ul>
      <li>
        <p>Holding Period Returns</p>

        <p>Assume you invest in a stock-index fund, where shares currently sells for \(100\\)$ per share. With an investment horizon of 1-year, the realized rate of return depends on (i) the price per share at year’s end and (ii) the cash dividendsyou will collect over the year.</p>

        <p>In this example, if the price of the share at year’s end is \(110\\)$ and cash dividends over the year amount to \(4\\)$, the <em>realized return</em> or <em>holding period return (HPR)</em>, is defined as</p>

\[\text{HPR} = \frac{\text{Ending price of a share} - \text{Beginning price of a share} + \text{Cash dividends}}{\text{Beginning price of a share}}\]

        <p>Here we have</p>

\[\text{HPR} = \frac{110 -100  + 4 }{100 } = 0.14 \text{ or } 14\%\]

        <p><em>HPR treats the dividend as paid at the end of the holdin period</em>. When dividends are received earlier, the HPR inores investment income between the receipt of the payment and the end of the holding period. The percent return from dividends is called the <em>dividend yield</em>, and so dividend yield plus the rate of capital gains equals HPR.</p>
      </li>
      <li>
        <p>Expected Return and Standard Deviation</p>

        <p>There is uncertainty in the share’s price plus its devidend after 1-year. We can quantify the belief about the state of the market and the stock-index funds in terms of probabilities. Suppose, each state has a HPR of \(r_i\) with probability of \(p_i\). The expected return is as</p>

\[E(r) = \sum_i p_i r_i\]

        <p>The standard deviation of the rate of return \(\sigma\) is a measure of risk. It is defined as the square root of the variance, which in turn is the expected value of the squared deviations from the expected return. The higher volatility in outcomes, the higher will be the average value of these squared deviations. Therefore the variance and standard deviation, provide a measure of the uncertainty of outcomes. The variance is defined as</p>

\[\sigma^2 = \sum_i p_i (r_i - E(r))^2\]

        <p>What troubles the potential investors in the index fund is the downside risk of a crash or poor market, not the upside potential of a good or excellent market. As long as the probability distribution is more or less symmetric about the mean, \(\sigma\) is a reasonable measure of risk.</p>
      </li>
      <li>
        <p>Excess Returns and Risk Premiums</p>

        <p>The main question for investors, is that: how much, if anything, should i invest in an index fund? We should look at the amount of expected reward offered for the risk involved in investing money in stocks!</p>

        <p>The reward is measured as the difference between the <em>expected HPR</em> on the index stock and the <em>risk free rate</em>, that is the rate you can earn by leaving money in risk-free assets such as T-bills, money market funds, or the bank. This difference is called <em>risk premium</em> on common stocks.</p>

        <p>For example if the risk-free rate is \(4\%\) and the expected index fund return is \(10\%\), then the risk premium on stocks is \(6\%\).</p>

        <p>The difference in any particular period between the <em>actual</em> rate of return on a risky asset and the actual risk-free rate is called <em>excess return</em>. Therefore the risk premium is the <em>expected value of the excess return</em>.</p>

        <p>The degree to which investors are willing to commit funds to stocks depends on <em>risk aversion</em>. Investors are risk averse in the sense that, if the risk premium were zero, they would not invest any money in stocks. In theory, there must always be a positive risk premium on stocks in order to induce risk-averse investors to hold the existin supply of stocks instead of placin all their money in risk-free assets.</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Time Series Analysis of Past Rates of Return</p>

    <p>In forward looking scenario analysis, we determine a set of scenarios and associated investment rates of return, assign probabilities to each, and conclude by computing the risk premium (reward) and standard deviation (risk).</p>

    <p>In historical looking, we have only dates and associated HPRs. We must infer from this limited data the probability distribution from which these returns might have been drawn or, at least, expected return and standard deviation.</p>
  </li>
  <li>
    <p>Expected Returns and the Arithmetic Average</p>

    <p>When we use historical data, we treat each observation as an equally likely “scenario”. This would result in arithmitic average of rates of return as</p>

\[E(r) = \sum_{i=1}^n p_i r_i = \frac{1}{n}\sum_{i=1}^n r_i\]

    <p>If the time series of historical returns fairly represents the true underlying probability distribution, then the arithmetic average return from a historical period provides a forecast of the investmen’t expected future of HPR.</p>
  </li>
  <li>
    <p>The Geometric (Time-Weighted) Average Return</p>

    <p>An intuitive measure of performance over the sample period is the (fixed) annual HPR that would compound over the period to the same terminal value as obtained from the sequence of actual returns in the time series.</p>

\[\text{Terminal Value} = (1 + r_1) \times (1+r_2) \times \ldots \times (1+r_5) = (1+g)^n\]

\[g = \text{Terminal Value}^{1/n}\]

    <p>where \(1+ g\) is the geometric average of the gross returns \(1+r\) from the time series and \(g\) is the annual HPR that would replicate the final value of our investment.</p>

    <p>\(g\) is known as the <em>time-weighted average return</em> to emphasize that each past return receives an equal weight in the process of averaging.</p>

    <p><em>The larger the swings in rates of return</em>, <em>the larger the discrepency between *the arithmetic averages and the geometric averages</em>, that is, between the compound rate earned over the sample period and the average of the annual returns.</p>

    <p>If returns come from a normal distribution, the expected difference is exactly half the variance of the distribution, that is</p>

\[E[\text{Geometric average}] = E[\text{Arithmetic average}] - \frac{1}{2} \sigma^2\]
  </li>
  <li>
    <p>Variance and Standard Deviation</p>

    <p>In risk, we are interested in the likelihood of deviations from the <em>expected</em> return. Since, in practice we cannot directly observe expectations, so we estimate the variance by averaging the squared deviations from our <em>estimate</em> of the expected return, therefore:</p>

\[\text{Variance} = \sigma^2 = \sum p_i ( r_i - E(r))^2\]

    <p>Using the historical data with \(n\) observation, we could estimate the variance as</p>

\[\hat{\sigma}^2 = \frac{1}{n} \sum_i (r_i - \bar{r})^2\]

    <p>where $\hat{\sigma}$ replaces $\sigma$ to denote that it is an estimate. The variance estimate here, is <em>biased downward</em>. The reason is that we have taken deviations from the sample arithmetic average, \(\bar{r}\), instead of the unknown, true expected value \(E(r)\), and so have introduced an estimation error. Its effect on the estimated variance is sometimes called a <em>degrees of freedom bias</em>. We can eliminate the bias by multiplying the arithmetic average of squared deviations by the factor of \(n/(n-1)\). The variance and standard deviation then becomes</p>

\[\hat{\sigma}^2 = \frac{1}{n-1} \sum_i (r_i -\bar{r})^2\]

    <p>For a large sample, \(n\) becomes large and, \(n/(n-1)\) approaches \(1\), and the adjustment for degrees of freedom becomes trivially small.</p>
  </li>
  <li>
    <p>Mean and Standard Deviation Estimates from Higher Frequency Observations</p>

    <p>Does increasing the number of observations lead to more accurate estimates? The answer may surprise you: the frequency of observations has no impact on the accuracy of mean estimates. Instead, it is the duration of the sample time series (not the number of observations) that improves accuracy.</p>

    <p>For example, the average annual return estimated by dividing the total 10-year return by 10 is as accurate as the average of 120 monthly returns multiplied by 12. The average monthly return should align with the average of the 10-year return. If the probability distribution of returns remains unchanged, a longer sample, such as 100 years, provides a more accurate estimate of the mean return than a 10-year sample.</p>

    <p>Therefore, the rule of thumb is to use the longest sample that still comes from the same return distribution. However, in practice, old data may not be as informative and could limit the accuracy of mean return estimates.</p>

    <p>In contrast to the mean, the accuracy of estimates of the standard deviation and higher moments (computed using deviations from the average) can be improved by increasing the number of observations. Therefore, the accuracy of estimates of the SD and higher moments of the distribution can be improved by using more frequent observations.</p>

    <p>When monthly returns are uncorrelated from one month to another month, monthly variances simply add up. Thus, if the variance is the same every month, we annualize by \(\sigma_A^2 = 12 \sigma_M^2\). In general, the \(T\)-month variance is \(T\) times the \(1\)-month variance. Consequently the standard deviation grows at the rate of \(\sqrt{T}\), i.e. \(\sigma_A = \sqrt{12} \sigma_M\). *The mean and variance grow in direct proportion to time, SD grows at the rate of square root of time.</p>
  </li>
  <li>
    <p>The Reward-to-Volatility (Sharpe) Ratio</p>

    <p>Finally, it is worth noting that investors presumably are interested in <em>the expected excess return</em> they can earn by <em>replacing T-bills with a risky portfolio</em>, as well as <em>the risk</em> they would thereby incur. While the T-bill rate is not constant over the entire period, we still know with certainty what nominal rate we will earn if we purchase a bill and hold it to maturity. <em>Other investments typically entail accepting some risk in return for the prospect of earning more than the safe T-bill rate.</em> Investors price risky assets so that the risk premium will be commensurate with the risk of that expected excess return, and hence it’s best to measure risk by the standard deviation of excess, not total, returns.</p>

    <p>The importance of the trade-off between <em>reward (the risk premium)</em> and <em>risk ( measured by standard deviation or SD)</em>, suggests that we measure the attraction of a portfolio by the ratio of risk premium to SD of excess returns.</p>

\[\text{Sharpe Ratio} = \frac{\text{Risk Premium}}{\text{SD of Excess Return}}\]

    <p>The <em>reward-to-volatility</em> measure (proposed by William Sharpe and hence called <em>Sharpe Ratio</em> or <em>SR</em>) is widely used to evaluate the performance of investment managers.</p>

    <p>Notice that the Sharpe Ratio, devides the risk premium (grows directly with time) by the standard deviation (grows proportional to square root of time). Therefore <em>Sharpe Ratio (SR)</em> <em>grows proportional to square root of time</em>, meaning that if we want to annualize SR from monthly value, we multiply that by \(\sqrt{12}\) or \(SR_A = SR_M \sqrt{12}\).</p>
  </li>
  <li>
    <p>The Normal Distribution</p>

    <p>The bell-shaped <em>normal distribution</em> appears naturally in many applications. In fact, many variables that are the end result of multiple random influences will exhibit a normal distribution.</p>

    <p><em>If return expectations implicit in asset prices are rational, actual rates of return should be normally distributed around these expectations.</em></p>

    <p>Next figure shows a normal distribution profile. Decreasing \(\sigma\) results in tight figure around the average. The two parameters controlling this distributin are the average and the standard deviation.</p>
  </li>
</ul>

<figure>
    <picture>
        

        <!-- Fallback to the original file -->
        <img src="/assets/img/bodie/normal-distribution.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

    </picture><figcaption class="caption">The normal distribution</figcaption>

</figure>

<ul>
  <li>
    <p>Deviations from Normality and Risk Measures</p>

    <p>to be cont’d</p>
  </li>
</ul>]]></content><author><name></name></author><summary type="html"><![CDATA[investment]]></summary></entry><entry><title type="html">Bayesian Machine Learning</title><link href="https://azareei.github.io/blog/2022/Baysian-ml/" rel="alternate" type="text/html" title="Bayesian Machine Learning" /><published>2022-01-26T02:30:00+00:00</published><updated>2022-01-26T02:30:00+00:00</updated><id>https://azareei.github.io/blog/2022/Baysian-ml</id><content type="html" xml:base="https://azareei.github.io/blog/2022/Baysian-ml/"><![CDATA[<p>These is a review of Bayesian Machine Learning. It’s based on HSE’s course on this topic.</p>

<h3 id="maximum-likelihood-estimation-mle">Maximum Likelihood Estimation (MLE)</h3>

<p>The ML estimate for \(\theta\) is the value under which the data are most likely, i.e.</p>

\[\boxed{\hat{\theta}_{ML} \in \text{argmax}_\theta p(y|\theta)}\]

<p>Example: We know that a fair coin has \(p(\text{head}) = p(\text{tail}) = 1/2\). Now imagine you have a coin and you don’t know if it is fair or not. You decide to throw the coin \(m\) times, where you observe \(m_H\) times head, and \(m_T\) times tail, where \(m_H + m_T = m\). Now you ask given this observation, what is the probability of \(p(\text{head}), p(\text{tail})\) for this coin? We know that if \(p(\text{head}) =\theta\), then the likelihood of such observation is</p>

\[p(y|\theta) = \theta^{m_H} (1-\theta)^{m-m_H}\]

<p>Now, we are interested to find a \(\hat \theta_{ML}\) such that the above probability is maximized. Instead of the probability, we maximize its logarithm which will be easier. We have</p>

\[l(\theta) = m_H \log(\theta) + (m-m_H) \log(1-\theta)\]

<p>finding the \(\text{argmax}_\theta\) for the above equation we have</p>

\[\frac{d}{d\theta}d(\theta)|_{\hat\theta} = 0 = \frac{m_H}{\theta}|_{\hat\theta} - \frac{m-m_H}{1-\theta}|_{\hat\theta}\]

\[\longrightarrow \hat{\theta} = \frac{m_H}{m}\]

<h3 id="maximum-a-posteriori-map-estimation">Maximum a posteriori (MAP) estimation</h3>

<p>We learned that in MLE estimation we find \(\theta\) to maximize the likelihood function \(p(y\mid \theta)\). Now, in MAP, we find \(\theta\) such that the posterior \(p(\theta\mid y)\) is maximized, i.e.,</p>

\[\boxed{\hat{\theta}_{MAP} \in \text{argmax}_\theta p(\theta\mid y) = \text{argmax}_\theta  \frac{p(y\mid \theta) p(\theta)}{p(y)}}\]

<p>Since the denominator does not depend on \(\theta\), we have</p>

\[\hat{\theta}_{MAP} = \text{argmax}_\theta p(y\mid \theta)p(\theta) = \text{argmax}_\theta \log p(y\mid \theta) + \log p(\theta)\]

<p>The last term, \(\log p(\theta)\) is known as our prior belief.</p>

<p>Example: Again, imagine the same coin flip problem. Imagine we take the prior to be a beta distribution as</p>

\[p(\theta) = \beta(\theta;\alpha,\beta) = A~ \theta^\alpha (1-\theta)^{\beta}\]

<p>where \(A\) is a constant to make \(\int p(\theta)\text{d}\theta=1\). Now finding the solution to the MAP estimator, we find that</p>

\[\hat{\theta}_{MAP} = \text{argmax}_\theta \log p(y\mid \theta) + \log p(\theta)\]

\[\frac{m_H}{\theta}\mid _{\hat\theta} - \frac{m-m_H}{1-\theta}\mid _{\hat\theta}  + \frac{\alpha}{\theta}\mid _{\hat\theta} - \frac{\beta}{1-\theta}\mid _{\hat\theta} = 0\]

\[\hat{\theta}_{MAP} = \frac{m_H + \alpha}{m+\alpha+\beta }\]

<p>The point of \(\alpha, \beta\) coming from the prior in the above equation will be a regularizer. Imagine, we only throw the coin only once, then the ML gives \(\hat{\theta}_{ML}=1\), however, \(\hat{\theta}_{MAP} = \alpha/(\alpha+\beta)\).</p>

<h3 id="point-estimation-and-probabilistic-linear-regression">Point estimation and probabilistic linear regression</h3>

<p>Imagine we are given \(m\) datapoints, \((x_1,y_1), \cdots, (x_m,y_m)\), where \(x_i\)’s are independent variables and \(y_i\)’s are dependent. Assuming a linear relationship as</p>

\[y_i \sim \theta^\top x_i + \epsilon\]

<p>where \(\epsilon \sim \mathcal{N}(0,\sigma^2)\). Assuming the independence between the \(y_i\)’s, we can write</p>

\[p(y\mid x,\theta)= \Pi_{i=1}^m p(y_i\mid x_i,\theta) = \Pi_{i=1}^m \mathcal{N}(y_i;\theta^\top x_i,\sigma^2)\]

<p>Finding the maximum of log-likelihood, we obtain</p>

\[\hat{\theta}_{ML} = \text{argmax}_\theta p(y\mid x,\theta) = \text{argmin}_\theta \sum_{i=1}^m (y_i - \theta^\top x_i)^2\]

<p>which is the equivalent to ordinary least squares.</p>

<p>Now, trying the MAP estimate, we first need to assume a prior for the \(\theta\) variables. As an initial estimate we assume \(\theta \sim \mathcal{N}(0, \nu^2\mathbf{I})\). Finding the MAP solution we find that</p>

\[\hat{\theta}_{MAP} = \text{argmax}_\theta \log p(y\mid \theta) + \log p(\theta)\]

\[\hat{\theta}_{MAP} = \text{argmin}_\theta \sum_{i=1}^m (y_i-\theta^\top x_i)^2 + \frac{\sigma^2}{\nu^2} \mid \mid \theta\mid \mid ^2\]

<p>which is the same as ML solution with a regularization term.</p>

<h3 id="conjugate-priors">Conjugate priors</h3>

<p>We often would like to find the full posterior, \(p(\theta\mid y)\). If we know the full posterior distribution, then we can do posterior predictive distribution as</p>

\[p(y_{m+1}\mid y) = \int p(y_{m+1}\mid y,\theta)~p(\theta\mid y) d\theta = \int p(y_{m+1}\mid \theta)~p(\theta\mid y) d\theta\]

<p>The second part is because \(y_{m+1}\) and \(y\) are conditionally independent. If we would like to find the full posterior, then</p>

\[p(\theta\mid y) = \frac{p(y\mid \theta)p(\theta)}{p(y)}\]

<p>The bottom part is just a normalizer. So we need to choose the prior, \(p(\theta)\), such that with the likelihood distribution, \(p(y\mid \theta)\), we are able to track the distribution. Selecting prior in such a way that the \(p(y\mid \theta)p(\theta)\) becomes tractable is known as a selection of conjugate priors for \(p(y\mid \theta)\).</p>

<h3 id="exponential-families-and-conjugate-priors">Exponential families and conjugate priors</h3>

<p>The family of distribution \(\mathcal{F}\) is called exponential family if every member of \(\mathcal{F}\) has the form</p>

\[\boxed{p(y_i\mid \theta) = f(y) g(\theta)\exp(\phi(\theta)^\top u(y_i))}\]

<p>where \(f(\cdot), g(\cdot), \phi(\cdot),u(\cdot)\) are some functions. For example, an exponential distribution is an exponential family distribution:</p>

\[p(y\mid \theta) = \theta e^{-\theta y}\]

<p>or a beta distribution:</p>

\[p(y\mid \theta) = \theta^{y} (1-\theta)^{1-y} = \exp(y\log\theta + (1-y)\log(1-\theta)) = (1-\theta)\exp(y \log\frac{\theta}{1-\theta})\]

<p>Normal distribution is also an exponential family.</p>

<p>If the \(p(y_i\mid \theta)\) is coming from an exponential family distribution, then if \(y_i\)’s are independent, the likelihood becomes</p>

\[p(y\mid \theta) = \Pi_{i=1}^m p(y_i\mid \theta) = \left[\Pi_{i=1}^m f(y_i)\right] g(\theta)^m \exp\left( \phi(\theta)^\top \sum_{i=1}^m u(y_i)\right)\]

<p>Now, we can select the prior as</p>

\[p(\theta) \sim g(\theta)^\eta \exp(\phi(\theta)^\top \nu)\]

<p>where \(\eta,\nu\) are hyper-parameters.</p>

<p>Now you might ask, shouldn’t the choice of prior matter here? Can we really pick the prior distribution only based on making the problem tracktable? In the next part, we show that as long as you pick a prior that assigns non-zero probabilities to every possible value of \(\theta\), the solution of MAP converges to the true solution \(\theta^*\), or more precisely, \(theta^*\) corresponds to the likelihood model which is closest to the true generating distribution. The closeness of the distributions is defined using KL divergence.</p>

<h3 id="kl-divergence">KL divergence</h3>

<p>The KL divergence between two distributions \(p\) and \(q\) is defined as</p>

\[\boxed{D_{KL}(p\mid \mid q) := \int_x p(x) \log \frac{p(x)}{q(x)}dx}\\ \to D_{KL}(p\mid \mid q)= \mathbf{E}_p[\log p(x) - \log q(x)]\]

<p>Note that \(D_{KL}(p\mid \mid q)\) is always positive since</p>

\[-D_{KL}(p\mid \mid q) = \int p(x)\left(-\log \frac{p(x)}{q(x)}\right) dx \leq  -\log \int p(x) \frac{q(x)}{p(x)} dx =0\]

\[\rightarrow D_{KL}(p\mid \mid q)\geq 0\]

<p>and the equality with zero only happens when \(p=q\). Now, we want to use the KL divergence to find the distribution from the likelihood family that is closest to the true generating function</p>

\[\theta^* = \text{argmin}_\theta D(q(\cdot) \mid \mid p(\cdot\mid \theta))\]

<p>Imagine we have \(y=(y_1,\cdots, y_m)\) as a set of independent samples from an arbitrary distribution \(q(y)\). We assume a family \(\mathcal{F}\) of likelihood distributions with \(\Theta = \{ \theta: p(\cdot \mid  \theta) \in \mathcal{F}\}\) the finite parameter space. Our goal is to show that if \(p(\theta=\theta^*)&gt;0\), then \(p(\theta=\theta^*\mid y)\to1\) as the number of observation increases or \(m\to\infty\). Consider \(\theta\neq \theta^*\), then</p>

\[\log \frac{p(\theta\mid y)}{p(\theta^*\mid y)} = \log \frac{p(y\mid \theta) p (\theta)}{p(y\mid \theta^*) p (\theta^*)} = \log \frac{p (\theta)}{p (\theta^*)} + \sum_{i=1}^m \log \frac{p(y_i\mid \theta) }{p(y_i\mid \theta^*)}\]

<p>where we used the fact that \(p(\theta^*) \neq 0\). We have</p>

\[\frac{1}{m} \sum_{i=1}^m \log \frac{p(y_i\mid \theta) }{p(y_i\mid \theta^*)} \to \mathbf{E}_q\left[ \log \frac{p(y_i\mid \theta) }{p(y_i\mid \theta^*)}\right]\]

<p>Expanding the Expected value we have</p>

\[\mathbf{E}_q\left[ \log \frac{p(y_i\mid \theta) }{p(y_i\mid \theta^*)}\right] = \mathbf{E}_q\left[ \log \frac{p(y_i\mid \theta) }{p(y_i\mid \theta^*)}\frac{q(y)}{q(y)}\right] = \mathbf{E}_q\left[ \log \frac{q(y) }{p(y_i\mid \theta^*)}- \log \frac{q(y)}{p(y_i\mid \theta)} \right]\]

\[\mathbf{E}_q\left[ \log \frac{p(y_i\mid \theta) }{p(y_i\mid \theta^*)}\right] = D_{KL}\left(q(\cdot) \mid \mid  p(\cdot\mid \theta^*)\right) - D_{KL}\left(q(\cdot) \mid \mid  p(\cdot\mid \theta)\right) &lt; 0\]

<p>The above result is negative since we assume that \(\theta^*\) minimizes the KL divergence between \(q(\cdot)\) and \(p(\cdot\mid \theta)\). So far we have found that</p>

\[\sum_{i=1}^m \log \frac{p(y_i\mid \theta) }{p(y_i\mid \theta^)} \to m\mathbf{E}_q\left[ \log \frac{p(y_i\mid \theta) }{p(y_i\mid \theta^)}\right] \to -\infty\]

<p>since the expected value we found to be negative, and as \(m\to\infty\), the value goes to negative infinity. Plugging back into the initial equation we have</p>

\[\log \frac{p(\theta\mid y)}{p(\theta^*\mid y)} = \log \frac{p (\theta)}{p (\theta^*)} + \sum_{i=1}^m \log \frac{p(y_i\mid \theta) }{p(y_i\mid \theta^*)} = \log \frac{p (\theta)}{p (\theta^*)} -\infty \to -\infty\]

\[\log \frac{p(\theta\mid y)}{p(\theta^*\mid y)}  \to -\infty\]

<p>This implies that \(p(\theta\mid y)/p(\theta^*\mid y) \to 0\), which means that \(p(\theta\mid y) \to 0\). We started with the fact that \(\theta\neq\theta^*\). So if \(p(\theta\mid y)\to 0\) for \(\theta\neq\theta^*\), then \(p(\theta^*\mid y)\to 1\).</p>

<h1 id="expectation-maximization">Expectation Maximization</h1>

<h3 id="guassian-mixture-models">Guassian Mixture Models:</h3>

<p>In Gaussian Mixture model, you assume that your data is coming from a combination of Gaussian (Gaussian Mixture). There is a latent variable, \(z\), that determines which Gaussian to pick or how to combine the Gaussian models. In this latent model, we are interested to find \(\theta\) parameters of the Gaussian, such that \(p(x\mid \theta)\) is maximized. Let’s assume that the latent variable is discrete and \(z=1\) or \(2\). The probability of observing a datapoint is</p>

\[p(x\mid \theta) = \sum_{c=1}^2 p(x,z=c\mid \theta) = \sum_{c=1}^2 p(z=c)~p(x\mid \theta,z)\]

<p>Our goal as usual is to find \(\max_\theta p(X\mid \theta))\). We have</p>

\[\max_\theta p(X\mid \theta) = \max_\theta \log p(X\mid \theta)= \max_\theta \log \Pi_{i=1}^N p(x_i\mid \theta)=  \max_\theta \sum_{i=1}^N \log p(x_i\mid \theta)\]

\[\max*\theta p(X\mid \theta) = \max*\theta \sum*{i=1}^N \log \sum*{c=1}^2 p(x*i,z_i=c\mid \theta)\\ = \max*\theta \sum*{i=1}^N \log \sum*{c=1}^2 \frac{q(z*i=c)}{q(z_i=c)}p(x_i,z_i=c\mid \theta) \\ = \max*\theta \sum*{i=1}^N \log \sum*{c=1}^2q(z*i=c) \frac{p(x_i,z_i=c\mid \theta)}{q(z_i=c)}) \\ \geq \max*\theta \sum*{i=1}^N \sum*{c=1}^2 q(z_i=c) \log \frac{p(x_i,z_i=c\mid \theta)}{q(z_i=c)})\]

<p>So, in summary we have found the following</p>

\[\boxed{\log p(X\mid \theta) \geq \mathcal{L}(\theta,q) \text{ for any } q }\\ \boxed{\mathcal{L}(\theta,q) = \sum_{i=1}^N \sum_{c=1}^2 q(z_i=c) \log   \frac{p(x_i,z_i=c\mid \theta)}{q(z_i=c)}) }\]

<p>So, we do the above part in two steps as follows (Expectation step)</p>

\[\boxed{q^{k+1} = \text{argmax}_q \mathcal{L}(\theta^k,q)}\]

<p>and next (Maximization step)</p>

\[\boxed{\theta^{k+1} = \text{argmax}_\theta \mathcal{L}(\theta,q^{k+1})}\]

<h3 id="e-step">E-Step:</h3>

<p>Let’s look at the E-Step. In order to do so, let’s look at the difference between the log-likelihood and the lowerbound that we defined</p>

\[\log p(X,\theta)-\mathcal{L}(\theta,q) = \sum_{i=1}^N \log p(x_i\mid \theta)  - \sum_{i=1}^N \sum_{c=1}^2 q(z_i=c) \log   \frac{p(x_i,z_i=c\mid \theta)}{q(z_i=c)}) \\ = \sum_{i=1}^N \log p(x_i\mid \theta) \sum_{c=1}^2 q(z_i=c)  - \sum_{i=1}^N \sum_{c=1}^2 q(z_i=c) \log   \frac{p(x_i,z_i=c\mid \theta)}{q(z_i=c)}) \\ = \sum_{i=1}^N \sum_{c=1}^2 q(z_i=c)  \left( \log p(x_i\mid \theta)  -\log   \frac{p(x_i,z_i=c\mid \theta)}{q(z_i=c)}) \right)\\ = \sum_{i=1}^N \sum_{c=1}^2 q(z_i=c)  \left( \log   \frac{q(z_i=c) p(x_i\mid \theta) }{p(x_i,z_i=c\mid \theta)}) \right) \\ = \sum_{i=1}^N \sum_{c=1}^2 q(z_i=c)  \left( \log   \frac{q(z_i=c) }{p(z_i=c\mid x_i,\theta)}) \right) \\ = D_{KL}\left({q(z_i=c) }\mid \mid {p(z_i=c\mid x_i,\theta)} \right)\]

<p>So we found that</p>

\[\boxed{\log p(X\mid \theta) - \mathcal{L}(\theta,q) = D_{KL}\left({q(z_i=c) }\mid \mid {p(z_i=c\mid x_i,\theta)} \right)}\]

<p>which basically means that to maximize lowerbound \(\mathcal{L}(\theta,q)\) (which minimizes the distance between the log-likelihood and the lowerbound), we need to minimize the KL-divergence on the righthandside. The KL divergence is zero when the two PDFs are the same, so</p>

\[q(z_i=c) = p(z_i=c\mid x_i,\theta)\]

<h3 id="m-step">M-Step:</h3>

<p>Now we are interested to maximize the following with respect to \(\theta\) as</p>

\[\mathcal{L}(\theta,q) = \sum_{i=1}^N \sum_{c=1}^2 q(z_i=c) \log   \frac{p(x_i,z_i=c\mid \theta)}{q(z_i=c)})  \\= \sum_{i=1}^N \sum_{c=1}^2 q(z_i=c) \log   {p(x_i,z_i=c\mid \theta)}) - \sum_{i=1}^N \sum_{c=1}^2 q(z_i=c) \log   {q(z_i=c)})\\ = \mathbf{E}_q \log p(X,Z\mid \theta)\]

<h3 id="summary-of-expectation-maximization">Summary of Expectation-Maximization:</h3>

<p>E-step:</p>

\[\boxed{q^{k+1}(z_i) = p(z_i\mid x_i,\theta^k) }\]

<p>which results in the fact that \(\log p(X,\theta) = \mathcal{L}(\theta,q^{k+1})\). Next for the M-step, we have</p>

\[\boxed{\theta^{k+1} = \text{argmax}_\theta \mathbf{E}_q \log p(X,Z\mid \theta)}\]

<p>Note that this maximizes the lower bound, however it is guaranteed that \(\log p(X\mid \theta^{k+1}) \geq \mathcal{L}(\theta^{k+1},q^{k+1})\)</p>

<h3 id="convergence">Convergence</h3>

<p>We have</p>

\[\log p(X\mid \theta^{k+1}) \geq \mathcal{L}(\theta^{k+1},q^{k+1}) \geq \mathcal{L}(\theta^k,q^{k+1}) = \log p(X\mid \theta^k)\]

<h3 id="gaussian-mixture-models-gmm">Gaussian Mixture Models (GMM)</h3>

<p>In these models, we assume that the data is coming from a mixture of Gaussian distributions \(\mathcal{N}(\mu,\Sigma)\) and the latent distribution is a categorical distribution \(\phi\). This basically means that</p>

\[\boxed{p(X) = \sum_{k=1}^K \pi_k \mathcal{N}(X\mid \mu_k,\Sigma_k)}\]

<p>where \(\sum_k \pi_k = 1\). Note that \(\theta = \{ \mu_1,\Sigma_1, \cdots, \mu_K,\Sigma_K\}.\) Now, let’s assume the latent variable is called \(z_i\). Using Expectation-Maximization that we discussed here, we find that</p>

\[q(z_i = k) = p(z_i=k\mid x_i,\theta) = \frac{p(z_i=k) p(x_i \mid  z_i=k,\theta) }{p(x_i\mid \theta)} = \frac{p(z_i=k)p(x_i \mid  z_i=k,\theta) }{\sum_{k} p(z_i=k) p(x_i \mid  z_i=k,\theta) } \\ \boxed{q(z_i=k) = \frac{\pi_k \mathcal{N}(x_i\mid \mu_k,\Sigma_k)}{\sum_k\pi_k \mathcal{N}(x_i\mid \mu_k,\Sigma_k)}}\]

<p>Next, in the Maximization step, we have</p>

\[\theta^*= \max_\theta \mathbf{E}_q \log p(X,Z\mid \theta) = \max_\theta \log p(X\mid \theta) \\ \theta^* = \max_\theta \sum_i \log \left( \sum_k \pi_k \mathcal{N}(x_i\mid \mu_k,\sigma_k) \right)\]

<p>Taking the derivative with respect to the \(\mu_k\), we find that</p>

\[\frac{\partial \cdots}{\partial \mu_k} = 0 = \sum_i \frac{\pi_k \mathcal{N}(x_i\mid \mu_k,\sigma_k)}{\sum_k \pi_k \mathcal{N}(x_i\mid \mu_k,\sigma_k) } \\  \sum_i q(z_i=k)   \Sigma_k^{-1}(x_i - \mu_k) =0 =  \sum_i q(z_i=k)   (x_i - \mu_k) \\ \boxed{\mu_k =\frac{\sum_i q(z_i=k) x_i}{\sum_i q(z_i=k)}}\]

<p>Similarly, we can find that</p>

\[\boxed{\Sigma_k =   \frac{ \sum_i q(z_i=k)(x_i-\mu)^\top(x_i-\mu)}{  \sum_i q(z_i=k)}  }\]

<h3 id="k-means-as-em">K-Means as EM</h3>

<p>Imagine the K-means model, where we randomly initialize \(\theta = \{\mu_1, \cdots, \mu_C\}\) points, and then we repeat the following steps until convergence</p>

<ul>
  <li>For each point we calculate the closest centroid</li>
</ul>

\[z_i = \text{argmin}_k \\mid x_i-\mu_k\\mid ^2\]

<ul>
  <li>Update centroid</li>
</ul>

\[\mu_k = \frac{\sum_{i:z_i=k} x_i}{\sum_{i:z_i=k} 1}\]

<p>The above K-means model can be think of as a GMM. Imagine we fix the covariance matrix to be identity, $\Sigma_k = I$, and also we fix the weights to be \(\pi_k = 1/\#\text{of Gaussians}\). We then will have</p>

\[p(x_i\mid z_i=k,\theta) = \frac{1}{Z} \exp\left(-\frac{1}{2} \\mid x_i-\mu_k\\mid ^2\right)\]

<p>Then, in the E-step, we pick \(q(z)\) such that they belong to the delta functions. Then are interested to find a function from the family of delta functions such that</p>

\[q(z_i) = \begin{cases} 1 &amp; \text{ if } z_i = \text{argmax}_k p(z_i=k\mid x_i,\theta)\\ 0 &amp; \text{otherwise}\end{cases}\]

<p>Note that</p>

\[p(z_i=k\mid x_i,\theta) = \frac{1}{Z} p(x_i\mid z_i,\theta) p(z_i\mid \theta) = \frac{1}{Z} \exp(-\frac{1}{2}\\mid  x_i-\mu_k\\mid ^2) \pi_k\]

<p>So the above maximization problem becomes</p>

\[q(z_i) = \begin{cases} 1 &amp; \text{ if } z_i = \text{argmin}_k  \\mid x_i-\mu_k\\mid ^2 \\ 0&amp; \text{otherwise}\end{cases}\]

<p>which is the same as the first step in the K-means. Now, lets look at the M-step, using the GMM derivation that we did above, we ha</p>

\[\mu_k =\frac{\sum_i q(z_i=k) x_i}{\sum_i q(z_i=k)} = \frac{\sum_{i:z_i=k} x_i}{\sum_{i:z_i=k} 1}\]

<h3 id="implementing-gmm-in-python">Implementing GMM in python</h3>

<p>So in GMM we are implementing the following formulae</p>

<p>E-step:</p>

\[q(z_i=k) = \frac{\pi_k \mathcal{N}(x_i\mid \mu_k,\Sigma_k)}{\sum_k\pi_k \mathcal{N}(x_i\mid \mu_k,\Sigma_k)}\]

<p>M-Step:</p>

\[\mu_k =\frac{\sum_i q(z_i=k) x_i}{\sum_i q(z_i=k)}\]

\[\Sigma_k =   \frac{ \sum_i q(z_i=k)(x_i-\mu)^\top(x_i-\mu)}{  \sum_i q(z_i=k)}\]

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">scipy</span> <span class="kn">import</span> <span class="n">stats</span>
<span class="c1"># here we denote q(z_i=k) with a NxC matrix called gamma
# where N is the number of poitns i=1,...,N
# and C is the number of clusters
</span><span class="k">def</span> <span class="nf">E_step</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">pi</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Performs E-step on GMM model
    Each input is numpy array:
    X: (N x d), data points
    pi: (C), mixture component weights
    mu: (C x d), mixture component means
    sigma: (C x d x d), mixture component covariance matrices

    Returns:
    gamma: (N x C), probabilities of clusters for objects

    P(z\mid x) = (p(x\mid z) p(z))/(sum_z p(x\mid z) p(z) )
    gamma  =
    </span><span class="sh">"""</span>
    <span class="n">N</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># number of objects
</span>    <span class="n">C</span> <span class="o">=</span> <span class="n">pi</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># number of clusters
</span>    <span class="n">d</span> <span class="o">=</span> <span class="n">mu</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># dimension of each object
</span>    <span class="n">gamma</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">))</span> <span class="c1"># distribution q(T)
</span>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">C</span><span class="p">):</span>
      <span class="n">pi_i</span> <span class="o">=</span> <span class="n">pi</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
      <span class="n">gamma</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">pi_i</span><span class="o">*</span><span class="n">stats</span><span class="p">.</span><span class="nf">multivariate_normal</span><span class="p">(</span><span class="n">mu</span><span class="p">[</span><span class="n">i</span><span class="p">,:],</span><span class="n">sigma</span><span class="p">[</span><span class="n">i</span><span class="p">,:,:]).</span><span class="nf">pdf</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

    <span class="n">gamma</span> <span class="o">=</span> <span class="n">gamma</span><span class="o">/</span><span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">gamma</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">gamma</span>

<span class="k">def</span> <span class="nf">M_step</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">gamma</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Performs M-step on GMM model
    Each input is numpy array:
    X: (N x d), data points
    gamma: (N x C), distribution q(T)

    Returns:
    pi: (C)
    mu: (C x d)
    sigma: (C x d x d)
    </span><span class="sh">"""</span>
    <span class="n">N</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># number of objects
</span>    <span class="n">C</span> <span class="o">=</span> <span class="n">gamma</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># number of clusters
</span>    <span class="n">d</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># dimension of each object
</span>
    <span class="n">resp_weights</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">gamma</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">pi</span> <span class="o">=</span> <span class="n">resp_weights</span><span class="o">/</span><span class="p">(</span><span class="mf">1.0</span><span class="o">*</span><span class="n">N</span><span class="p">)</span>

    <span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">gamma</span><span class="p">.</span><span class="n">T</span><span class="p">,</span><span class="n">X</span><span class="p">)</span><span class="o">/</span><span class="n">resp_weights</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">sigma</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">C</span><span class="p">,</span><span class="n">d</span><span class="p">,</span><span class="n">d</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">C</span><span class="p">):</span>
      <span class="n">diff</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span><span class="o">-</span><span class="n">mu</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
      <span class="n">weighted_sum</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">((</span><span class="n">gamma</span><span class="p">[:,</span><span class="n">i</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">diff</span><span class="p">).</span><span class="n">T</span><span class="p">,</span><span class="n">diff</span><span class="p">)</span>
      <span class="n">sigma</span><span class="p">[</span><span class="n">i</span><span class="p">,:,:]</span> <span class="o">=</span> <span class="n">weighted_sum</span><span class="o">/</span><span class="n">resp_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">pi</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span>

<span class="k">def</span> <span class="nf">train_EM</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">restarts</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="sh">'''</span><span class="s">
    Starts with random initialization *restarts* times
    Runs optimization until saturation with *rtol* reached
    or *max_iter* iterations were made.

    X: (N, d), data points
    C: int, number of clusters
    </span><span class="sh">'''</span>
    <span class="n">N</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># number of objects
</span>    <span class="n">d</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># dimension of each object
</span>    <span class="n">best_loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="n">inf</span>
    <span class="n">best_pi</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="n">best_mu</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="n">best_sigma</span> <span class="o">=</span> <span class="bp">None</span>

    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">restarts</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">pi</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="n">C</span><span class="p">)</span><span class="o">/</span><span class="nf">float</span><span class="p">(</span><span class="n">C</span><span class="p">)</span>
            <span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="n">C</span><span class="p">,</span><span class="n">d</span><span class="p">)</span>
            <span class="n">sigma</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">C</span><span class="p">,</span><span class="n">d</span><span class="p">,</span><span class="n">d</span><span class="p">))</span>
            <span class="n">sigma</span><span class="p">[...]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">identity</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
            <span class="n">prev_loss</span> <span class="o">=</span> <span class="bp">None</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">max_iter</span><span class="p">):</span>
              <span class="n">gamma</span> <span class="o">=</span> <span class="nc">E_step</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">pi</span><span class="p">,</span><span class="n">mu</span><span class="p">,</span><span class="n">sigma</span><span class="p">)</span>
              <span class="n">pi</span><span class="p">,</span><span class="n">mu</span><span class="p">,</span><span class="n">sigma</span> <span class="o">=</span> <span class="nc">M_step</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">gamma</span><span class="p">)</span>
              <span class="n">loss</span> <span class="o">=</span> <span class="nf">compute_vlb</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">pi</span><span class="p">,</span><span class="n">mu</span><span class="p">,</span><span class="n">sigma</span><span class="p">,</span><span class="n">gamma</span><span class="p">)</span>

              <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="p">.</span><span class="nf">isnan</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span> <span class="ow">and</span> <span class="n">loss</span><span class="o">&gt;</span><span class="n">best_loss</span><span class="p">:</span>
                <span class="n">best_loss</span> <span class="o">=</span> <span class="n">loss</span>
                <span class="n">best_mu</span> <span class="o">=</span> <span class="n">mu</span>
                <span class="n">best_pi</span> <span class="o">=</span> <span class="n">pi</span>
                <span class="n">best_sigma</span> <span class="o">=</span> <span class="n">sigma</span>

              <span class="k">if</span> <span class="n">prev_loss</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
                <span class="n">diff</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">abs</span><span class="p">(</span><span class="n">prev_loss</span><span class="o">-</span><span class="n">loss</span><span class="p">)</span><span class="o">/</span><span class="n">np</span><span class="p">.</span><span class="nf">abs</span><span class="p">(</span><span class="n">prev_loss</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">diff</span> <span class="o">&lt;</span> <span class="n">rtol</span><span class="p">:</span>
                  <span class="k">break</span>
              <span class="n">prev_loss</span> <span class="o">=</span> <span class="n">loss</span>

        <span class="k">except</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">LinAlgError</span><span class="p">:</span>
            <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Singular matrix: components collapsed</span><span class="sh">"</span><span class="p">)</span>
            <span class="k">pass</span>

    <span class="k">return</span> <span class="n">best_loss</span><span class="p">,</span> <span class="n">best_pi</span><span class="p">,</span> <span class="n">best_mu</span><span class="p">,</span> <span class="n">best_sigma</span>
</code></pre></div></div>

<p>Benefits of GMM models: in unsupervised clustering for example, KNN methods accuracy will increase as we increase the number of groups. So you never know how many groups are better for KNN methods. In GNN on the other hand, the accuracy increases and then decreases. So increasing the number of clusters does not necessary increase the accuracy.</p>

<h3 id="dirichlet-distribution">Dirichlet Distribution</h3>

<p>A Dirichlet distribution is defined as</p>

\[f(\theta;\alpha) = \frac{1}{B(\alpha)} \Pi_{i=1}^K \theta_i^{\alpha_i-1}\]

<p>Note that \(\sum_{i=1}^K \theta_i = 1\) and \(\theta_i&gt;0\). The expected value and variance can be found as</p>

<p>Note that the Dirichlet distribution is conjugate to the multinomial distribution as</p>

\[p(\theta) = \frac{n!}{x_1! \cdots x_K!} \Pi_{i=1}^K \theta_i^{x_i}\]

<p>So if prior has a Dirichlet distribution, and likelihood is a multinomial, then the posetrior will also be a Dirichlet distribution.</p>

<h3 id="latent-dirichelet-model">Latent Dirichelet Model</h3>

<p>Imagine the following model for the distribution of words in a document</p>

<p><br /></p>
<div class="row mt-3" style="text-align:center;">
    <div class="col-sm mt-3 mt-md-0">
        <img class="img-fluid rounded z-depth-1" width="300" src="/assets/research/bayes1.jpg" />
    </div>
</div>
<p><br /></p>

<p>In latent Dirichelet model, we have</p>

\[p(W,Z,\theta) = \Pi_{d=1}^D p(\theta_d) \Pi_{n=1}^{N_d} p(z_{dn}\mid \theta_d)~p(w_{dn}\mid z_{dn})\]

<p>where \(p(\theta_d)\sim \text{Dir}(\alpha)\), and \(p(z_{dn}\mid \theta_d) = \theta_{dz_{dn}}\), and \(p(w_{dn}\mid z_{dn}) = \Phi_{z_{dn},w_{dn}}\), where \(\sum \Phi_{z_{dn},w_{dn}} =1\). In order to calculate the E-step, we first need to find the log-likelihood, where we have</p>

\[\log p(W,Z,\theta) = \sum_{d=1}^D \left[ \sum_{t=1}^T (\alpha_t-1) \log \theta_{dt} +  \sum_{n=1}^{N_d} \sum_{t=1}^T \mathbf{1}(z_{dn}=t) \left(\log \theta_{dt} + \log \phi_{tw_{dn}} \right) \right] + \text{C.}\]

<p>In the E-step, we want to</p>

\[\min D_{KL}\left( q(\theta) q(Z) \\mid  p(\theta,Z\mid W) \right)\]

\[\log q(\theta) = \mathbf{E}_{q(z)} \log p(\theta,Z,W)  =  \mathbf{E}_{q(z)} \log p(\theta,Z\mid  W) + C.\]

\[\log q(\theta) = \mathbf{E}_{q(z)} \sum_{d=1}^D \left[ \sum_{t=1}^T (\alpha_t-1) \log \theta_{dt} +  \sum_{n=1}^{N_d} \sum_{t=1}^T\mathbf{1}(z_{dn}=t) \left(\log \theta_{dt} + \log \phi_{tw_{dn}} \right) \right]\\ = \mathbf{E}_{q(z)} \sum_{d=1}^D \left[ \sum_{t=1}^T (\alpha_t-1) \log \theta_{dt} +  \sum_{n=1}^{N_d}\sum_{t=1}^T \mathbf{1}(z_{dn}=t) \left(\log \theta_{dt} \right) \right] \\ =  \sum_{d=1}^D \left[ \sum_{t=1}^T (\alpha_t-1) \log \theta_{dt} +  \sum_{n=1}^{N_d} \sum_{t=1}^T \mathbf{E}_{q(z)}\left[\mathbf{1}(z_{dn}=t)\right] \left(\log \theta_{dt}  \right) \right] \\  =  \sum_{d=1}^D \sum_{t=1}^T \log \theta_{dt} \left[ (\alpha_t-1)  +  \sum_{n=1}^{N_d} \mathbf{E}_{q(z)}\left[\mathbf{1}(z_{dn}=t)\right] \right]\]

<p>So in summary, we have</p>

\[\boxed{\log q(\theta) =  \sum_{d=1}^D \sum_{t=1}^T \log \theta_{dt} \left[ (\alpha_t-1)  +  \sum_{n=1}^{N_d} \gamma_{dn}^t \right]} \\ \boxed{\gamma_{dn}^t = \mathbf{E}_{q(z)}\left[\mathbf{1}(z_{dn}=t)\right]}\]

\[\to q(\theta) \propto \Pi_d \Pi_t \theta_{dt}^{\left[\alpha_t + \sum_n \gamma^t_{dn} - 1\right]}\]

<p>Now, let’s take the E-step for \(q(Z)\), we have</p>

\[\log q(Z) = \\  \mathbf{E}_{q(\theta)} \sum_{d=1}^D \left[ \sum_{t=1}^T (\alpha_t-1) \log \theta_{dt} +  \sum_{n=1}^{N_d} \sum_{t=1}^T\mathbf{1}(z_{dn}=t) \left(\log \theta_{dt} + \log \phi_{tw_{dn}} \right) \right] \\ = \mathbf{E}_{q(\theta)} \sum_{d=1}^D  \sum_{n=1}^{N_d} \mathbf{1}(z_{dn}=t) \left(\log \theta_{dt} + \log \phi_{tw_{dn}} \right)  \\ =  \sum_{d=1}^D  \sum_{n=1}^{N_d} \mathbf{1}(z_{dn}=t) \left(\mathbf{E}_{q(\theta)} \log \theta_{dt} + \log \phi_{tw_{dn}} \right)\]

<p>so in summary</p>

\[\boxed{\log q(Z) = \sum_{d=1}^D  \sum_{n=1}^{N_d} \mathbf{1}(z_{dn}=t) \left(\mathbf{E}_{q(\theta)} \log \theta_{dt} + \log \phi_{tw_{dn}} \right) } \\ \to q(Z) = \Pi_d \Pi_t q(z_{dn})\\ q\left( z_{dn}=t\right) =   \frac{\phi_{t w_{dn}} \exp \left( \mathbf{E}_{q(\theta)} \log \theta_{dt} \right)}{\sum_{t'} {\phi_{t' w_{dn}} \exp \left( \mathbf{E}_{q(\theta)} \log \theta_{dt'} \right)}}\]

<p>and in the M-step we would like to maximize the following</p>

\[\mathbf{E}_{q(\theta)q(Z)} \log p(\theta,Z,W)  = \mathbf{E}_{q(\theta)q(Z)}  \left[ \sum_{d=1}^D \left[ \sum_{t=1}^T (\alpha_t-1) \log \theta_{dt} +  \sum_{n=1}^{N_d} \sum_{t=1}^T \mathbf{1}(z_{dn}=t) \left(\log \theta_{dt} + \log \phi_{tw_{dn}} \right) \right] \right] \\ = \mathbf{E}_{q(\theta)q(Z)}  \left[ \sum_{d=1}^D \sum_{t=1}^T \sum_{n=1}^{N_d} \mathbf{1}(z_{dn}=t)  \log \phi_{tw_{dn}} \right] \\  =   \sum_{d=1}^D \sum_{t=1}^T \sum_{n=1}^{N_d} \mathbf{E}_{q(\theta)q(Z)} \left[\mathbf{1}(z_{dn}=t)\right]  \log \phi_{tw_{dn}} \\ =   \sum_{d=1}^D \sum_{t=1}^T \sum_{n=1}^{N_d} \gamma_{dn}^t  \log \phi_{tw_{dn}}\]

<p>given that \(\sum_w \phi_{tw} = 1\) and also \(\phi_{tw}\geq 0\). We use lagrangian to maximize the above equation, we have</p>

\[L =  \sum_{d=1}^D \sum_{t=1}^T \sum_{n=1}^{N_d} \gamma_{dn}^t \log \phi_{tw_{dn}} - \sum_{t=1}^T \lambda_t \left(\sum_w \phi_{tw}-1\right)\]

<p>Now we take the derivative to maximize the above equation, we find</p>

\[\frac{\partial L}{\partial \phi_{tw}} = \sum_{d=1}^D \sum_{n=1}^{N_d} \gamma_{dn}^t \frac{1}{\phi_{tw}}\mathbf{1}\left[w_{dn} = w\right] -  \lambda_t  = 0 \\ \phi_{tw} = \frac{\sum_{d=1}^D \sum_{n=1}^{N_d} \gamma_{dn}^t \mathbf{1}\left[w_{dn}= w\right]}{ \lambda_t}\]

<p>Knowing that \(\sum_w \phi_{tw} = 1\), we can find that</p>

\[\phi_{tw} = \frac{\sum_{d=1}^D \sum_{n=1}^{N_d} \gamma_{dn}^t \mathbf{1}\left[w_{dn}= w\right]}{ \sum_w \sum_{d=1}^D \sum_{n=1}^{N_d} \gamma_{dn}^t \mathbf{1}\left[w_{dn}= w\right]} \\ \to \boxed{\phi_{tw} = \frac{\sum_{d,n} \gamma_{dn}^t \mathbf{1}\left[w_{dn}= w\right]}{ \sum_{d,n,w'} \gamma_{dn}^t \mathbf{1}\left[w_{dn}= w'\right]}}\]

<h2 id="monte-carlo-method">Monte-Carlo Method</h2>

<p>Estimating expected values using sampling</p>

\[\mathbf{E}_{p(x)} f(x) = \frac{1}{M} \sum f(x_s), \quad \text{where } x_s\sim p(x)\]

<p>Now the question is how to sample from a probability distribution \(p(x)\)? In the following we will discuss this. Note that we assume that generating a random number with uniform distribution from in \([0,1]\) is given, i.e., we can easily sample form \(\mathcal{U}(0,1)\).</p>

<h3 id="sampling-from-1-d-distribution">Sampling from 1-D distribution</h3>

<p>Consider a distribution over discrete set such as \(p(a_i) = p_i\) for \(i=1,\cdots,n\). Note that \(\sum_i p_i = 1\). We can separate the \([0,1]\) distance proportional to the \(p_i\). Next, we sample a point from $[0,1]$ using the uniform distribution, we can assign it to the discrete values of \(a_i\) based on the interval that it lands into. Here is an example:</p>

<p><br /></p>
<div class="row mt-3" style="text-align:center;">
    <div class="col-sm mt-3 mt-md-0">
        <img class="img-fluid rounded z-depth-1" width="300" src="/assets/research/bayes2.png" />
    </div>
</div>
<p><br /></p>

<p>Sampling Normal distribution:</p>

<p>We can generate normal distribution using central limit theorem, i.e.</p>

\[x = \frac{1}{\sqrt{N}} \left[ \sum_{i=1}^N \left( x_i - \frac{1}{2}\right) \right]\]

<p>As the \(N\to \infty\), the \(p(x) \to \mathcal{N}(0,1)\). This has been done very efficiently, and we can use packages such as <code class="language-plaintext highlighter-rouge">np.random.randn()</code> to generate these numbers. Now imagine that we are interested in 1d sampling from a continuous distribution such as \(p(x)\) shown below</p>

<p><br /></p>
<div class="row mt-3" style="text-align:center;">
    <div class="col-sm mt-3 mt-md-0">
        <img class="img-fluid rounded z-depth-1" width="300" src="/assets/research/bayes3.png" />
    </div>
</div>
<p><br /></p>

<p>One way to sample from \(p(x)\) in the above is to first bound the pdf by some normal distribution $q(x)$. Next, we generate a random point, say \(x_0\). We then accept this point with probability \(\alpha= p(x)/q(x)\) and reject it with \(1-\alpha\). This way, we create samples from the \(p(x)\).</p>

<h3 id="markov-chains">Markov-Chains</h3>

<p>There are two methods that we will introduce here (Metropolis-Hasting and Gibbs sampling) that depend on Markov-Chain. A few introductory remarks on Markov-process is helpful before we talk about them.</p>

<p>Let \(X_t\) denote the value of a random variable at time $t$. The <em>state space</em> is the space of all possible values for $X$ values. The random variable is called a <strong>Markov process</strong> if the transition probabilities betwen different values in the state space only depend on the current’s value of the random variable, i.e.,</p>

\[p(X_{t+1}=s_{j}\mid X_0=s_k, \cdots, X_t=s_i) = p(X_{t+1}=s_{j}\mid  X_t=s_i)\]

<p>A Markov-Chain referes to a sequence of random variables \((X_0, \cdots,X_n)\) generated by a markov process. Transition probability (or the transition kernel) gives us the probability of transitioning between the states ina single step, i.e.,</p>

\[p(i\to j) = p(X_{t+1}=s_j\mid  X_{t}=s_i)\]

<p>Using the transition kernel, if we are at state \(s_i\) we can define a row vector for the state space probabilities, i.e., \(\pi_i(t) = p(X_t = s_i)\). The evolution of this state space probabilities can be obtained using the kernel as</p>

\[\pi_j(t+1) = p(X_{t+1}=s_j) \\= \sum_k p(X_{t+1}=s_j\mid   X_t = s_k) p(X_t = s_k) = \sum_k p(k,j) \pi_k(t) \\ \mathbf{\pi}(t+1) = \mathbf{\pi}(t) \mathbf{P}\]

<p>As a result, we can find that \(\pi(t) = \pi(0) \mathbf{P}^k\). A distribution of states $\mathbf{\pi}^*$ is called stationary if \(\mathbf{\pi}^* = \mathbf{\pi}^*\mathbf{P}\). A sufficient condition for a unique stationary distribution is that the <strong>detailed balance</strong> condition holds</p>

\[p(j\to k) \pi^*_j = p(k\to j) \pi^*_k\]

<p>If the above condition holds then we have</p>

\[(\mathbf{\pi}\mathbf{P})_j = \sum_i \pi_i P(i,j) = \sum_i \pi_i P(i\to j) \\= \sum_i \pi_j P(j\to i)  = \pi_j \sum_i P(j\to i) = \pi_j\]

<h3 id="metropolis-hasting-algorithm">Metropolis-Hasting Algorithm</h3>

<p>So our goal is to generate a sample with PDF \(p(x)\). In Metropolis-Hasting the basic idea is to create a Markov-Process to generate new data points where \(p(x)\) is its stationary distribution. If \(p(x)\) is stationary distribution, then using following the Markov process for a long time we will generate data-points that have the distribution of \(p(x)\). But how can we create a Markov-Process where \(p(x)\) is its stationary distribution? We can use the idea of rejecting points. We start with any Markov-process \(Q\) (as long as we have a non-zero probability of going over all the data points), we then start from a data-point \(x_0\) (or state) and find our new data-point \(x_1\) (the new state). Now we have an option of accepting this new state or rejecting it. We select this acceptance/rejection probability such that our \(p(x)\) becomes the stationary distribution of our Markov process.</p>

\[p(x_0) Q(x_0\to x_1) A(x_0 \to x_1) = p(x_1) Q(x_1\to x_0) A(x_1 \to x_0) \\ \frac{A(x_0 \to x_1)}{A(x_1 \to x_0)} = \frac{p(x_1)}{p(x_0)} \frac{Q(x_1\to x_0)}{Q(x_0\to x_1)} = \rho\]

<p>So as long as our acceptance probability follows the above equality, we are doing well. Assume that the above proportionality is \(\rho\). If \(\rho\leq 1\), we can have \(A(x_0\to x_1) = \rho, A(x_1\to x_0) = 1\). On the other hand, if \(\rho&gt;1\), we can assign \(A(x_0\to x_1) = 1, A(x_1\to x_0) = 1/\rho\). So basically, we can assign the following acceptance probability</p>

\[A(x_0\to x_1) = \begin{cases} \rho &amp; \rho \leq 1 \\ 1 &amp; \rho &gt;1 \end{cases}\]

<p>Or we can summarize it as</p>

\[A(x_0\to x_1) = \min\left(1, \frac{p(x_1)}{p(x_0)} \frac{Q(x_1\to x_0)}{Q(x_0\to x_1)} \right)\]]]></content><author><name></name></author><summary type="html"><![CDATA[Machine learning]]></summary></entry><entry><title type="html">Optimum first guess for Persian Wordle (in Farsi)</title><link href="https://azareei.github.io/blog/2022/wordle/" rel="alternate" type="text/html" title="Optimum first guess for Persian Wordle (in Farsi)" /><published>2022-01-26T02:30:00+00:00</published><updated>2022-01-26T02:30:00+00:00</updated><id>https://azareei.github.io/blog/2022/wordle</id><content type="html" xml:base="https://azareei.github.io/blog/2022/wordle/"><![CDATA[<p><a href="vajoor.ir">Vaajoor</a> is the persian version of <a href="https://www.powerlanguage.co.uk/wordle/">wordle</a>. In this post I explore the optimum first guess for <a href="vajoor.ir">Vaajoor</a> in persian.</p>

<p><br /></p>

<p style="text-align:right;dir:rtl;">
در بازی واجور هدف حدس زدن یک کلمه پنج حرفیه. در این بازی امکان پنج‌بار حدس زدن وجود داره. برای هر کلمه‌ای که حدس میزنیم، برای هر حرف سه حالت وجود داره: اگر حرف در کلمه اصلی وجود نداشته باشه، حرف قرمز میشه. اگر حرف در کلمه اصلی وجود داشته باشد، اما مکانش درست نباشه، زرد میشه. و اگر حرف هم در کلمه اصلی باشه و هم مکانش درست باشه، سبز میشه. خیلی شبیه به بازی فکر‌بکر هست اگه توی بچگی بازی کرده باشین. حال با حدس کلمه و اینکه هر حرف‌ آن در چه حالتی است، کلمه اصلی حدس زده میشه 
</p>

<p><br />
<br /></p>

<p style="text-align:right;dir:rtl;">
نمونه‌ای از بازی
</p>

<div class="row mt-3" style="text-align:center;">
    <div class="col-sm mt-3 mt-md-0">
        <img class="img-fluid rounded z-depth-1" width="300" src="/assets/posts/vajoor_sample.png" />
    </div>
</div>

<p><br />
<br /></p>

<p style="text-align:right;dir:rtl;">

سوالی که پیش میآید این هست که آیا حدس اول بهینه‌ای وجود داره؟

<br />

با نگاهی به لغات ۵ حرفی فرهنگ معین میبینیم که تعداد لغات پنج‌حرفی ۸۲۱۶ کلمه هست. حدس اول میتونه از کل این لیست باشه. با توجه به حدس اول، و اینکه چه حرف‌هایی در آن هست و نیست لیست کلمات قابل قبول برای حدس دوم کمتر میشه. سوال این هست که آیا حدس اولیه بهینه‌ای وجود داره؟
<br />

هر حدسی که ما میزنیم، بقیه کلمات رو به ۳*۳*۳*۳*۳ دسته تقسیم میکنه، با توجه به اینکه هر حرف این حدس ما در کدوم گروه سبز یا زرد یا قرمز میافته. پس هر کلمه‌ای، بقیه کلمات رو بین این ۳*۳*۳*۳*۳ = ۲۴۳ گروه تقسیم میکنه. حالا با توجه به اینکه کدوم گروه انتخاب شده، ادامه مسیر از بین کلمات اون گروه خواهد بود. حالا اگه حدس اولیه‌ای بهینه باشه، باید کلمات رو جوری بین این گروه‌ها تقسیم کنه، که لیست تعداد کلمات بعدی کمترین باشه! اگه اینجوری باشه، این کلمه انتخاب خوبی بوده
<br />

برای اینکه کلمه بهینه برای انتخاب اول رو پیدا کنیم، روی لیست تمام کلمات میگردیم، برای هر کلمه نگاه میکنیم که بقیه کلمات چه‌طور بین این ۲۴۳ گروه تقسیم میشن. برای هر گروه تعدادی ثبت میشه. ماکزیمم تعداد کلمات در یه گروه از این ۲۴۳ گروه رو برای اون کلمه ثبت میکنیم. در نهایت کلمه‌ای رو انتخاب میکنیم که این عدد ماکزیممش کمترین باشه. یعنی مینیمم این ماکزیمم رو پیدا میکنیم. در این صورت، در بدترین حالت حدسمون، تعداد کلمات برای انتخاب دوم کمترین شده
<br />

حالا همین کار رو من برای کلمات فارسی فرهنگ معین انجام دادم (کد شخمی نوشته شده پایین همین صفحه هست). به نظر میاد که حدس بهینه اول کلمه تریان هست. منم نمیدونستم تریان یعنی چه ! انگار به معنی چیزی هست که طبقی شکل هست و بافته شده از شاخ بید! والا منم نفهمیدم یعنی چی. حالا اگه کلمه تریان رو به عنوان انتخاب اول بزاریم، ماکزیمم تعداد کلمات در اون ۲۴۳ گروه فقط ۵۴۲ کلمه هست. یعنی در بد‌ترین حالت برای حدس دوم باید فقط از بین این ۵۴۲ کلمه انتخاب کنیم. حالا همین داستان رو برای حدس دوم هم میشه انجام داد، البته وقتی حدس اول در اومده باشه

<br />

حالا چون تریان خیلی واژه سختی شد، کلمه دوم هم نگاه کردم دیدم خیلی ساده‌تره: تیمار. هم کلمه راحت‌تری هست و هم آدم یادش بمونه. اگه کلمه تیمار رو برای حدس اول انتخاب کنین، برای حدس دوم در بدترین حالت فقط باید بین ۵۶۰ کلمه، اون کلمه مورد نظر رو پیدا کنین. در ادامه هم لینک گیت‌هاب این کد سر‌سری پایتون و لیست کلمات فرهنگ معین رو میزارم خواستین خودتون باش ور برین

</p>
<p><br />
<br /></p>

<p><a href="https://github.com/ahmadzareei/vajoor">Github Link</a></p>

<p><br />
<br /></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
</pre></td><td class="code"><pre><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="sh">'</span><span class="s">Moin_dictionary_words.txt</span><span class="sh">'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
<span class="n">lines</span> <span class="o">=</span> <span class="n">f</span><span class="p">.</span><span class="nf">readlines</span><span class="p">()</span>

<span class="n">lines</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">]</span>

<span class="n">words</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">lines</span> <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">==</span><span class="mi">5</span><span class="p">]</span>

<span class="kn">from</span> <span class="n">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>
<span class="n">score</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>\<span class="o">*</span><span class="nf">len</span><span class="p">(</span><span class="n">words</span><span class="p">)</span>
<span class="k">for</span> <span class="n">j</span><span class="p">,</span><span class="n">w</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">words</span><span class="p">):</span>
<span class="n">category</span> <span class="o">=</span> <span class="nf">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="k">for</span> <span class="n">w_inquiry</span> <span class="ow">in</span> <span class="n">words</span><span class="p">:</span>
<span class="n">key</span> <span class="o">=</span> <span class="sh">''</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">ch</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">w</span><span class="p">):</span>
<span class="k">if</span> <span class="n">ch</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">w_inquiry</span><span class="p">:</span>
<span class="n">key</span> <span class="o">+=</span> <span class="sh">'</span><span class="s">K</span><span class="sh">'</span> <span class="c1"># it's black
</span><span class="k">else</span><span class="p">:</span>
<span class="k">if</span> <span class="n">ch</span> <span class="o">==</span> <span class="n">w_inquiry</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
<span class="n">key</span> <span class="o">+=</span> <span class="sh">'</span><span class="s">G</span><span class="sh">'</span> <span class="c1"># it should be green
</span><span class="k">else</span><span class="p">:</span>
<span class="n">key</span> <span class="o">+=</span> <span class="sh">'</span><span class="s">Y</span><span class="sh">'</span> <span class="c1"># then it's yellow
</span><span class="n">category</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="n">score</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="nf">max</span><span class="p">(</span><span class="n">category</span><span class="p">.</span><span class="nf">values</span><span class="p">())</span>

<span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">score</span><span class="p">).</span><span class="nf">argsort</span><span class="p">()[:</span><span class="mi">20</span><span class="p">]:</span>
<span class="nf">print</span><span class="p">(</span><span class="n">score</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span><span class="n">words</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
</pre></td></tr></tbody></table></code></pre></figure>

<p style="text-align:right;dir:rtl;">
542 تریان
<br />
560 تیمار
<br />
611 رمانی
<br />
631 نوایر
<br />
631 روانی
<br />
643 ربانی
<br />
643 برانی
<br />
644 منابر
<br />
656 نرمال
<br />
661 بهیار
<br />
661 بیراه
<br />
663 ویران
<br />
663 رویان
<br />
680 تریاک
<br />
681 مهوار
<br />
681 میراب
<br />
681 هموار
<br />
681 بیمار
<br />
686 نهاری
<br />
686 مناره
</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Molavi]]></summary></entry><entry><title type="html">KL Divergence between two normal distributions</title><link href="https://azareei.github.io/blog/2021/KL-Divergence/" rel="alternate" type="text/html" title="KL Divergence between two normal distributions" /><published>2021-03-11T02:10:00+00:00</published><updated>2021-03-11T02:10:00+00:00</updated><id>https://azareei.github.io/blog/2021/KL-Divergence</id><content type="html" xml:base="https://azareei.github.io/blog/2021/KL-Divergence/"><![CDATA[<p>These is a review of Bayesian Machine Learning. It’s based on HSE’s course on this topic.</p>

<h3 id="maximum-likelihood-estimation-mle">Maximum Likelihood Estimation (MLE)</h3>

<p>The ML estimate for \(\theta\) is the value under which the data are most likely, i.e.</p>

\[\boxed{\hat{\theta}_{ML} \in \text{argmax}_\theta p(y|\theta)}\]

<p>Example: We know that a fair coin has \(p(\text{head}) = p(\text{tail}) = 1/2\). Now imagine you have a coin and you don’t know if it is fair or not. You decide to throw the coin \(m\) times, where you observe \(m_H\) times head, and \(m_T\) times tail, where \(m_H + m_T = m\). Now you ask given this observation, what is the probability of \(p(\text{head}), p(\text{tail})\) for this coin? We know that if \(p(\text{head}) =\theta\), then the likelihood of such observation is</p>

\[p(y|\theta) = \theta^{m_H} (1-\theta)^{m-m_H}\]

<p>Now, we are interested to find a \(\hat \theta_{ML}\) such that the above probability is maximized. Instead of the probability, we maximize its logarithm which will be easier. We have</p>

\[l(\theta) = m_H \log(\theta) + (m-m_H) \log(1-\theta)\]

<p>finding the \(\text{argmax}_\theta\) for the above equation we have</p>

\[\frac{d}{d\theta}d(\theta)|_{\hat\theta} = 0 = \frac{m_H}{\theta}|_{\hat\theta} - \frac{m-m_H}{1-\theta}|_{\hat\theta}\]

\[\longrightarrow \hat{\theta} = \frac{m_H}{m}\]

<h3 id="maximum-a-posteriori-map-estimation">Maximum a posteriori (MAP) estimation</h3>

<p>We learned that in MLE estimation we find \(\theta\) to maximize the likelihood function \(p(y\mid \theta)\). Now, in MAP, we find \(\theta\) such that the posterior \(p(\theta\mid y)\) is maximized, i.e.,</p>

\[\boxed{\hat{\theta}_{MAP} \in \text{argmax}_\theta p(\theta\mid y) = \text{argmax}_\theta  \frac{p(y\mid \theta) p(\theta)}{p(y)}}\]

<p>Since the denominator does not depend on \(\theta\), we have</p>

\[\hat{\theta}_{MAP} = \text{argmax}_\theta p(y\mid \theta)p(\theta) = \text{argmax}_\theta \log p(y\mid \theta) + \log p(\theta)\]

<p>The last term, \(\log p(\theta)\) is known as our prior belief.</p>

<p>Example: Again, imagine the same coin flip problem. Imagine we take the prior to be a beta distribution as</p>

\[p(\theta) = \beta(\theta;\alpha,\beta) = A~ \theta^\alpha (1-\theta)^{\beta}\]

<p>where \(A\) is a constant to make \(\int p(\theta)\text{d}\theta=1\). Now finding the solution to the MAP estimator, we find that</p>

\[\hat{\theta}_{MAP} = \text{argmax}_\theta \log p(y\mid \theta) + \log p(\theta)\]

\[\frac{m_H}{\theta}\mid _{\hat\theta} - \frac{m-m_H}{1-\theta}\mid _{\hat\theta}  + \frac{\alpha}{\theta}\mid _{\hat\theta} - \frac{\beta}{1-\theta}\mid _{\hat\theta} = 0\]

\[\hat{\theta}_{MAP} = \frac{m_H + \alpha}{m+\alpha+\beta }\]

<p>The point of \(\alpha, \beta\) coming from the prior in the above equation will be a regularizer. Imagine, we only throw the coin only once, then the ML gives \(\hat{\theta}_{ML}=1\), however, \(\hat{\theta}_{MAP} = \alpha/(\alpha+\beta)\).</p>

<h3 id="point-estimation-and-probabilistic-linear-regression">Point estimation and probabilistic linear regression</h3>

<p>Imagine we are given $m$ datapoints, \((x_1,y_1), \cdots, (x_m,y_m)\), where \(x_i\)’s are independent variables and \(y_i\)’s are dependent. Assuming a linear relationship as</p>

\[y_i \sim \theta^\top x_i + \epsilon\]

<p>where \(\epsilon \sim \mathcal{N}(0,\sigma^2)\). Assuming the independence between the \(y_i\)’s, we can write</p>

\[p(y\mid x,\theta)= \Pi_{i=1}^m p(y_i\mid x_i,\theta) = \Pi_{i=1}^m \mathcal{N}(y_i;\theta^\top x_i,\sigma^2)\]

<p>Finding the maximum of log-likelihood, we obtain</p>

\[\hat{\theta}_{ML} = \text{argmax}_\theta p(y\mid x,\theta) = \text{argmin}_\theta \sum_{i=1}^m (y_i - \theta^\top x_i)^2\]

<p>which is the equivalent to ordinary least squares.</p>

<p>Now, trying the MAP estimate, we first need to assume a prior for the \(\theta\) variables. As an initial estimate we assume \(\theta \sim \mathcal{N}(0, \nu^2\mathbf{I})\). Finding the MAP solution we find that</p>

\[\hat{\theta}_{MAP} = \text{argmax}_\theta \log p(y\mid \theta) + \log p(\theta)\]

\[\hat{\theta}_{MAP} = \text{argmin}_\theta \sum_{i=1}^m (y_i-\theta^\top x_i)^2 + \frac{\sigma^2}{\nu^2} \mid \mid \theta\mid \mid ^2\]

<p>which is the same as ML solution with a regularization term.</p>

<h3 id="conjugate-priors">Conjugate priors</h3>

<p>We often would like to find the full posterior, \(p(\theta\mid y)\). If we know the full posterior distribution, then we can do posterior predictive distribution as</p>

\[p(y_{m+1}\mid y) = \int p(y_{m+1}\mid y,\theta)~p(\theta\mid y) d\theta = \int p(y_{m+1}\mid \theta)~p(\theta\mid y) d\theta\]

<p>The second part is because \(y_{m+1}\) and \(y\) are conditionally independent. If we would like to find the full posterior, then</p>

\[p(\theta\mid y) = \frac{p(y\mid \theta)p(\theta)}{p(y)}\]

<p>The bottom part is just a normalizer. So we need to choose the prior, \(p(\theta)\), such that with the likelihood distribution, \(p(y\mid \theta)\), we are able to track the distribution. Selecting prior in such a way that the \(p(y\mid \theta)p(\theta)\) becomes tractable is known as a selection of conjugate priors for \(p(y\mid \theta)\).</p>

<h3 id="exponential-families-and-conjugate-priors">Exponential families and conjugate priors</h3>

<p>The family of distribution \(\mathcal{F}\) is called exponential family if every member of \(\mathcal{F}\) has the form</p>

\[\boxed{p(y_i\mid \theta) = f(y) g(\theta)\exp(\phi(\theta)^\top u(y_i))}\]

<p>where $f(\cdot), g(\cdot), \phi(\cdot),u(\cdot)$ are some functions. For example, an exponential distribution is an exponential family distribution:</p>

\[p(y\mid \theta) = \theta e^{-\theta y}\]

<p>or a beta distribution:</p>

\[p(y\mid \theta) = \theta^{y} (1-\theta)^{1-y} = \exp(y\log\theta + (1-y)\log(1-\theta)) = (1-\theta)\log(y \log\frac{\theta}{1-\theta})\]

<p>Normal distribution is also an exponential family.</p>

<p>If the \(p(y_i\mid \theta)\) is coming from an exponential family distribution, then if \(y_i\)’s are independent, the likelihood becomes</p>

\[p(y\mid \theta) = \Pi_{i=1}^m p(y_i\mid \theta) = \left[\Pi_{i=1}^m f(y_i)\right] g(\theta)^m \exp\left( \phi(\theta)^\top \sum_{i=1}^m u(y_i)\right)\]

<p>Now, we can select the prior as</p>

\[p(\theta) \sim g(\theta)^\eta \exp(\phi(\theta)^\top \nu)\]

<p>where \(\eta,\nu\) are hyper-parameters.</p>

<p>Now you might ask, doesn’t the choice of prior doesn’t matter? Can we really pick any prior distribution? <strong>In the next part, we show that as long as you pick a prior that assigns non-zero probabilities to every possible value of $\theta$, the solution of MAP converges to the true solution $\theta^<em>$, or more precisely, $\theta^</em>$ corresponds to the likelihood model which is closest to the true generating distribution. The closeness of the distributions is defined using KL divergence.</strong></p>

<h3 id="kl-divergence">KL divergence</h3>

<p>The KL divergence between two distributions \(p\) and \(q\) is defined as</p>

\[\boxed{D_{KL}(p\mid \mid q) := \int_x p(x) \log \frac{p(x)}{q(x)}dx}\\ \to D_{KL}(p\mid \mid q)= \mathbf{E}_p[\log p(x) - \log q(x)]\]

<p>Note that \(D_{KL}(p\mid \mid q)\) is always positive since</p>

\[-D_{KL}(p\mid \mid q) = \int p(x)\left(-\log \frac{p(x)}{q(x)}\right) dx \leq  -\log \int p(x) \frac{q(x)}{p(x)} dx =0\]

\[\rightarrow D_{KL}(p\mid \mid q)\geq 0\]

<p>and the equality with zero only happens when \(p=q\). Now, we want to use the KL divergence to find the distribution from the likelihood family that is closest to the true generating function</p>

\[\theta^* = \text{argmin}_\theta D(q(\cdot) \mid \mid p(\cdot\mid \theta))\]

<p>Imagine we have \(y=(y_1,\cdots, y_m)\) as a set of independent samples from an arbitrary distribution \(q(y)\). We assume a family \(\mathcal{F}\) of likelihood distributions with \(\Theta = \{ \theta: p(\cdot \mid  \theta) \in \mathcal{F}\}\) the finite parameter space. Our goal is to show that if \(p(\theta=\theta^*)&gt;0\), then \(p(\theta=\theta^*\mid y)\to1\) as the number of observation increases or \(m\to\infty\). Consider \(\theta\neq \theta^*\), then</p>

\[\log \frac{p(\theta\mid y)}{p(\theta^*\mid y)} = \log \frac{p(y\mid \theta) p (\theta)}{p(y\mid \theta^*) p (\theta^*)} = \log \frac{p (\theta)}{p (\theta^*)} + \sum_{i=1}^m \log \frac{p(y_i\mid \theta) }{p(y_i\mid \theta^*)}\]

<p>where we used the fact that \(p(\theta^*) \neq 0\). We have</p>

\[\frac{1}{m} \sum_{i=1}^m \log \frac{p(y_i\mid \theta) }{p(y_i\mid \theta^*)} \to \mathbf{E}_q\left[ \log \frac{p(y_i\mid \theta) }{p(y_i\mid \theta^*)}\right]\]

<p>Expanding the Expected value we have</p>

\[\mathbf{E}_q\left[ \log \frac{p(y_i\mid \theta) }{p(y_i\mid \theta^*)}\right] = \mathbf{E}_q\left[ \log \frac{p(y_i\mid \theta) }{p(y_i\mid \theta^*)}\frac{q(y)}{q(y)}\right] = \mathbf{E}_q\left[ \log \frac{q(y) }{p(y_i\mid \theta^*)}- \log \frac{q(y)}{p(y_i\mid \theta)} \right]\]

\[\mathbf{E}_q\left[ \log \frac{p(y_i\mid \theta) }{p(y_i\mid \theta^*)}\right] = D_{KL}\left(q(\cdot) \mid \mid  p(\cdot\mid \theta^*)\right) - D_{KL}\left(q(\cdot) \mid \mid  p(\cdot\mid \theta)\right) &lt; 0\]

<p>The above result is negative since we assume that \(\theta^*\) minimizes the KL divergence between \(q(\cdot)\) and \(p(\cdot\mid \theta)\). So far we have found that</p>

\[\sum_{i=1}^m \log \frac{p(y_i\mid \theta) }{p(y_i\mid \theta^)} \to m\mathbf{E}_q\left[ \log \frac{p(y_i\mid \theta) }{p(y_i\mid \theta^)}\right] \to -\infty\]

<p>since the expected value we found to be negative, and as \(m\to\infty\), the value goes to negative infinity. Plugging back into the initial equation we have</p>

\[\log \frac{p(\theta\mid y)}{p(\theta^*\mid y)} = \log \frac{p (\theta)}{p (\theta^*)} + \sum_{i=1}^m \log \frac{p(y_i\mid \theta) }{p(y_i\mid \theta^*)} = \log \frac{p (\theta)}{p (\theta^*)} -\infty \to -\infty\]

\[\log \frac{p(\theta\mid y)}{p(\theta^*\mid y)}  \to -\infty\]

<p>This implies that \(p(\theta\mid y)/p(\theta^*\mid y) \to 0\), which means that \(p(\theta\mid y) \to 0\). We started with the fact that \(\theta\neq\theta^*\). So if \(p(\theta\mid y)\to 0\) for \(\theta\neq\theta^*\), then \(p(\theta^*\mid y)\to 1\).</p>

<h1 id="expectation-maximization">Expectation Maximization</h1>

<h3 id="guassian-mixture-models">Guassian Mixture Models:</h3>

<p>In Gaussian Mixture model, you assume that your data is coming from a combination of Gaussian (Gaussian Mixture). There is a latent variable, \(z\), that determines which Gaussian to pick or how to combine the Gaussian models. In this latent model, we are interested to find \(\theta\) parameters of the Gaussian, such that \(p(x\mid \theta)\) is maximized. Let’s assume that the latent variable is discrete and \(z=1\) or \(2\). The probability of observing a datapoint is</p>

\[p(x\mid \theta) = \sum_{c=1}^2 p(x,z=c\mid \theta) = \sum_{c=1}^2 p(z=c)~p(x\mid \theta,z)\]

<p>Our goal as usual is to find \(\max_\theta p(X\mid \theta)\). We have</p>

\[\max_\theta p(X\mid \theta) = \max_\theta \log p(X\mid \theta)= \max_\theta \log \Pi_{i=1}^N p(x_i\mid \theta)=  \max_\theta \sum_{i=1}^N \log p(x_i\mid \theta)\]

\[\begin{align*}
\max_\theta p(X\mid \theta) &amp;= \max_\theta \sum_{i=1}^N \log \sum_{c=1}^2 p(x_i,z_i=c\mid \theta) \\
&amp;= \max_\theta \sum_{i=1}^N \log \sum_{c=1}^2 \frac{q(z_i=c)}{q(z_i=c)}p(x_i,z_i=c\mid \theta) \\
&amp;= \max_\theta \sum_{i=1}^N \log \sum_{c=1}^2q(z_i=c) \frac{p(x_i,z_i=c\mid \theta)}{q(z_i=c)}  \geq \max_\theta \sum_{i=1}^N \sum_{c=1}^2 q(z_i=c) \log \frac{p(x_i,z_i=c\mid \theta)}{q(z_i=c)}
\end{align*}\]

<p>So, in summary we have found the following</p>

\[\boxed{\log p(X\mid \theta) \geq \mathcal{L}(\theta,q) \text{ for any } q }\]

\[\boxed{\mathcal{L}(\theta,q) = \sum_{i=1}^N \sum_{c=1}^2 q(z_i=c) \log   \frac{p(x_i,z_i=c\mid \theta)}{q(z_i=c)}) }\]

<p>So, we do the above part in two steps as follows (Expectation step)</p>

\[\boxed{q^{k+1} = \text{argmax}_q \mathcal{L}(\theta^k,q)}\]

<p>and next (Maximization step)</p>

\[\boxed{\theta^{k+1} = \text{argmax}_\theta \mathcal{L}(\theta,q^{k+1})}\]

<h3 id="e-step">E-Step:</h3>

<p>Let’s look at the E-Step. In order to do so, let’s look at the difference between the log-likelihood and the lowerbound that we defined</p>

\[\begin{align*}
\log p(X,\theta)-\mathcal{L}(\theta,q) &amp;= \sum_{i=1}^N \log p(x_i\mid \theta)  - \sum_{i=1}^N \sum_{c=1}^2 q(z_i=c) \log   \frac{p(x_i,z_i=c\mid \theta)}{q(z_i=c)}) \\ &amp;= \sum_{i=1}^N \log p(x_i\mid \theta) \sum_{c=1}^2 q(z_i=c)  - \sum_{i=1}^N \sum_{c=1}^2 q(z_i=c) \log   \frac{p(x_i,z_i=c\mid \theta)}{q(z_i=c)}) \\ &amp;= \sum_{i=1}^N \sum_{c=1}^2 q(z_i=c)  \left( \log p(x_i\mid \theta)  -\log   \frac{p(x_i,z_i=c\mid \theta)}{q(z_i=c)}) \right)\\ &amp; = \sum_{i=1}^N \sum_{c=1}^2 q(z_i=c)  \left( \log   \frac{q(z_i=c) p(x_i\mid \theta) }{p(x_i,z_i=c\mid \theta)}) \right) \\ &amp;= \sum_{i=1}^N \sum_{c=1}^2 q(z_i=c)  \left( \log   \frac{q(z_i=c) }{p(z_i=c\mid x_i,\theta)}) \right) \\ &amp;= D_{KL}\left({q(z_i=c) }\mid \mid {p(z_i=c\mid x_i,\theta)} \right)
\end{align*}\]

<p>So we found that</p>

\[\boxed{\log p(X\mid \theta) - \mathcal{L}(\theta,q) = D_{KL}\left({q(z_i=c) }\mid \mid {p(z_i=c\mid x_i,\theta)} \right)}\]

<p>which basically means that to maximize lowerbound \(\mathcal{L}(\theta,q)\) (which minimizes the distance between the log-likelihood and the lowerbound), we need to minimize the KL-divergence on the righthandside. The KL divergence is zero when the two PDFs are the same, so</p>

\[q(z_i=c) = p(z_i=c\mid x_i,\theta)\]

<h3 id="m-step">M-Step:</h3>

<p>Now we are interested to maximize the following with respect to \(\theta\) as</p>

\[\begin{align*}
\mathcal{L}(\theta,q) &amp;= \sum_{i=1}^N \sum_{c=1}^2 q(z_i=c) \log   \frac{p(x_i,z_i=c\mid \theta)}{q(z_i=c)})  \\ &amp;= \sum_{i=1}^N \sum_{c=1}^2 q(z_i=c) \log   {p(x_i,z_i=c\mid \theta)}) - \sum_{i=1}^N \sum_{c=1}^2 q(z_i=c) \log   {q(z_i=c)})\\ &amp;= \mathbf{E}_q \log p(X,Z\mid \theta) 
\end{align*}\]

<h3 id="summary-of-expectation-maximization">Summary of Expectation-Maximization:</h3>

<p>E-step:</p>

\[\boxed{q^{k+1}(z_i) = p(z_i\mid x_i,\theta^k) }\]

<p>which results in the fact that \(\log p(X,\theta) = \mathcal{L}(\theta,q^{k+1})\). Next for the M-step, we have</p>

\[\boxed{\theta^{k+1} = \text{argmax}_\theta \mathbf{E}_q \log p(X,Z\mid \theta)}\]

<p>Note that this maximizes the lower bound, however it is guaranteed that \(\log p(X\mid \theta^{k+1}) \geq \mathcal{L}(\theta^{k+1},q^{k+1})\)</p>

<h3 id="convergence">Convergence</h3>

<p>We have</p>

\[\log p(X\mid \theta^{k+1}) \geq \mathcal{L}(\theta^{k+1},q^{k+1}) \geq \mathcal{L}(\theta^k,q^{k+1}) = \log p(X\mid \theta^k)\]

<h3 id="gaussian-mixture-models-gmm">Gaussian Mixture Models (GMM)</h3>

<p>In these models, we assume that the data is coming from a mixture of Gaussian distributions \(\mathcal{N}(\mu,\Sigma)\) and the latent distribution is a categorical distribution \(\phi\). This basically means that</p>

\[\boxed{p(X) = \sum_{k=1}^K \pi_k \mathcal{N}(X\mid \mu_k,\Sigma_k)}\]

<p>where \(\sum_k \pi_k = 1\). Note that \(\theta = \{ \mu_1,\Sigma_1, \cdots, \mu_K,\Sigma_K\}.\) Now, let’s assume the latent variable is called \(z_i\). Using Expectation-Maximization that we discussed here, we find that</p>

\[q(z_i = k) = p(z_i=k\mid x_i,\theta) = \frac{p(z_i=k) p(x_i \mid  z_i=k,\theta) }{p(x_i\mid \theta)} = \frac{p(z_i=k)p(x_i \mid  z_i=k,\theta) }{\sum_{k} p(z_i=k) p(x_i \mid  z_i=k,\theta) }\]

\[\boxed{q(z_i=k) = \frac{\pi_k \mathcal{N}(x_i\mid \mu_k,\Sigma_k)}{\sum_k\pi_k \mathcal{N}(x_i\mid \mu_k,\Sigma_k)}}\]

<p>Next, in the Maximization step, we have</p>

\[\theta^*= \max_\theta \mathbf{E}_q \log p(X,Z\mid \theta) = \max_\theta \log p(X\mid \theta) \\ \theta^* = \max_\theta \sum_i \log \left( \sum_k \pi_k \mathcal{N}(x_i\mid \mu_k,\sigma_k) \right)\]

<p>Taking the derivative with respect to the \(\mu_k\), we find that</p>

\[\frac{\partial \cdots}{\partial \mu_k} = 0 = \sum_i \frac{\pi_k \mathcal{N}(x_i\mid \mu_k,\sigma_k)}{\sum_k \pi_k \mathcal{N}(x_i\mid \mu_k,\sigma_k) }\]

\[\sum_i q(z_i=k)   \Sigma_k^{-1}(x_i - \mu_k) =0 =  \sum_i q(z_i=k)   (x_i - \mu_k)\]

\[\boxed{\mu_k =\frac{\sum_i q(z_i=k) x_i}{\sum_i q(z_i=k)}}\]

<p>Similarly, we can find that</p>

\[\boxed{\Sigma_k =   \frac{ \sum_i q(z_i=k)(x_i-\mu)^\top(x_i-\mu)}{  \sum_i q(z_i=k)}  }\]

<h3 id="k-means-as-em">K-Means as EM</h3>

<p>Imagine the K-means model, where we randomly initialize \(\theta = \{\mu_1, \cdots, \mu_C\}\) points, and then we repeat the following steps until convergence</p>

<ul>
  <li>For each point we calculate the closest centroid</li>
</ul>

\[z_i = \text{argmin}_k \\mid x_i-\mu_k\\mid ^2\]

<ul>
  <li>Update centroid</li>
</ul>

\[\mu_k = \frac{\sum_{i:z_i=k} x_i}{\sum_{i:z_i=k} 1}\]

<p>The above K-means model can be think of as a GMM. Imagine we fix the covariance matrix to be identity, $\Sigma_k = I$, and also we fix the weights to be \(\pi_k = 1/\#\text{of Gaussians}\). We then will have</p>

\[p(x_i\mid z_i=k,\theta) = \frac{1}{Z} \exp\left(-\frac{1}{2} \\mid x_i-\mu_k\\mid ^2\right)\]

<p>Then, in the E-step, we pick \(q(z)\) such that they belong to the delta functions. Then are interested to find a function from the family of delta functions such that</p>

\[q(z_i) = \begin{cases} 1 &amp; \text{ if } z_i = \text{argmax}_k p(z_i=k\mid x_i,\theta)\\ 0 &amp; \text{otherwise}\end{cases}\]

<p>Note that</p>

\[p(z_i=k\mid x_i,\theta) = \frac{1}{Z} p(x_i\mid z_i,\theta) p(z_i\mid \theta) = \frac{1}{Z} \exp(-\frac{1}{2}\\mid  x_i-\mu_k\\mid ^2) \pi_k\]

<p>So the above maximization problem becomes</p>

\[q(z_i) = \begin{cases} 1 &amp; \text{ if } z_i = \text{argmin}_k  \\mid x_i-\mu_k\\mid ^2 \\ 0&amp; \text{otherwise}\end{cases}\]

<p>which is the same as the first step in the K-means. Now, lets look at the M-step, using the GMM derivation that we did above, we ha</p>

\[\mu_k =\frac{\sum_i q(z_i=k) x_i}{\sum_i q(z_i=k)} = \frac{\sum_{i:z_i=k} x_i}{\sum_{i:z_i=k} 1}\]

<h3 id="implementing-gmm-in-python">Implementing GMM in python</h3>

<p>So in GMM we are implementing the following formulae</p>

<p>E-step:</p>

\[q(z_i=k) = \frac{\pi_k \mathcal{N}(x_i\mid \mu_k,\Sigma_k)}{\sum_k\pi_k \mathcal{N}(x_i\mid \mu_k,\Sigma_k)}\]

<p>M-Step:</p>

\[\mu_k =\frac{\sum_i q(z_i=k) x_i}{\sum_i q(z_i=k)}\]

\[\Sigma_k =   \frac{ \sum_i q(z_i=k)(x_i-\mu)^\top(x_i-\mu)}{  \sum_i q(z_i=k)}\]

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">scipy</span> <span class="kn">import</span> <span class="n">stats</span>
<span class="c1"># here we denote q(z_i=k) with a NxC matrix called gamma
# where N is the number of poitns i=1,...,N
# and C is the number of clusters
</span><span class="k">def</span> <span class="nf">E_step</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">pi</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Performs E-step on GMM model
    Each input is numpy array:
    X: (N x d), data points
    pi: (C), mixture component weights
    mu: (C x d), mixture component means
    sigma: (C x d x d), mixture component covariance matrices

    Returns:
    gamma: (N x C), probabilities of clusters for objects

    P(z\mid x) = (p(x\mid z) p(z))/(sum_z p(x\mid z) p(z) )
    gamma  =
    </span><span class="sh">"""</span>
    <span class="n">N</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># number of objects
</span>    <span class="n">C</span> <span class="o">=</span> <span class="n">pi</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># number of clusters
</span>    <span class="n">d</span> <span class="o">=</span> <span class="n">mu</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># dimension of each object
</span>    <span class="n">gamma</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">))</span> <span class="c1"># distribution q(T)
</span>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">C</span><span class="p">):</span>
      <span class="n">pi_i</span> <span class="o">=</span> <span class="n">pi</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
      <span class="n">gamma</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">pi_i</span><span class="o">*</span><span class="n">stats</span><span class="p">.</span><span class="nf">multivariate_normal</span><span class="p">(</span><span class="n">mu</span><span class="p">[</span><span class="n">i</span><span class="p">,:],</span><span class="n">sigma</span><span class="p">[</span><span class="n">i</span><span class="p">,:,:]).</span><span class="nf">pdf</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

    <span class="n">gamma</span> <span class="o">=</span> <span class="n">gamma</span><span class="o">/</span><span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">gamma</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">gamma</span>

<span class="k">def</span> <span class="nf">M_step</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">gamma</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Performs M-step on GMM model
    Each input is numpy array:
    X: (N x d), data points
    gamma: (N x C), distribution q(T)

    Returns:
    pi: (C)
    mu: (C x d)
    sigma: (C x d x d)
    </span><span class="sh">"""</span>
    <span class="n">N</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># number of objects
</span>    <span class="n">C</span> <span class="o">=</span> <span class="n">gamma</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># number of clusters
</span>    <span class="n">d</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># dimension of each object
</span>
    <span class="n">resp_weights</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">gamma</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">pi</span> <span class="o">=</span> <span class="n">resp_weights</span><span class="o">/</span><span class="p">(</span><span class="mf">1.0</span><span class="o">*</span><span class="n">N</span><span class="p">)</span>

    <span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">gamma</span><span class="p">.</span><span class="n">T</span><span class="p">,</span><span class="n">X</span><span class="p">)</span><span class="o">/</span><span class="n">resp_weights</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">sigma</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">C</span><span class="p">,</span><span class="n">d</span><span class="p">,</span><span class="n">d</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">C</span><span class="p">):</span>
      <span class="n">diff</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span><span class="o">-</span><span class="n">mu</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
      <span class="n">weighted_sum</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">((</span><span class="n">gamma</span><span class="p">[:,</span><span class="n">i</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">diff</span><span class="p">).</span><span class="n">T</span><span class="p">,</span><span class="n">diff</span><span class="p">)</span>
      <span class="n">sigma</span><span class="p">[</span><span class="n">i</span><span class="p">,:,:]</span> <span class="o">=</span> <span class="n">weighted_sum</span><span class="o">/</span><span class="n">resp_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">pi</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span>

<span class="k">def</span> <span class="nf">train_EM</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">restarts</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="sh">'''</span><span class="s">
    Starts with random initialization *restarts* times
    Runs optimization until saturation with *rtol* reached
    or *max_iter* iterations were made.

    X: (N, d), data points
    C: int, number of clusters
    </span><span class="sh">'''</span>
    <span class="n">N</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># number of objects
</span>    <span class="n">d</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># dimension of each object
</span>    <span class="n">best_loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="n">inf</span>
    <span class="n">best_pi</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="n">best_mu</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="n">best_sigma</span> <span class="o">=</span> <span class="bp">None</span>

    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">restarts</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">pi</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="n">C</span><span class="p">)</span><span class="o">/</span><span class="nf">float</span><span class="p">(</span><span class="n">C</span><span class="p">)</span>
            <span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="n">C</span><span class="p">,</span><span class="n">d</span><span class="p">)</span>
            <span class="n">sigma</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">C</span><span class="p">,</span><span class="n">d</span><span class="p">,</span><span class="n">d</span><span class="p">))</span>
            <span class="n">sigma</span><span class="p">[...]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">identity</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
            <span class="n">prev_loss</span> <span class="o">=</span> <span class="bp">None</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">max_iter</span><span class="p">):</span>
              <span class="n">gamma</span> <span class="o">=</span> <span class="nc">E_step</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">pi</span><span class="p">,</span><span class="n">mu</span><span class="p">,</span><span class="n">sigma</span><span class="p">)</span>
              <span class="n">pi</span><span class="p">,</span><span class="n">mu</span><span class="p">,</span><span class="n">sigma</span> <span class="o">=</span> <span class="nc">M_step</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">gamma</span><span class="p">)</span>
              <span class="n">loss</span> <span class="o">=</span> <span class="nf">compute_vlb</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">pi</span><span class="p">,</span><span class="n">mu</span><span class="p">,</span><span class="n">sigma</span><span class="p">,</span><span class="n">gamma</span><span class="p">)</span>

              <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="p">.</span><span class="nf">isnan</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span> <span class="ow">and</span> <span class="n">loss</span><span class="o">&gt;</span><span class="n">best_loss</span><span class="p">:</span>
                <span class="n">best_loss</span> <span class="o">=</span> <span class="n">loss</span>
                <span class="n">best_mu</span> <span class="o">=</span> <span class="n">mu</span>
                <span class="n">best_pi</span> <span class="o">=</span> <span class="n">pi</span>
                <span class="n">best_sigma</span> <span class="o">=</span> <span class="n">sigma</span>

              <span class="k">if</span> <span class="n">prev_loss</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
                <span class="n">diff</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">abs</span><span class="p">(</span><span class="n">prev_loss</span><span class="o">-</span><span class="n">loss</span><span class="p">)</span><span class="o">/</span><span class="n">np</span><span class="p">.</span><span class="nf">abs</span><span class="p">(</span><span class="n">prev_loss</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">diff</span> <span class="o">&lt;</span> <span class="n">rtol</span><span class="p">:</span>
                  <span class="k">break</span>
              <span class="n">prev_loss</span> <span class="o">=</span> <span class="n">loss</span>

        <span class="k">except</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">LinAlgError</span><span class="p">:</span>
            <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Singular matrix: components collapsed</span><span class="sh">"</span><span class="p">)</span>
            <span class="k">pass</span>

    <span class="k">return</span> <span class="n">best_loss</span><span class="p">,</span> <span class="n">best_pi</span><span class="p">,</span> <span class="n">best_mu</span><span class="p">,</span> <span class="n">best_sigma</span>
</code></pre></div></div>

<p>Benefits of GMM models: in unsupervised clustering for example, KNN methods accuracy will increase as we increase the number of groups. So you never know how many groups are better for KNN methods. In GNN on the other hand, the accuracy increases and then decreases. So increasing the number of clusters does not necessary increase the accuracy.</p>

<h3 id="dirichlet-distribution">Dirichlet Distribution</h3>

<p>A Dirichlet distribution is defined as</p>

\[f(\theta;\alpha) = \frac{1}{B(\alpha)} \Pi_{i=1}^K \theta_i^{\alpha_i-1}\]

<p>Note that \(\sum_{i=1}^K \theta_i = 1\) and \(\theta_i&gt;0\). The expected value and variance can be found as</p>

<p>Note that the Dirichlet distribution is conjugate to the multinomial distribution as</p>

\[p(\theta) = \frac{n!}{x_1! \cdots x_K!} \Pi_{i=1}^K \theta_i^{x_i}\]

<p>So if prior has a Dirichlet distribution, and likelihood is a multinomial, then the posetrior will also be a Dirichlet distribution.</p>

<h3 id="latent-dirichelet-model">Latent Dirichelet Model</h3>

<p>Imagine the following model for the distribution of words in a document</p>

<p><br /></p>
<div class="row mt-3" style="text-align:center;">
    <div class="col-sm mt-3 mt-md-0">
        <img class="img-fluid rounded z-depth-1" width="300" src="/assets/research/bayes1.jpg" />
    </div>
</div>
<p><br /></p>

<p>In latent Dirichelet model, we have</p>

\[p(W,Z,\theta) = \Pi_{d=1}^D p(\theta_d) \Pi_{n=1}^{N_d} p(z_{dn}\mid \theta_d)~p(w_{dn}\mid z_{dn})\]

<p>where \(p(\theta_d)\sim \text{Dir}(\alpha)\), and \(p(z_{dn}\mid \theta_d) = \theta_{dz_{dn}}\), and \(p(w_{dn}\mid z_{dn}) = \Phi_{z_{dn},w_{dn}}\), where \(\sum \Phi_{z_{dn},w_{dn}} =1\). In order to calculate the E-step, we first need to find the log-likelihood, where we have</p>

\[\log p(W,Z,\theta) = \sum_{d=1}^D \left[ \sum_{t=1}^T (\alpha_t-1) \log \theta_{dt} +  \sum_{n=1}^{N_d} \sum_{t=1}^T \mathbf{1}(z_{dn}=t) \left(\log \theta_{dt} + \log \phi_{tw_{dn}} \right) \right] + \text{C.}\]

<p>In the E-step, we want to</p>

\[\min D_{KL}\left( q(\theta) q(Z) \\mid  p(\theta,Z\mid W) \right)\]

\[\log q(\theta) = \mathbf{E}_{q(z)} \log p(\theta,Z,W)  =  \mathbf{E}_{q(z)} \log p(\theta,Z\mid  W) + C.\]

\[\begin{align*}
\log q(\theta) &amp;= \mathbf{E}_{q(z)} \sum_{d=1}^D \left[ \sum_{t=1}^T (\alpha_t-1) \log \theta_{dt} +  \sum_{n=1}^{N_d} \sum_{t=1}^T\mathbf{1}(z_{dn}=t) \left(\log \theta_{dt} + \log \phi_{tw_{dn}} \right) \right]\\ &amp;= \mathbf{E}_{q(z)} \sum_{d=1}^D \left[ \sum_{t=1}^T (\alpha_t-1) \log \theta_{dt} +  \sum_{n=1}^{N_d}\sum_{t=1}^T \mathbf{1}(z_{dn}=t) \left(\log \theta_{dt} \right) \right] \\ &amp;=  \sum_{d=1}^D \left[ \sum_{t=1}^T (\alpha_t-1) \log \theta_{dt} +  \sum_{n=1}^{N_d} \sum_{t=1}^T \mathbf{E}_{q(z)}\left[\mathbf{1}(z_{dn}=t)\right] \left(\log \theta_{dt}  \right) \right] \\  &amp;=  \sum_{d=1}^D \sum_{t=1}^T \log \theta_{dt} \left[ (\alpha_t-1)  +  \sum_{n=1}^{N_d} \mathbf{E}_{q(z)}\left[\mathbf{1}(z_{dn}=t)\right] \right]
\end{align*}\]

<p>So in summary, we have</p>

\[\boxed{\log q(\theta) =  \sum_{d=1}^D \sum_{t=1}^T \log \theta_{dt} \left[ (\alpha_t-1)  +  \sum_{n=1}^{N_d} \gamma_{dn}^t \right]}\]

\[\boxed{\gamma_{dn}^t = \mathbf{E}_{q(z)}\left[\mathbf{1}(z_{dn}=t)\right]}\]

\[\to q(\theta) \propto \Pi_d \Pi_t \theta_{dt}^{\left[\alpha_t + \sum_n \gamma^t_{dn} - 1\right]}\]

<p>Now, let’s take the E-step for \(q(Z)\), we have</p>

\[\begin{align*}
\log q(Z) &amp;=   \mathbf{E}_{q(\theta)} \sum_{d=1}^D \left[ \sum_{t=1}^T (\alpha_t-1) \log \theta_{dt} +  \sum_{n=1}^{N_d} \sum_{t=1}^T\mathbf{1}(z_{dn}=t) \left(\log \theta_{dt} + \log \phi_{tw_{dn}} \right) \right] \\ &amp;= \mathbf{E}_{q(\theta)} \sum_{d=1}^D  \sum_{n=1}^{N_d} \mathbf{1}(z_{dn}=t) \left(\log \theta_{dt} + \log \phi_{tw_{dn}} \right)  \\ &amp;=  \sum_{d=1}^D  \sum_{n=1}^{N_d} \mathbf{1}(z_{dn}=t) \left(\mathbf{E}_{q(\theta)} \log \theta_{dt} + \log \phi_{tw_{dn}} \right) 
\end{align*}\]

<p>so in summary</p>

\[\boxed{\log q(Z) = \sum_{d=1}^D  \sum_{n=1}^{N_d} \mathbf{1}(z_{dn}=t) \left(\mathbf{E}_{q(\theta)} \log \theta_{dt} + \log \phi_{tw_{dn}} \right) } \\ \to q(Z) = \Pi_d \Pi_t q(z_{dn})\]

\[q\left( z_{dn}=t\right) =   \frac{\phi_{t w_{dn}} \exp \left( \mathbf{E}_{q(\theta)} \log \theta_{dt} \right)}{\sum_{t'} {\phi_{t' w_{dn}} \exp \left( \mathbf{E}_{q(\theta)} \log \theta_{dt'} \right)}}\]

<p>and in the M-step we would like to maximize the following</p>

\[\begin{align*}
\mathbf{E}_{q(\theta)q(Z)} \log p(\theta,Z,W)  &amp;= \mathbf{E}_{q(\theta)q(Z)}  \left[ \sum_{d=1}^D \left[ \sum_{t=1}^T (\alpha_t-1) \log \theta_{dt} +  \sum_{n=1}^{N_d} \sum_{t=1}^T \mathbf{1}(z_{dn}=t) \left(\log \theta_{dt} + \log \phi_{tw_{dn}} \right) \right] \right] \\ &amp;= \mathbf{E}_{q(\theta)q(Z)}  \left[ \sum_{d=1}^D \sum_{t=1}^T \sum_{n=1}^{N_d} \mathbf{1}(z_{dn}=t)  \log \phi_{tw_{dn}} \right] \\  &amp;=   \sum_{d=1}^D \sum_{t=1}^T \sum_{n=1}^{N_d} \mathbf{E}_{q(\theta)q(Z)} \left[\mathbf{1}(z_{dn}=t)\right]  \log \phi_{tw_{dn}} \\ &amp;=   \sum_{d=1}^D \sum_{t=1}^T \sum_{n=1}^{N_d} \gamma_{dn}^t  \log \phi_{tw_{dn}}
\end{align*}\]

<p>given that \(\sum_w \phi_{tw} = 1\) and also \(\phi_{tw}\geq 0\). We use lagrangian to maximize the above equation, we have</p>

\[L =  \sum_{d=1}^D \sum_{t=1}^T \sum_{n=1}^{N_d} \gamma_{dn}^t \log \phi_{tw_{dn}} - \sum_{t=1}^T \lambda_t \left(\sum_w \phi_{tw}-1\right)\]

<p>Now we take the derivative to maximize the above equation, we find</p>

\[\frac{\partial L}{\partial \phi_{tw}} = \sum_{d=1}^D \sum_{n=1}^{N_d} \gamma_{dn}^t \frac{1}{\phi_{tw}}\mathbf{1}\left[w_{dn} = w\right] -  \lambda_t  = 0 \\ \phi_{tw} = \frac{\sum_{d=1}^D \sum_{n=1}^{N_d} \gamma_{dn}^t \mathbf{1}\left[w_{dn}= w\right]}{ \lambda_t}\]

<p>Knowing that \(\sum_w \phi_{tw} = 1\), we can find that</p>

\[\phi_{tw} = \frac{\sum_{d=1}^D \sum_{n=1}^{N_d} \gamma_{dn}^t \mathbf{1}\left[w_{dn}= w\right]}{ \sum_w \sum_{d=1}^D \sum_{n=1}^{N_d} \gamma_{dn}^t \mathbf{1}\left[w_{dn}= w\right]}\]

\[\to \boxed{\phi_{tw} = \frac{\sum_{d,n} \gamma_{dn}^t \mathbf{1}\left[w_{dn}= w\right]}{ \sum_{d,n,w'} \gamma_{dn}^t \mathbf{1}\left[w_{dn}= w'\right]}}\]

<h2 id="monte-carlo-method">Monte-Carlo Method</h2>

<p>Estimating expected values using sampling</p>

\[\mathbf{E}_{p(x)} f(x) = \frac{1}{M} \sum f(x_s), \quad \text{where } x_s\sim p(x)\]

<p>Now the question is how to sample from a probability distribution \(p(x)\)? In the following we will discuss this. Note that we assume that generating a random number with uniform distribution from in \([0,1]\) is given, i.e., we can easily sample form \(\mathcal{U}(0,1)\).</p>

<h3 id="sampling-from-1-d-distribution">Sampling from 1-D distribution</h3>

<p>Consider a distribution over discrete set such as \(p(a_i) = p_i\) for \(i=1,\cdots,n\). Note that \(\sum_i p_i = 1\). We can separate the \([0,1]\) distance proportional to the \(p_i\). Next, we sample a point from $[0,1]$ using the uniform distribution, we can assign it to the discrete values of \(a_i\) based on the interval that it lands into. Here is an example:</p>

<p><br /></p>
<div class="row mt-3" style="text-align:center;">
    <div class="col-sm mt-3 mt-md-0">
        <img class="img-fluid rounded z-depth-1" width="300" src="/assets/research/bayes2.png" />
    </div>
</div>
<p><br /></p>

<p>Sampling Normal distribution:</p>

<p>We can generate normal distribution using central limit theorem, i.e.</p>

\[x = \frac{1}{\sqrt{N}} \left[ \sum_{i=1}^N \left( x_i - \frac{1}{2}\right) \right]\]

<p>As the \(N\to \infty\), the \(p(x) \to \mathcal{N}(0,1)\). This has been done very efficiently, and we can use packages such as <code class="language-plaintext highlighter-rouge">np.random.randn()</code> to generate these numbers. Now imagine that we are interested in 1d sampling from a continuous distribution such as \(p(x)\) shown below</p>

<p><br /></p>
<div class="row mt-3" style="text-align:center;">
    <div class="col-sm mt-3 mt-md-0">
        <img class="img-fluid rounded z-depth-1" width="300" src="/assets/research/bayes3.png" />
    </div>
</div>
<p><br /></p>

<p>One way to sample from \(p(x)\) in the above is to first bound the pdf by some normal distribution $q(x)$. Next, we generate a random point, say \(x_0\). We then accept this point with probability \(\alpha= p(x)/q(x)\) and reject it with \(1-\alpha\). This way, we create samples from the \(p(x)\).</p>

<h3 id="markov-chains">Markov-Chains</h3>

<p>There are two methods that we will introduce here (Metropolis-Hasting and Gibbs sampling) that depend on Markov-Chain. A few introductory remarks on Markov-process is helpful before we talk about them.</p>

<p>Let \(X_t\) denote the value of a random variable at time $t$. The <em>state space</em> is the space of all possible values for $X$ values. The random variable is called a <strong>Markov process</strong> if the transition probabilities betwen different values in the state space only depend on the current’s value of the random variable, i.e.,</p>

\[p(X_{t+1}=s_{j}\mid X_0=s_k, \cdots, X_t=s_i) = p(X_{t+1}=s_{j}\mid  X_t=s_i)\]

<p>A Markov-Chain referes to a sequence of random variables \((X_0, \cdots,X_n)\) generated by a markov process. Transition probability (or the transition kernel) gives us the probability of transitioning between the states ina single step, i.e.,</p>

\[p(i\to j) = p(X_{t+1}=s_j\mid  X_{t}=s_i)\]

<p>Using the transition kernel, if we are at state \(s_i\) we can define a row vector for the state space probabilities, i.e., \(\pi_i(t) = p(X_t = s_i)\). The evolution of this state space probabilities can be obtained using the kernel as</p>

\[\pi_j(t+1) = p(X_{t+1}=s_j)  = \sum_k p(X_{t+1}=s_j\mid   X_t = s_k) p(X_t = s_k) = \sum_k p(k,j) \pi_k(t) \\ \mathbf{\pi}(t+1) = \mathbf{\pi}(t) \mathbf{P}\]

<p>As a result, we can find that \(\pi(t) = \pi(0) \mathbf{P}^k\). A distribution of states $\mathbf{\pi}^*$ is called stationary if \(\mathbf{\pi}^* = \mathbf{\pi}^*\mathbf{P}\). A sufficient condition for a unique stationary distribution is that the <strong>detailed balance</strong> condition holds</p>

\[p(j\to k) \pi^*_j = p(k\to j) \pi^*_k\]

<p>If the above condition holds then we have</p>

\[(\mathbf{\pi}\mathbf{P})_j = \sum_i \pi_i P(i,j) = \sum_i \pi_i P(i\to j) \\= \sum_i \pi_j P(j\to i)  = \pi_j \sum_i P(j\to i) = \pi_j\]

<h3 id="metropolis-hasting-algorithm">Metropolis-Hasting Algorithm</h3>

<p>So our goal is to generate a sample with PDF \(p(x)\). In Metropolis-Hasting the basic idea is to create a Markov-Process to generate new data points where \(p(x)\) is its stationary distribution. If \(p(x)\) is stationary distribution, then using following the Markov process for a long time we will generate data-points that have the distribution of \(p(x)\). But how can we create a Markov-Process where \(p(x)\) is its stationary distribution? We can use the idea of rejecting points. We start with any Markov-process \(Q\) (as long as we have a non-zero probability of going over all the data points), we then start from a data-point \(x_0\) (or state) and find our new data-point \(x_1\) (the new state). Now we have an option of accepting this new state or rejecting it. We select this acceptance/rejection probability such that our \(p(x)\) becomes the stationary distribution of our Markov process.</p>

\[p(x_0) Q(x_0\to x_1) A(x_0 \to x_1) = p(x_1) Q(x_1\to x_0) A(x_1 \to x_0) \\ \frac{A(x_0 \to x_1)}{A(x_1 \to x_0)} = \frac{p(x_1)}{p(x_0)} \frac{Q(x_1\to x_0)}{Q(x_0\to x_1)} = \rho\]

<p>So as long as our acceptance probability follows the above equality, we are doing well. Assume that the above proportionality is \(\rho\). If \(\rho\leq 1\), we can have \(A(x_0\to x_1) = \rho, A(x_1\to x_0) = 1\). On the other hand, if \(\rho&gt;1\), we can assign \(A(x_0\to x_1) = 1, A(x_1\to x_0) = 1/\rho\). So basically, we can assign the following acceptance probability</p>

\[A(x_0\to x_1) = \begin{cases} \rho &amp; \rho \leq 1 \\ 1 &amp; \rho &gt;1 \end{cases}\]

<p>Or we can summarize it as</p>

\[A(x_0\to x_1) = \min\left(1, \frac{p(x_1)}{p(x_0)} \frac{Q(x_1\to x_0)}{Q(x_0\to x_1)} \right)\]]]></content><author><name></name></author><summary type="html"><![CDATA[KL Divergence]]></summary></entry></feed>